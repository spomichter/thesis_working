{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Tokenizer \n",
    "Takes Segmentation Masks and Returns a Text-based token representation of the frame and its masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import cv2\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import re\n",
    "import imageio\n",
    "sys.path.append('..')\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_plot_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raycast out from the centroid and find the distance to the outer border of the mask\n",
    "# TODO: Implement logic for when centroid point is outside the mask- need to employ special logic in that case\n",
    "def raycast(mask, point, angle, max_dist):\n",
    "    furthest_dist = -1\n",
    "    in_bounds = True\n",
    "    for i in range(max_dist):\n",
    "        x = int(point[0] + i * np.cos(angle))\n",
    "        y = int(point[1] + i * np.sin(angle))\n",
    "        if x < 0 or y < 0 or x >= mask.shape[1] or y >= mask.shape[0]:\n",
    "            if in_bounds:\n",
    "                furthest_dist = i\n",
    "            return furthest_dist\n",
    "        if not in_bounds and mask[y, x] == 1:\n",
    "            in_bounds = True\n",
    "        if in_bounds and mask[y, x] == 0:\n",
    "            in_bounds = False\n",
    "            furthest_dist = i\n",
    "    return furthest_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_single_mask(mask, id, num_rays):\n",
    "    # Find the centroid of the mask\n",
    "    centroid = find_centroid(mask)\n",
    "    # Tokenize the mask\n",
    "    tokens = []\n",
    "    tokens.append(str(id))\n",
    "    tokens.append(centroid[0])\n",
    "    tokens.append(centroid[1])\n",
    "    str_tok = \"{\"\n",
    "    str_tok += str(id)\n",
    "    str_tok += (\",{\")\n",
    "    str_tok += str(centroid[0])\n",
    "    str_tok += (\",\")\n",
    "    str_tok += str(centroid[1])\n",
    "    str_tok += (\"}\")\n",
    "    for i in range(num_rays):\n",
    "        angle = i * 2 * np.pi / num_rays\n",
    "        raycast_distance = raycast(mask, centroid, angle, 400)\n",
    "        tokens.append(raycast_distance)\n",
    "        str_tok += (\",\")\n",
    "        str_tok += str(raycast_distance)\n",
    "    str_tok += (\"}\")\n",
    "    return tokens, str_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_masks(masks, num_rays):\n",
    "    ret_tokens = []\n",
    "    str_tokens = []\n",
    "    for i in range(len(masks)):\n",
    "        if i == 0:\n",
    "            arr, str = tokenize_single_mask(masks[i], \"gripper\", num_rays)\n",
    "        elif i == 1:\n",
    "            arr, str = tokenize_single_mask(masks[i], \"table\", num_rays)\n",
    "        elif i == 2:\n",
    "            arr, str = tokenize_single_mask(masks[i], \"yellow block\", num_rays)\n",
    "        elif i == 3:\n",
    "            arr, str = tokenize_single_mask(masks[i], \"green block\", num_rays)\n",
    "        elif i == 4:\n",
    "            arr, str = tokenize_single_mask(masks[i], \"blue block\", num_rays)\n",
    "        elif i == 5:\n",
    "            arr, str = tokenize_single_mask(masks[i], \"red block\", num_rays)\n",
    "        else:\n",
    "            arr, str = tokenize_single_mask(masks[i], i, num_rays)\n",
    "        ret_tokens.append(arr)\n",
    "        str_tokens.append(str)\n",
    "        # print('Tokens for mask', i, ':', tokens)\n",
    "    return ret_tokens, str_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of points that represent a polygon, write a function to convert it to a mask\n",
    "def polygon_to_mask(polygon, width, height):\n",
    "    mask = np.zeros((height, width))\n",
    "    polygon = np.array(polygon, np.int32)\n",
    "    mask = cv2.fillPoly(mask, [polygon], 1)\n",
    "    return mask\n",
    "\n",
    "# Given a centroid and a list of radiused points and the height and width of the original image, reconstruct the mask, making sure all the points inside the polygon are filled in\n",
    "def reconstruct_mask(centroid, radiused_points, width, height):\n",
    "    mask = np.zeros((height, width))\n",
    "    polygon_points = []\n",
    "    for i in range(len(radiused_points)):\n",
    "        angle = i * 2 * np.pi / len(radiused_points)\n",
    "        polygon_points.append([int(centroid[0] + radiused_points[i] * np.cos(angle)), int(centroid[1] + radiused_points[i] * np.sin(angle))])\n",
    "\n",
    "    mask = polygon_to_mask(polygon_points, width, height)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/home/yashas/Documents/thesis/test-images/group_0/traj0/images0/\"\n",
    "image_prefix = 'im_'\n",
    "image_suffix = '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_full_process():\n",
    "    # importing segmentations\n",
    "    segmentations = import_segmentations(image_dir)\n",
    "    # print(segmentations.shape)\n",
    "\n",
    "    # get copy of segmentations[0] where the value is 1 if the pixel is in the mask and 0 if it is not\n",
    "    # print(binarize_mask(segmentations[0], 1))\n",
    "    # print(max(segmentations[0].flatten()))\n",
    "\n",
    "    # create numpy array of shape (segmentations.shape[0], 6, segmentations.shape[1], segmentations.shape[2]) to store the segmentations\n",
    "    # for each image in the dataset\n",
    "    for i in range(segmentations.shape[0]):\n",
    "        segs = np.array([])\n",
    "        for j in range(6):\n",
    "            mask = binarize_and_preprocess(segmentations[i], j+1)\n",
    "            np_mask = np.array([mask])\n",
    "            if len(segs) == 0:\n",
    "                segs = np_mask\n",
    "            else:\n",
    "                segs = np.concatenate([segs, np_mask], axis=0)\n",
    "        if i == 0:\n",
    "            segmentations_reshaped = np.array([segs])\n",
    "        else:\n",
    "            segmentations_reshaped = np.concatenate([segmentations_reshaped, [segs]], axis=0)\n",
    "    print(segmentations_reshaped.shape)\n",
    "\n",
    "    # plot the segmentations\n",
    "    # fig, ax = plt.subplots(1, 1, figsize=(big_plot_dim, big_plot_dim))\n",
    "    # show_mask(segmentations_reshaped[0][0], ax, random_color=True)\n",
    "    # plt.show()\n",
    "\n",
    "    curr_frame_num = 0\n",
    "    curr_frame = segmentations_reshaped[curr_frame_num]\n",
    "    print(curr_frame.shape)\n",
    "    \n",
    "    # Display the current frame and then the mask\n",
    "    image = cv2.imread(image_dir + image_prefix + str(curr_frame_num) + image_suffix)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "    # plt.title('Frame ' + str(curr_frame_num))\n",
    "    # plt.imshow(image)\n",
    "    # for j in range(curr_frame.shape[0]):\n",
    "    #     show_mask(curr_frame[j], plt.gca(), color=color_list[j])\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    # Getting the centroids\n",
    "    centroids = []\n",
    "    for i in range(len(curr_frame)):\n",
    "        centroid = find_centroid(curr_frame[i])\n",
    "        centroids.append(centroid)\n",
    "\n",
    "    # Displaying the centroid on the image\n",
    "    # plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "    # plt.title('Frame ' + str(curr_frame_num))\n",
    "    # plt.imshow(image)\n",
    "    # for j in range(curr_frame.shape[0]):\n",
    "    #     show_mask(curr_frame[j], plt.gca(), color=color_list[j])\n",
    "    # for j in range(len(centroids)):\n",
    "    #     plt.scatter(centroids[j][0], centroids[j][1], color='red', marker='.', s=375, edgecolor='white', linewidth=1.25)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    # Test the raycast function\n",
    "    angle = np.pi\n",
    "    max_dist = 400\n",
    "    raycast_distances = []\n",
    "    for i in range(len(centroids)):\n",
    "        raycast_distance = raycast(curr_frame[i], centroids[i], angle, max_dist)\n",
    "        raycast_distances.append(raycast_distance)\n",
    "        print('Raycast distance for mask', i, 'is', raycast_distance)\n",
    "\n",
    "    # Displaying the raycast on the image\n",
    "    # plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "    # plt.title('Frame ' + str(curr_frame_num))\n",
    "    # # plt.imshow(image)\n",
    "    # for j in range(curr_frame.shape[0]):\n",
    "    #     show_mask(curr_frame[j], plt.gca(), color=color_list[j])\n",
    "    # for j in range(len(centroids)):\n",
    "    #     plt.scatter(centroids[j][0], centroids[j][1], color='red', marker='.', s=375, edgecolor='white', linewidth=1.25)\n",
    "    #     plt.plot([centroids[j][0], centroids[j][0] + raycast_distances[j] * np.cos(angle)], [centroids[j][1], centroids[j][1] + raycast_distances[j] * np.sin(angle)], color='red', linestyle='-', linewidth=2)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    # Test the tokenization function\n",
    "    num_rays = 25\n",
    "    tokens = tokenize_single_mask(curr_frame[0], \"gripper\", num_rays)\n",
    "    print('Tokens for mask 0:', tokens)\n",
    "\n",
    "\n",
    "    # Test the tokenization function\n",
    "    frame_tokens, string_tokens = tokenize_masks(curr_frame, num_rays)\n",
    "    print(frame_tokens)\n",
    "    np_frame = np.array(frame_tokens)\n",
    "    print(np_frame.shape)\n",
    "    print(string_tokens)\n",
    "\n",
    "    # Visualize frame_tokens\n",
    "    # plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "    # plt.title('Frame ' + str(curr_frame_num))\n",
    "    # plt.imshow(image)\n",
    "    # for j in range(curr_frame.shape[0]):\n",
    "    #     show_mask(curr_frame[j], plt.gca(), color=color_list[j])\n",
    "    # for j in range(len(centroids)):\n",
    "    #     plt.scatter(centroids[j][0], centroids[j][1], color='blue', marker='.', s=375, edgecolor='white', linewidth=1.25)\n",
    "    #     for k in range(num_rays):\n",
    "    #         plt.plot([centroids[j][0], centroids[j][0] + frame_tokens[j][k+3] * np.cos(k * 2 * np.pi / num_rays)], [centroids[j][1], centroids[j][1] + frame_tokens[j][k+3] * np.sin(k * 2 * np.pi / num_rays)], color='red', linestyle='-', linewidth=1)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    # Test the reconstruction function\n",
    "    reconstructed_masks = []\n",
    "    for i in range(len(frame_tokens)):\n",
    "        reconstructed_mask = reconstruct_mask(np.array([frame_tokens[i][1], frame_tokens[i][2]]), frame_tokens[i][3:], image.shape[1], image.shape[0])\n",
    "        reconstructed_masks.append(reconstructed_mask)\n",
    "\n",
    "    # Visualize the reconstructed masks\n",
    "    # plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "    # plt.title('Frame ' + str(curr_frame_num))\n",
    "    # plt.imshow(image)\n",
    "    # for j in range(len(reconstructed_masks)):\n",
    "    #     show_mask(reconstructed_masks[j], plt.gca(), color=color_list[j])\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    # Tokenize all frames and visualize the reconstructed masks as an animation\n",
    "    num_rays = 25\n",
    "    reconstructed_masks_over_time = []\n",
    "    string_tokens_over_time = []\n",
    "    for i in range(len(segmentations_reshaped)):\n",
    "        curr_frame = segmentations_reshaped[i]\n",
    "        print('Tokenizing frame', i)\n",
    "        frame_tokens, str_tokens = tokenize_masks(curr_frame, num_rays)\n",
    "        string_tokens_over_time.append(str(str_tokens))\n",
    "        reconstructed_masks = []\n",
    "        for j in range(len(frame_tokens)):\n",
    "            reconstructed_mask = reconstruct_mask(np.array([frame_tokens[j][1], frame_tokens[j][2]]), frame_tokens[j][3:], image.shape[1], image.shape[0])\n",
    "            reconstructed_masks.append(reconstructed_mask)\n",
    "        reconstructed_masks_over_time.append(reconstructed_masks)\n",
    "\n",
    "    string_tokens_over_time = np.array(string_tokens_over_time)\n",
    "    print(len(string_tokens_over_time))\n",
    "    print(string_tokens_over_time)\n",
    "    # output to a text file  in same directory as segmentations\n",
    "    text_file_path = image_dir + \"tokens_over_time.txt\"\n",
    "    np.savetxt(text_file_path, string_tokens_over_time, fmt='%s')\n",
    "\n",
    "\n",
    "    # Visualize the reconstructed masks over time compared to the original masks\n",
    "    # for i in range(len(reconstructed_masks_over_time)):\n",
    "    #     image = cv2.imread(image_dir + image_prefix + str(i) + image_suffix)\n",
    "    #     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #     fig, axs = plt.subplots(1, 2, figsize=(big_plot_dim*3, big_plot_dim*3))\n",
    "    #     axs[0].set_title(f'Frame {i} Reconstruction')\n",
    "    #     # axs[0].imshow(image)\n",
    "    #     for j in range(len(reconstructed_masks_over_time[i])):\n",
    "    #         show_mask(reconstructed_masks_over_time[i][j], axs[0], color=color_list[j])\n",
    "    #     # plt.axis('off')\n",
    "    #     axs[1].set_title(f'Frame {i} Orig Segmentation')\n",
    "    #     for j in range(segmentations_reshaped[i].shape[0]):\n",
    "    #         show_mask(segmentations_reshaped[i][j], axs[1], color=color_list[j])\n",
    "    #     plt.show()\n",
    "    #     time.sleep(0.1)\n",
    "    #     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images in /home/yashas/Documents/thesis/test-images/group_0/traj0/images0/\n",
      "(47, 6, 480, 640)\n",
      "(6, 480, 640)\n",
      "Raycast distance for mask 0 is 87\n",
      "Raycast distance for mask 1 is 312\n",
      "Raycast distance for mask 2 is 43\n",
      "Raycast distance for mask 3 is 43\n",
      "Raycast distance for mask 4 is 45\n",
      "Raycast distance for mask 5 is 39\n",
      "Tokens for mask 0: (['gripper', 231, 48, 91, 80, 85, 94, 98, 14, 13, 13, 82, 78, 71, 94, 90, 86, 88, 84, 64, 55, 50, 50, 52, 59, 72, 91, 87], '{gripper,{231,48},91,80,85,94,98,14,13,13,82,78,71,94,90,86,88,84,64,55,50,50,52,59,72,91,87}')\n",
      "[['gripper', 231, 48, 91, 80, 85, 94, 98, 14, 13, 13, 82, 78, 71, 94, 90, 86, 88, 84, 64, 55, 50, 50, 52, 59, 72, 91, 87], ['table', 311, 309, 329, 340, 351, 247, 201, 178, 170, 173, 187, 220, 288, 336, 315, 315, 336, 298, 277, 224, 181, 193, 190, 198, 224, 276, 340], ['yellow block', 210, 313, 43, 36, 32, 30, 30, 33, 39, 50, 50, 50, 51, 49, 47, 37, 30, 28, 26, 27, 30, 37, 48, 49, 52, 53, 49], ['green block', 166, 217, 42, 38, 31, 27, 27, 27, 30, 34, 42, 40, 41, 41, 41, 43, 33, 26, 25, 24, 25, 28, 34, 40, 42, 44, 42], ['blue block', 387, 328, 45, 40, 34, 31, 31, 33, 38, 47, 50, 49, 50, 48, 45, 42, 35, 30, 30, 29, 32, 38, 48, 49, 50, 54, 49], ['red block', 345, 196, 39, 41, 42, 40, 41, 32, 28, 25, 25, 25, 28, 35, 39, 40, 41, 38, 38, 34, 27, 24, 23, 23, 25, 30, 39]]\n",
      "(6, 28)\n",
      "['{gripper,{231,48},91,80,85,94,98,14,13,13,82,78,71,94,90,86,88,84,64,55,50,50,52,59,72,91,87}', '{table,{311,309},329,340,351,247,201,178,170,173,187,220,288,336,315,315,336,298,277,224,181,193,190,198,224,276,340}', '{yellow block,{210,313},43,36,32,30,30,33,39,50,50,50,51,49,47,37,30,28,26,27,30,37,48,49,52,53,49}', '{green block,{166,217},42,38,31,27,27,27,30,34,42,40,41,41,41,43,33,26,25,24,25,28,34,40,42,44,42}', '{blue block,{387,328},45,40,34,31,31,33,38,47,50,49,50,48,45,42,35,30,30,29,32,38,48,49,50,54,49}', '{red block,{345,196},39,41,42,40,41,32,28,25,25,25,28,35,39,40,41,38,38,34,27,24,23,23,25,30,39}']\n",
      "Tokenizing frame 0\n",
      "Tokenizing frame 1\n",
      "Tokenizing frame 2\n",
      "Tokenizing frame 3\n",
      "Tokenizing frame 4\n",
      "Tokenizing frame 5\n",
      "Tokenizing frame 6\n",
      "Tokenizing frame 7\n",
      "Tokenizing frame 8\n",
      "Tokenizing frame 9\n",
      "Tokenizing frame 10\n",
      "Tokenizing frame 11\n",
      "Tokenizing frame 12\n",
      "Tokenizing frame 13\n",
      "Tokenizing frame 14\n",
      "Tokenizing frame 15\n",
      "Tokenizing frame 16\n",
      "Tokenizing frame 17\n",
      "Tokenizing frame 18\n",
      "Tokenizing frame 19\n",
      "Tokenizing frame 20\n",
      "Tokenizing frame 21\n",
      "Tokenizing frame 22\n",
      "Tokenizing frame 23\n",
      "Tokenizing frame 24\n",
      "Tokenizing frame 25\n",
      "Tokenizing frame 26\n",
      "Tokenizing frame 27\n",
      "Tokenizing frame 28\n",
      "Tokenizing frame 29\n",
      "Tokenizing frame 30\n",
      "Tokenizing frame 31\n",
      "Tokenizing frame 32\n",
      "Tokenizing frame 33\n",
      "Tokenizing frame 34\n",
      "Tokenizing frame 35\n",
      "Tokenizing frame 36\n",
      "Tokenizing frame 37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m image_dir \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing images in\u001b[39m\u001b[38;5;124m'\u001b[39m, image_dir)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtokenize_full_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 134\u001b[0m, in \u001b[0;36mtokenize_full_process\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m curr_frame \u001b[38;5;241m=\u001b[39m segmentations_reshaped[i]\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTokenizing frame\u001b[39m\u001b[38;5;124m'\u001b[39m, i)\n\u001b[0;32m--> 134\u001b[0m frame_tokens, str_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m string_tokens_over_time\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(str_tokens))\n\u001b[1;32m    136\u001b[0m reconstructed_masks \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mtokenize_masks\u001b[0;34m(masks, num_rays)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(masks)):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m         arr, \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_single_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgripper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      8\u001b[0m         arr, \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m tokenize_single_mask(masks[i], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_rays)\n",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mtokenize_single_mask\u001b[0;34m(mask, id, num_rays)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_rays):\n\u001b[1;32m     17\u001b[0m     angle \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m num_rays\n\u001b[0;32m---> 18\u001b[0m     raycast_distance \u001b[38;5;241m=\u001b[39m \u001b[43mraycast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     tokens\u001b[38;5;241m.\u001b[39mappend(raycast_distance)\n\u001b[1;32m     20\u001b[0m     str_tok \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m, in \u001b[0;36mraycast\u001b[0;34m(mask, point, angle, max_dist)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m in_bounds \u001b[38;5;129;01mand\u001b[39;00m mask[y, x] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     14\u001b[0m     in_bounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_bounds \u001b[38;5;129;01mand\u001b[39;00m mask[y, x] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     16\u001b[0m     in_bounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     furthest_dist \u001b[38;5;241m=\u001b[39m i\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import paths from the file\n",
    "with open(\"/home/yashas/Documents/thesis/test-images/image_dirs.txt\", \"r\") as f:\n",
    "    paths = f.read().splitlines()\n",
    "\n",
    "for path in paths:\n",
    "    path = path + \"/\"\n",
    "    image_dir = path\n",
    "    print('Processing images in', image_dir)\n",
    "    tokenize_full_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 186 frames of predicted masks\n"
     ]
    }
   ],
   "source": [
    "# import predicted mask and real mask from JSON\n",
    "import json\n",
    "with open('../eval_tokens_over_time.json') as f:\n",
    "    predicted_masks = json.load(f)\n",
    "\n",
    "print(\"Loaded\", len(predicted_masks), \"frames of predicted masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Number of tokens in output and predicted masks do not match\n",
      "Error: Number of tokens in output and predicted masks do not match\n",
      "Error: Number of tokens in output and predicted masks do not match\n",
      "Error: Number of tokens in output and predicted masks do not match\n",
      "Error: Number of tokens in output and predicted masks do not match\n",
      "Error: Number of tokens in output and predicted masks do not match\n",
      "Error: Number of tokens in output and predicted masks do not match\n",
      "Error: Number of tokens in output and predicted masks do not match\n",
      "Error: Number of tokens in output and predicted masks do not match\n",
      "Error: Number of tokens in output and predicted masks do not match\n",
      "Loaded 176 frames of output masks and 176 frames of predicted masks\n",
      "Processing frame 0\n",
      "Processing frame 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2835640/3540668270.py:94: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed two minor releases later. Use buffer_rgba instead.\n",
      "  image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 2\n",
      "Processing frame 3\n",
      "Processing frame 4\n",
      "Processing frame 5\n",
      "Processing frame 6\n",
      "Processing frame 7\n",
      "Processing frame 8\n",
      "Processing frame 9\n",
      "Processing frame 10\n",
      "Processing frame 11\n",
      "Processing frame 12\n",
      "Processing frame 13\n",
      "Processing frame 14\n",
      "Processing frame 15\n",
      "Processing frame 16\n",
      "Processing frame 17\n",
      "Processing frame 18\n",
      "Processing frame 19\n",
      "Processing frame 20\n",
      "Processing frame 21\n",
      "Processing frame 22\n",
      "Processing frame 23\n",
      "Processing frame 24\n",
      "Processing frame 25\n",
      "Processing frame 26\n",
      "Processing frame 27\n",
      "Processing frame 28\n",
      "Processing frame 29\n",
      "Processing frame 30\n",
      "Processing frame 31\n",
      "Processing frame 32\n",
      "Processing frame 33\n",
      "Processing frame 34\n",
      "Processing frame 35\n",
      "Processing frame 36\n",
      "Processing frame 37\n",
      "Processing frame 38\n",
      "Processing frame 39\n",
      "Processing frame 40\n",
      "Processing frame 41\n",
      "Processing frame 42\n",
      "Processing frame 43\n",
      "Processing frame 44\n",
      "Processing frame 45\n",
      "Processing frame 46\n",
      "Processing frame 47\n",
      "Processing frame 48\n",
      "Processing frame 49\n",
      "Processing frame 50\n",
      "Processing frame 51\n",
      "Processing frame 52\n",
      "Processing frame 53\n",
      "Processing frame 54\n",
      "Processing frame 55\n",
      "Processing frame 56\n",
      "Processing frame 57\n",
      "Processing frame 58\n",
      "Processing frame 59\n",
      "Processing frame 60\n",
      "Processing frame 61\n",
      "Processing frame 62\n",
      "Processing frame 63\n",
      "Processing frame 64\n",
      "Processing frame 65\n",
      "Processing frame 66\n",
      "Processing frame 67\n",
      "Processing frame 68\n",
      "Processing frame 69\n",
      "Processing frame 70\n",
      "Processing frame 71\n",
      "Processing frame 72\n",
      "Processing frame 73\n",
      "Processing frame 74\n",
      "Processing frame 75\n",
      "Processing frame 76\n",
      "Processing frame 77\n",
      "Processing frame 78\n",
      "Processing frame 79\n",
      "Processing frame 80\n",
      "Processing frame 81\n",
      "Processing frame 82\n",
      "Processing frame 83\n",
      "Processing frame 84\n",
      "Processing frame 85\n",
      "Processing frame 86\n",
      "Processing frame 87\n",
      "Processing frame 88\n",
      "Processing frame 89\n",
      "Processing frame 90\n",
      "Processing frame 91\n",
      "Processing frame 92\n",
      "Processing frame 93\n",
      "Processing frame 94\n",
      "Processing frame 95\n",
      "Processing frame 96\n",
      "Processing frame 97\n",
      "Processing frame 98\n",
      "Processing frame 99\n",
      "Processing frame 100\n",
      "Processing frame 101\n",
      "Processing frame 102\n",
      "Processing frame 103\n",
      "Processing frame 104\n",
      "Processing frame 105\n",
      "Processing frame 106\n",
      "Processing frame 107\n",
      "Processing frame 108\n",
      "Processing frame 109\n",
      "Processing frame 110\n",
      "Processing frame 111\n",
      "Processing frame 112\n",
      "Processing frame 113\n",
      "Processing frame 114\n",
      "Processing frame 115\n",
      "Processing frame 116\n",
      "Processing frame 117\n",
      "Processing frame 118\n",
      "Processing frame 119\n",
      "Processing frame 120\n",
      "Processing frame 121\n",
      "Processing frame 122\n",
      "Processing frame 123\n",
      "Processing frame 124\n",
      "Processing frame 125\n",
      "Processing frame 126\n",
      "Processing frame 127\n",
      "Processing frame 128\n",
      "Processing frame 129\n",
      "Processing frame 130\n",
      "Processing frame 131\n",
      "Processing frame 132\n",
      "Processing frame 133\n",
      "Processing frame 134\n",
      "Processing frame 135\n",
      "Processing frame 136\n",
      "Processing frame 137\n",
      "Processing frame 138\n",
      "Processing frame 139\n",
      "Processing frame 140\n",
      "Processing frame 141\n",
      "Processing frame 142\n",
      "Processing frame 143\n",
      "Processing frame 144\n",
      "Processing frame 145\n",
      "Processing frame 146\n",
      "Processing frame 147\n",
      "Processing frame 148\n",
      "Processing frame 149\n",
      "Processing frame 150\n",
      "Processing frame 151\n",
      "Processing frame 152\n",
      "Processing frame 153\n",
      "Processing frame 154\n",
      "Processing frame 155\n",
      "Processing frame 156\n",
      "Processing frame 157\n",
      "Processing frame 158\n",
      "Processing frame 159\n",
      "Processing frame 160\n",
      "Processing frame 161\n",
      "Processing frame 162\n",
      "Processing frame 163\n",
      "Processing frame 164\n",
      "Processing frame 165\n",
      "Processing frame 166\n",
      "Processing frame 167\n",
      "Processing frame 168\n",
      "Processing frame 169\n",
      "Processing frame 170\n",
      "Processing frame 171\n",
      "Processing frame 172\n",
      "Processing frame 173\n",
      "Processing frame 174\n",
      "Processing frame 175\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"/home/yashas/Documents/thesis/test-images/group_0/traj0/images0/\"\n",
    "image = cv2.imread(image_dir + image_prefix + str(0) + image_suffix)\n",
    "\n",
    "# getting predicted and real output masks from tokens\n",
    "output_frame_tokens = []\n",
    "predic_frame_tokens = []\n",
    "\n",
    "for i in range(len(predicted_masks)):\n",
    "    # print('Processing frame', i)\n",
    "    # print(predicted_masks[i]['output'])\n",
    "    # print(predicted_masks[i]['predic'])\n",
    "    # print(\"-----\")\n",
    "    output_token_arr = re.split(r'[{,}]', predicted_masks[i]['output'])\n",
    "    output_token_arr = output_token_arr[1:-1]\n",
    "    output_token_arr = [x.strip() for x in output_token_arr]\n",
    "    output_token_arr = list(filter(None, output_token_arr))\n",
    "    output_non_num_indexes = [j for j in range(len(output_token_arr)) if not output_token_arr[j].isdigit()]\n",
    "\n",
    "    predic_token_arr = re.split(r'[{,}]', predicted_masks[i]['predic'])\n",
    "    predic_token_arr = predic_token_arr[1:-1]\n",
    "    predic_token_arr = [x.strip() for x in predic_token_arr]\n",
    "    predic_token_arr = list(filter(None, predic_token_arr))\n",
    "    predic_non_num_indexes = [j for j in range(len(predic_token_arr)) if not predic_token_arr[j].isdigit()]\n",
    "\n",
    "    if len(output_non_num_indexes) != len(predic_non_num_indexes):\n",
    "        print(\"Error: Number of tokens in output and predicted masks do not match\")\n",
    "        continue\n",
    "\n",
    "    output_frame_tok = []\n",
    "    predic_frame_tok = []\n",
    "    for n in range(len(output_non_num_indexes)):\n",
    "        output_ind = output_non_num_indexes[n]\n",
    "        predic_ind = predic_non_num_indexes[n]\n",
    "        output_id = output_token_arr[output_ind]\n",
    "        predic_id = predic_token_arr[predic_ind]\n",
    "        output_centroid = (output_token_arr[output_ind+1], output_token_arr[output_ind+2])\n",
    "        predic_centroid = (predic_token_arr[predic_ind+1], predic_token_arr[predic_ind+2])\n",
    "        if n == len(output_non_num_indexes)-1:\n",
    "            output_ray = output_token_arr[output_ind+3:]\n",
    "            predic_ray = predic_token_arr[predic_ind+3:]\n",
    "        else:\n",
    "            output_ray = output_token_arr[output_ind+3:output_non_num_indexes[n+1]]\n",
    "            predic_ray = predic_token_arr[predic_ind+3:predic_non_num_indexes[n+1]]\n",
    "        output_ray = [int(i) for i in output_ray]\n",
    "        predic_ray = [int(i) for i in predic_ray]\n",
    "        output_tok = [output_id, int(output_centroid[0]), int(output_centroid[1])]\n",
    "        predic_tok = [predic_id, int(predic_centroid[0]), int(predic_centroid[1])]\n",
    "        output_tok.extend(output_ray)\n",
    "        predic_tok.extend(predic_ray)\n",
    "        # print(output_tok)\n",
    "        # print(predic_tok)\n",
    "        output_frame_tok.append(output_tok)\n",
    "        predic_frame_tok.append(predic_tok)\n",
    "\n",
    "    output_frame_tokens.append(output_frame_tok)\n",
    "    predic_frame_tokens.append(predic_frame_tok)\n",
    "\n",
    "\n",
    "print(\"Loaded\", len(output_frame_tokens), \"frames of output masks\"\n",
    "        \" and\", len(predic_frame_tokens), \"frames of predicted masks\")\n",
    "\n",
    "# Create a figure and subplots for the animation\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# Create a list to store the frames of the animation\n",
    "frames = []\n",
    "\n",
    "for frame in range(len(output_frame_tokens)):\n",
    "    print(f\"Processing frame {frame}\")\n",
    "    \n",
    "    axs[0].clear()\n",
    "    axs[1].clear()\n",
    "    \n",
    "    output_reconstructed_masks_test = []\n",
    "    predic_reconstructed_masks_test = []\n",
    "    for j in range(len(output_frame_tokens[0])):\n",
    "        output_reconstructed_mask = reconstruct_mask(np.array([output_frame_tokens[frame][j][1], output_frame_tokens[frame][j][2]]), output_frame_tokens[frame][j][3:], image.shape[1], image.shape[0])\n",
    "        output_reconstructed_masks_test.append(output_reconstructed_mask)\n",
    "        predic_reconstructed_mask = reconstruct_mask(np.array([predic_frame_tokens[frame][j][1], predic_frame_tokens[frame][j][2]]), predic_frame_tokens[frame][j][3:], image.shape[1], image.shape[0])\n",
    "        predic_reconstructed_masks_test.append(predic_reconstructed_mask)\n",
    "    \n",
    "    axs[0].set_title(f'Ex {frame} Output Recon')\n",
    "    for j in range(len(output_reconstructed_masks_test)):\n",
    "        show_mask(output_reconstructed_masks_test[j], axs[0], color=color_list[j])\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    axs[1].set_title(f'Ex {frame} Predic Recon')\n",
    "    for j in range(len(predic_reconstructed_masks_test)):\n",
    "        show_mask(predic_reconstructed_masks_test[j], axs[1], color=color_list[j])\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    # Capture the current frame as an image\n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    \n",
    "    # Append the frame to the list of frames\n",
    "    frames.append(image)\n",
    "\n",
    "# Save the frames as a GIF using imageio\n",
    "imageio.mimsave('prediction_reconstruction_comparison.gif', frames, fps=1)\n",
    "\n",
    "plt.close(fig)\n",
    "\n",
    "# for i in range(len(output_frame_tokens)):\n",
    "#     output_reconstructed_masks_test = []\n",
    "#     predic_reconstructed_masks_test = []\n",
    "#     for j in range (len(output_frame_tokens[0])):\n",
    "#         output_reconstructed_mask = reconstruct_mask(np.array([output_frame_tokens[i][j][1], output_frame_tokens[i][j][2]]), output_frame_tokens[i][j][3:], image.shape[1], image.shape[0])\n",
    "#         output_reconstructed_masks_test.append(output_reconstructed_mask)\n",
    "#         predic_reconstructed_mask = reconstruct_mask(np.array([predic_frame_tokens[i][j][1], predic_frame_tokens[i][j][2]]), predic_frame_tokens[i][j][3:], image.shape[1], image.shape[0])\n",
    "#         predic_reconstructed_masks_test.append(predic_reconstructed_mask)\n",
    "#     # Visualize output reconstructed mask in one subplot and predic reconstructed mask in another\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(big_plot_dim*3, big_plot_dim*3))\n",
    "#     axs[0].set_title(f'Frame {i} Output Reconstruction')\n",
    "#     # axs[0].imshow(image)\n",
    "#     for j in range(len(output_reconstructed_masks_test)):\n",
    "#         show_mask(output_reconstructed_masks_test[j], axs[0], color=color_list[j])\n",
    "#     # plt.axis('off')\n",
    "#     axs[1].set_title(f'Frame {i} Predic Reconstruction')\n",
    "#     for j in range(len(predic_reconstructed_masks_test)):\n",
    "#         show_mask(predic_reconstructed_masks_test[j], axs[1], color=color_list[j])\n",
    "#     plt.show()\n",
    "#     time.sleep(0.01)\n",
    "#     clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
