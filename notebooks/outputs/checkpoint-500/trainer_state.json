{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.7050298380221653,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.11932601034641266,
      "learning_rate": 0.0004,
      "loss": 0.8959,
      "step": 1
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.12995079159736633,
      "learning_rate": 0.000399863434619324,
      "loss": 0.9509,
      "step": 2
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1028643399477005,
      "learning_rate": 0.00039972686923864806,
      "loss": 0.8057,
      "step": 3
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.11891897022724152,
      "learning_rate": 0.000399590303857972,
      "loss": 0.781,
      "step": 4
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11693283915519714,
      "learning_rate": 0.000399453738477296,
      "loss": 0.7576,
      "step": 5
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11341890692710876,
      "learning_rate": 0.00039931717309662004,
      "loss": 0.798,
      "step": 6
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.122858926653862,
      "learning_rate": 0.00039918060771594404,
      "loss": 0.7117,
      "step": 7
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12956611812114716,
      "learning_rate": 0.00039904404233526803,
      "loss": 0.6596,
      "step": 8
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.21965965628623962,
      "learning_rate": 0.000398907476954592,
      "loss": 0.6033,
      "step": 9
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1176835373044014,
      "learning_rate": 0.000398770911573916,
      "loss": 0.5973,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11746004223823547,
      "learning_rate": 0.00039863434619324,
      "loss": 0.6031,
      "step": 11
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10500402748584747,
      "learning_rate": 0.000398497780812564,
      "loss": 0.5548,
      "step": 12
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.13920103013515472,
      "learning_rate": 0.00039836121543188806,
      "loss": 0.6046,
      "step": 13
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13967584073543549,
      "learning_rate": 0.00039822465005121205,
      "loss": 0.5541,
      "step": 14
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13367138803005219,
      "learning_rate": 0.00039808808467053605,
      "loss": 0.5453,
      "step": 15
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1382903754711151,
      "learning_rate": 0.00039795151928986004,
      "loss": 0.5255,
      "step": 16
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.16521431505680084,
      "learning_rate": 0.00039781495390918403,
      "loss": 0.5806,
      "step": 17
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.14018790423870087,
      "learning_rate": 0.00039767838852850803,
      "loss": 0.5837,
      "step": 18
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.20510762929916382,
      "learning_rate": 0.0003975418231478321,
      "loss": 0.5877,
      "step": 19
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15951736271381378,
      "learning_rate": 0.00039740525776715607,
      "loss": 0.5098,
      "step": 20
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.18222330510616302,
      "learning_rate": 0.00039726869238648,
      "loss": 0.5985,
      "step": 21
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.12442512810230255,
      "learning_rate": 0.00039713212700580406,
      "loss": 0.5194,
      "step": 22
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1894417256116867,
      "learning_rate": 0.00039699556162512805,
      "loss": 0.5462,
      "step": 23
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.12953850626945496,
      "learning_rate": 0.00039685899624445205,
      "loss": 0.4865,
      "step": 24
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.19135719537734985,
      "learning_rate": 0.0003967224308637761,
      "loss": 0.4825,
      "step": 25
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1669173687696457,
      "learning_rate": 0.00039658586548310004,
      "loss": 0.5047,
      "step": 26
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1852615624666214,
      "learning_rate": 0.00039644930010242403,
      "loss": 0.4946,
      "step": 27
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19344154000282288,
      "learning_rate": 0.000396312734721748,
      "loss": 0.5015,
      "step": 28
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.14693255722522736,
      "learning_rate": 0.00039617616934107207,
      "loss": 0.5102,
      "step": 29
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.15513701736927032,
      "learning_rate": 0.00039603960396039607,
      "loss": 0.5022,
      "step": 30
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.16791105270385742,
      "learning_rate": 0.00039590303857972006,
      "loss": 0.5442,
      "step": 31
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.17000769078731537,
      "learning_rate": 0.00039576647319904405,
      "loss": 0.4718,
      "step": 32
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.15345706045627594,
      "learning_rate": 0.00039562990781836805,
      "loss": 0.4348,
      "step": 33
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.19199515879154205,
      "learning_rate": 0.00039549334243769204,
      "loss": 0.4994,
      "step": 34
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.19298982620239258,
      "learning_rate": 0.0003953567770570161,
      "loss": 0.5367,
      "step": 35
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.18228675425052643,
      "learning_rate": 0.0003952202116763401,
      "loss": 0.4753,
      "step": 36
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.22715966403484344,
      "learning_rate": 0.0003950836462956641,
      "loss": 0.4911,
      "step": 37
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.17330849170684814,
      "learning_rate": 0.0003949470809149881,
      "loss": 0.4644,
      "step": 38
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3439425230026245,
      "learning_rate": 0.00039481051553431207,
      "loss": 0.5084,
      "step": 39
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2567111551761627,
      "learning_rate": 0.00039467395015363606,
      "loss": 0.5116,
      "step": 40
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.20711593329906464,
      "learning_rate": 0.0003945373847729601,
      "loss": 0.4745,
      "step": 41
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.18716032803058624,
      "learning_rate": 0.0003944008193922841,
      "loss": 0.4883,
      "step": 42
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.20658157765865326,
      "learning_rate": 0.00039426425401160804,
      "loss": 0.4738,
      "step": 43
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.19123712182044983,
      "learning_rate": 0.00039412768863093204,
      "loss": 0.4835,
      "step": 44
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.1860593855381012,
      "learning_rate": 0.0003939911232502561,
      "loss": 0.4783,
      "step": 45
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.16982242465019226,
      "learning_rate": 0.0003938545578695801,
      "loss": 0.4701,
      "step": 46
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.19591237604618073,
      "learning_rate": 0.0003937179924889041,
      "loss": 0.4279,
      "step": 47
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2108498215675354,
      "learning_rate": 0.00039358142710822807,
      "loss": 0.4391,
      "step": 48
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.1974157989025116,
      "learning_rate": 0.00039344486172755206,
      "loss": 0.501,
      "step": 49
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.1864587962627411,
      "learning_rate": 0.00039330829634687606,
      "loss": 0.4348,
      "step": 50
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.18650147318840027,
      "learning_rate": 0.0003931717309662001,
      "loss": 0.481,
      "step": 51
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.16282854974269867,
      "learning_rate": 0.0003930351655855241,
      "loss": 0.4605,
      "step": 52
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.18192808330059052,
      "learning_rate": 0.0003928986002048481,
      "loss": 0.4911,
      "step": 53
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.14408214390277863,
      "learning_rate": 0.0003927620348241721,
      "loss": 0.4521,
      "step": 54
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.16893240809440613,
      "learning_rate": 0.0003926254694434961,
      "loss": 0.4622,
      "step": 55
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.20898085832595825,
      "learning_rate": 0.0003924889040628201,
      "loss": 0.4969,
      "step": 56
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.19083088636398315,
      "learning_rate": 0.0003923523386821441,
      "loss": 0.5239,
      "step": 57
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1833944469690323,
      "learning_rate": 0.0003922157733014681,
      "loss": 0.5189,
      "step": 58
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.17402781546115875,
      "learning_rate": 0.0003920792079207921,
      "loss": 0.4416,
      "step": 59
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1983473300933838,
      "learning_rate": 0.00039194264254011605,
      "loss": 0.4058,
      "step": 60
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.198753222823143,
      "learning_rate": 0.0003918060771594401,
      "loss": 0.4304,
      "step": 61
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.19336481392383575,
      "learning_rate": 0.0003916695117787641,
      "loss": 0.4343,
      "step": 62
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.16549089550971985,
      "learning_rate": 0.0003915329463980881,
      "loss": 0.4663,
      "step": 63
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.18489280343055725,
      "learning_rate": 0.00039139638101741214,
      "loss": 0.4779,
      "step": 64
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.17566567659378052,
      "learning_rate": 0.0003912598156367361,
      "loss": 0.4406,
      "step": 65
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1636786162853241,
      "learning_rate": 0.00039112325025606007,
      "loss": 0.432,
      "step": 66
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1571778953075409,
      "learning_rate": 0.0003909866848753841,
      "loss": 0.4013,
      "step": 67
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1813317984342575,
      "learning_rate": 0.0003908501194947081,
      "loss": 0.453,
      "step": 68
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.15979111194610596,
      "learning_rate": 0.0003907135541140321,
      "loss": 0.4955,
      "step": 69
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.18714825809001923,
      "learning_rate": 0.00039057698873335616,
      "loss": 0.3917,
      "step": 70
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.16007860004901886,
      "learning_rate": 0.0003904404233526801,
      "loss": 0.4404,
      "step": 71
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18033036589622498,
      "learning_rate": 0.0003903038579720041,
      "loss": 0.4495,
      "step": 72
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18039646744728088,
      "learning_rate": 0.00039016729259132814,
      "loss": 0.4508,
      "step": 73
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18390505015850067,
      "learning_rate": 0.00039003072721065213,
      "loss": 0.4633,
      "step": 74
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.21328343451023102,
      "learning_rate": 0.00038989416182997613,
      "loss": 0.4402,
      "step": 75
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.20199717581272125,
      "learning_rate": 0.0003897575964493001,
      "loss": 0.4346,
      "step": 76
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.21577580273151398,
      "learning_rate": 0.0003896210310686241,
      "loss": 0.4383,
      "step": 77
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.17391496896743774,
      "learning_rate": 0.0003894844656879481,
      "loss": 0.4184,
      "step": 78
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.17531253397464752,
      "learning_rate": 0.0003893479003072721,
      "loss": 0.5059,
      "step": 79
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.25591975450515747,
      "learning_rate": 0.00038921133492659615,
      "loss": 0.4707,
      "step": 80
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.16724248230457306,
      "learning_rate": 0.00038907476954592015,
      "loss": 0.4205,
      "step": 81
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.18535126745700836,
      "learning_rate": 0.0003889382041652441,
      "loss": 0.4157,
      "step": 82
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1879180371761322,
      "learning_rate": 0.00038880163878456814,
      "loss": 0.4128,
      "step": 83
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.22169995307922363,
      "learning_rate": 0.00038866507340389213,
      "loss": 0.4654,
      "step": 84
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.22645032405853271,
      "learning_rate": 0.0003885285080232161,
      "loss": 0.4889,
      "step": 85
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.17365556955337524,
      "learning_rate": 0.00038839194264254017,
      "loss": 0.467,
      "step": 86
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.21194802224636078,
      "learning_rate": 0.00038825537726186417,
      "loss": 0.3815,
      "step": 87
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.21270978450775146,
      "learning_rate": 0.0003881188118811881,
      "loss": 0.4285,
      "step": 88
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.2029954493045807,
      "learning_rate": 0.00038798224650051215,
      "loss": 0.3947,
      "step": 89
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.17495183646678925,
      "learning_rate": 0.00038784568111983615,
      "loss": 0.3947,
      "step": 90
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.21961523592472076,
      "learning_rate": 0.00038770911573916014,
      "loss": 0.4331,
      "step": 91
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.17954495549201965,
      "learning_rate": 0.00038757255035848414,
      "loss": 0.4189,
      "step": 92
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.18917836248874664,
      "learning_rate": 0.00038743598497780813,
      "loss": 0.4617,
      "step": 93
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1711726039648056,
      "learning_rate": 0.0003872994195971321,
      "loss": 0.3694,
      "step": 94
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.18672242760658264,
      "learning_rate": 0.0003871628542164561,
      "loss": 0.3997,
      "step": 95
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1815706193447113,
      "learning_rate": 0.00038702628883578017,
      "loss": 0.4099,
      "step": 96
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.21121686697006226,
      "learning_rate": 0.00038688972345510416,
      "loss": 0.4231,
      "step": 97
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.24120746552944183,
      "learning_rate": 0.00038675315807442816,
      "loss": 0.4756,
      "step": 98
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.18905414640903473,
      "learning_rate": 0.00038661659269375215,
      "loss": 0.4366,
      "step": 99
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.2789367735385895,
      "learning_rate": 0.00038648002731307614,
      "loss": 0.4429,
      "step": 100
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.17393247783184052,
      "learning_rate": 0.00038634346193240014,
      "loss": 0.4259,
      "step": 101
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1679239571094513,
      "learning_rate": 0.0003862068965517242,
      "loss": 0.3994,
      "step": 102
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.19263914227485657,
      "learning_rate": 0.0003860703311710482,
      "loss": 0.4222,
      "step": 103
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1893499195575714,
      "learning_rate": 0.0003859337657903722,
      "loss": 0.4206,
      "step": 104
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.283657431602478,
      "learning_rate": 0.00038579720040969617,
      "loss": 0.4698,
      "step": 105
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.17698688805103302,
      "learning_rate": 0.00038566063502902016,
      "loss": 0.4357,
      "step": 106
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.20826728641986847,
      "learning_rate": 0.00038552406964834416,
      "loss": 0.3977,
      "step": 107
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1877846121788025,
      "learning_rate": 0.00038538750426766815,
      "loss": 0.4299,
      "step": 108
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.19921369850635529,
      "learning_rate": 0.0003852509388869922,
      "loss": 0.411,
      "step": 109
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.25177013874053955,
      "learning_rate": 0.00038511437350631614,
      "loss": 0.4259,
      "step": 110
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.23400160670280457,
      "learning_rate": 0.00038497780812564013,
      "loss": 0.3981,
      "step": 111
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.20995192229747772,
      "learning_rate": 0.0003848412427449642,
      "loss": 0.3497,
      "step": 112
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.18908075988292694,
      "learning_rate": 0.0003847046773642882,
      "loss": 0.3957,
      "step": 113
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.20198990404605865,
      "learning_rate": 0.00038456811198361217,
      "loss": 0.4369,
      "step": 114
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1864842027425766,
      "learning_rate": 0.00038443154660293616,
      "loss": 0.4417,
      "step": 115
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.20353202521800995,
      "learning_rate": 0.00038429498122226016,
      "loss": 0.4059,
      "step": 116
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.20620527863502502,
      "learning_rate": 0.00038415841584158415,
      "loss": 0.4505,
      "step": 117
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.17421503365039825,
      "learning_rate": 0.0003840218504609082,
      "loss": 0.4064,
      "step": 118
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.2056753933429718,
      "learning_rate": 0.0003838852850802322,
      "loss": 0.4032,
      "step": 119
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.189042329788208,
      "learning_rate": 0.0003837487196995562,
      "loss": 0.4334,
      "step": 120
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.19650782644748688,
      "learning_rate": 0.0003836121543188802,
      "loss": 0.3631,
      "step": 121
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.18814721703529358,
      "learning_rate": 0.0003834755889382042,
      "loss": 0.3932,
      "step": 122
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.17587293684482574,
      "learning_rate": 0.00038333902355752817,
      "loss": 0.4532,
      "step": 123
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.16995179653167725,
      "learning_rate": 0.0003832024581768522,
      "loss": 0.4116,
      "step": 124
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1828056275844574,
      "learning_rate": 0.0003830658927961762,
      "loss": 0.395,
      "step": 125
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.18312714993953705,
      "learning_rate": 0.0003829293274155002,
      "loss": 0.4075,
      "step": 126
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.17621472477912903,
      "learning_rate": 0.00038279276203482415,
      "loss": 0.4385,
      "step": 127
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1863430142402649,
      "learning_rate": 0.0003826561966541482,
      "loss": 0.3993,
      "step": 128
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.19096267223358154,
      "learning_rate": 0.0003825196312734722,
      "loss": 0.3839,
      "step": 129
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.21727265417575836,
      "learning_rate": 0.0003823830658927962,
      "loss": 0.4004,
      "step": 130
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.19263474643230438,
      "learning_rate": 0.00038224650051212023,
      "loss": 0.3918,
      "step": 131
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1866053193807602,
      "learning_rate": 0.0003821099351314442,
      "loss": 0.3859,
      "step": 132
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.18332050740718842,
      "learning_rate": 0.00038197336975076817,
      "loss": 0.4111,
      "step": 133
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.22084063291549683,
      "learning_rate": 0.0003818368043700922,
      "loss": 0.3605,
      "step": 134
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.21410885453224182,
      "learning_rate": 0.0003817002389894162,
      "loss": 0.4081,
      "step": 135
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.2135201394557953,
      "learning_rate": 0.0003815636736087402,
      "loss": 0.4057,
      "step": 136
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.2088382989168167,
      "learning_rate": 0.0003814271082280642,
      "loss": 0.3873,
      "step": 137
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.20540077984333038,
      "learning_rate": 0.0003812905428473882,
      "loss": 0.4035,
      "step": 138
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.20161038637161255,
      "learning_rate": 0.0003811539774667122,
      "loss": 0.4043,
      "step": 139
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.17132288217544556,
      "learning_rate": 0.00038101741208603623,
      "loss": 0.3702,
      "step": 140
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1865415871143341,
      "learning_rate": 0.00038088084670536023,
      "loss": 0.4161,
      "step": 141
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.19205421209335327,
      "learning_rate": 0.0003807442813246842,
      "loss": 0.3748,
      "step": 142
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.17669232189655304,
      "learning_rate": 0.0003806077159440082,
      "loss": 0.395,
      "step": 143
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.2023332417011261,
      "learning_rate": 0.0003804711505633322,
      "loss": 0.37,
      "step": 144
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.18515044450759888,
      "learning_rate": 0.0003803345851826562,
      "loss": 0.3901,
      "step": 145
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2399897426366806,
      "learning_rate": 0.0003801980198019802,
      "loss": 0.4218,
      "step": 146
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2420056313276291,
      "learning_rate": 0.00038006145442130425,
      "loss": 0.412,
      "step": 147
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.23440030217170715,
      "learning_rate": 0.00037992488904062824,
      "loss": 0.364,
      "step": 148
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.20118071138858795,
      "learning_rate": 0.0003797883236599522,
      "loss": 0.4022,
      "step": 149
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1706302911043167,
      "learning_rate": 0.00037965175827927623,
      "loss": 0.3944,
      "step": 150
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.19102372229099274,
      "learning_rate": 0.0003795151928986002,
      "loss": 0.3301,
      "step": 151
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.18222784996032715,
      "learning_rate": 0.0003793786275179242,
      "loss": 0.3984,
      "step": 152
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.17706440389156342,
      "learning_rate": 0.00037924206213724827,
      "loss": 0.4145,
      "step": 153
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.19225913286209106,
      "learning_rate": 0.0003791054967565722,
      "loss": 0.3456,
      "step": 154
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.19951173663139343,
      "learning_rate": 0.0003789689313758962,
      "loss": 0.3633,
      "step": 155
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.21073518693447113,
      "learning_rate": 0.00037883236599522025,
      "loss": 0.3773,
      "step": 156
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.17023064196109772,
      "learning_rate": 0.00037869580061454424,
      "loss": 0.3456,
      "step": 157
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.20859971642494202,
      "learning_rate": 0.00037855923523386824,
      "loss": 0.3543,
      "step": 158
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.23133733868598938,
      "learning_rate": 0.00037842266985319223,
      "loss": 0.3414,
      "step": 159
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1911781132221222,
      "learning_rate": 0.0003782861044725162,
      "loss": 0.3705,
      "step": 160
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.21870696544647217,
      "learning_rate": 0.0003781495390918402,
      "loss": 0.3987,
      "step": 161
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.16268710792064667,
      "learning_rate": 0.0003780129737111642,
      "loss": 0.364,
      "step": 162
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.21182574331760406,
      "learning_rate": 0.00037787640833048826,
      "loss": 0.3685,
      "step": 163
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.19948598742485046,
      "learning_rate": 0.00037773984294981226,
      "loss": 0.3888,
      "step": 164
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.16624271869659424,
      "learning_rate": 0.00037760327756913625,
      "loss": 0.3684,
      "step": 165
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.168888121843338,
      "learning_rate": 0.00037746671218846025,
      "loss": 0.4106,
      "step": 166
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1666525900363922,
      "learning_rate": 0.00037733014680778424,
      "loss": 0.4125,
      "step": 167
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1948082447052002,
      "learning_rate": 0.00037719358142710823,
      "loss": 0.3576,
      "step": 168
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.19242322444915771,
      "learning_rate": 0.0003770570160464323,
      "loss": 0.369,
      "step": 169
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1987505406141281,
      "learning_rate": 0.0003769204506657563,
      "loss": 0.4216,
      "step": 170
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.2443125993013382,
      "learning_rate": 0.0003767838852850802,
      "loss": 0.4162,
      "step": 171
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1850782334804535,
      "learning_rate": 0.00037664731990440426,
      "loss": 0.3304,
      "step": 172
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1918804794549942,
      "learning_rate": 0.00037651075452372826,
      "loss": 0.3673,
      "step": 173
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.22750459611415863,
      "learning_rate": 0.00037637418914305225,
      "loss": 0.4014,
      "step": 174
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.17416325211524963,
      "learning_rate": 0.00037623762376237625,
      "loss": 0.3891,
      "step": 175
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.16330155730247498,
      "learning_rate": 0.00037610105838170024,
      "loss": 0.3864,
      "step": 176
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.18479983508586884,
      "learning_rate": 0.00037596449300102423,
      "loss": 0.3783,
      "step": 177
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.19715462625026703,
      "learning_rate": 0.00037582792762034823,
      "loss": 0.3807,
      "step": 178
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1924590915441513,
      "learning_rate": 0.0003756913622396723,
      "loss": 0.3633,
      "step": 179
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.20747852325439453,
      "learning_rate": 0.00037555479685899627,
      "loss": 0.3715,
      "step": 180
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.2685392200946808,
      "learning_rate": 0.00037541823147832027,
      "loss": 0.4609,
      "step": 181
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.20092441141605377,
      "learning_rate": 0.00037528166609764426,
      "loss": 0.4046,
      "step": 182
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.19370871782302856,
      "learning_rate": 0.00037514510071696825,
      "loss": 0.4211,
      "step": 183
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.17117629945278168,
      "learning_rate": 0.00037500853533629225,
      "loss": 0.3857,
      "step": 184
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1688281148672104,
      "learning_rate": 0.0003748719699556163,
      "loss": 0.3542,
      "step": 185
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.18875424563884735,
      "learning_rate": 0.0003747354045749403,
      "loss": 0.4098,
      "step": 186
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.18127739429473877,
      "learning_rate": 0.0003745988391942643,
      "loss": 0.3278,
      "step": 187
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.17721326649188995,
      "learning_rate": 0.0003744622738135883,
      "loss": 0.3473,
      "step": 188
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1865159273147583,
      "learning_rate": 0.0003743257084329123,
      "loss": 0.3639,
      "step": 189
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.17829829454421997,
      "learning_rate": 0.00037418914305223627,
      "loss": 0.3781,
      "step": 190
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.18134117126464844,
      "learning_rate": 0.00037405257767156026,
      "loss": 0.3628,
      "step": 191
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.19378823041915894,
      "learning_rate": 0.0003739160122908843,
      "loss": 0.4108,
      "step": 192
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.18632633984088898,
      "learning_rate": 0.00037377944691020825,
      "loss": 0.4174,
      "step": 193
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.22484908998012543,
      "learning_rate": 0.00037364288152953224,
      "loss": 0.3919,
      "step": 194
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.17331703007221222,
      "learning_rate": 0.0003735063161488563,
      "loss": 0.3811,
      "step": 195
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16882792115211487,
      "learning_rate": 0.0003733697507681803,
      "loss": 0.382,
      "step": 196
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16708339750766754,
      "learning_rate": 0.0003732331853875043,
      "loss": 0.392,
      "step": 197
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.17704758048057556,
      "learning_rate": 0.0003730966200068283,
      "loss": 0.3711,
      "step": 198
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.16114240884780884,
      "learning_rate": 0.00037296005462615227,
      "loss": 0.3362,
      "step": 199
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.20022638142108917,
      "learning_rate": 0.00037282348924547626,
      "loss": 0.3806,
      "step": 200
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.18744675815105438,
      "learning_rate": 0.0003726869238648003,
      "loss": 0.3319,
      "step": 201
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.21558323502540588,
      "learning_rate": 0.0003725503584841243,
      "loss": 0.3529,
      "step": 202
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.21583403646945953,
      "learning_rate": 0.0003724137931034483,
      "loss": 0.39,
      "step": 203
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.19908298552036285,
      "learning_rate": 0.0003722772277227723,
      "loss": 0.351,
      "step": 204
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1802712231874466,
      "learning_rate": 0.0003721406623420963,
      "loss": 0.4298,
      "step": 205
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.19505298137664795,
      "learning_rate": 0.0003720040969614203,
      "loss": 0.3494,
      "step": 206
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.16028131544589996,
      "learning_rate": 0.0003718675315807443,
      "loss": 0.3365,
      "step": 207
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.17946474254131317,
      "learning_rate": 0.0003717309662000683,
      "loss": 0.3766,
      "step": 208
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1911803036928177,
      "learning_rate": 0.0003715944008193923,
      "loss": 0.3829,
      "step": 209
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.19979660212993622,
      "learning_rate": 0.00037145783543871626,
      "loss": 0.3937,
      "step": 210
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.17798380553722382,
      "learning_rate": 0.0003713212700580403,
      "loss": 0.3842,
      "step": 211
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.19575877487659454,
      "learning_rate": 0.0003711847046773643,
      "loss": 0.375,
      "step": 212
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.19981318712234497,
      "learning_rate": 0.0003710481392966883,
      "loss": 0.3749,
      "step": 213
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.1978575438261032,
      "learning_rate": 0.00037091157391601234,
      "loss": 0.343,
      "step": 214
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.16956236958503723,
      "learning_rate": 0.0003707750085353363,
      "loss": 0.3663,
      "step": 215
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.19567793607711792,
      "learning_rate": 0.0003706384431546603,
      "loss": 0.3659,
      "step": 216
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.18070311844348907,
      "learning_rate": 0.0003705018777739843,
      "loss": 0.3589,
      "step": 217
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.17055091261863708,
      "learning_rate": 0.0003703653123933083,
      "loss": 0.3523,
      "step": 218
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.18255577981472015,
      "learning_rate": 0.0003702287470126323,
      "loss": 0.3442,
      "step": 219
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.2007906138896942,
      "learning_rate": 0.00037009218163195636,
      "loss": 0.3675,
      "step": 220
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.2507295608520508,
      "learning_rate": 0.0003699556162512803,
      "loss": 0.3583,
      "step": 221
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18266668915748596,
      "learning_rate": 0.0003698190508706043,
      "loss": 0.3814,
      "step": 222
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18681594729423523,
      "learning_rate": 0.00036968248548992834,
      "loss": 0.3498,
      "step": 223
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18366739153862,
      "learning_rate": 0.00036954592010925234,
      "loss": 0.3385,
      "step": 224
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.17412066459655762,
      "learning_rate": 0.00036940935472857633,
      "loss": 0.3846,
      "step": 225
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1903606355190277,
      "learning_rate": 0.00036927278934790033,
      "loss": 0.376,
      "step": 226
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1933138221502304,
      "learning_rate": 0.0003691362239672243,
      "loss": 0.3759,
      "step": 227
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.22036446630954742,
      "learning_rate": 0.0003689996585865483,
      "loss": 0.4055,
      "step": 228
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.2663576900959015,
      "learning_rate": 0.0003688630932058723,
      "loss": 0.409,
      "step": 229
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.21347099542617798,
      "learning_rate": 0.00036872652782519636,
      "loss": 0.3664,
      "step": 230
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1852015256881714,
      "learning_rate": 0.00036858996244452035,
      "loss": 0.3758,
      "step": 231
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.19410254061222076,
      "learning_rate": 0.0003684533970638443,
      "loss": 0.3577,
      "step": 232
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1948726326227188,
      "learning_rate": 0.00036831683168316834,
      "loss": 0.3637,
      "step": 233
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.17496037483215332,
      "learning_rate": 0.00036818026630249233,
      "loss": 0.35,
      "step": 234
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.18115025758743286,
      "learning_rate": 0.00036804370092181633,
      "loss": 0.3865,
      "step": 235
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.20185108482837677,
      "learning_rate": 0.0003679071355411404,
      "loss": 0.364,
      "step": 236
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1938481330871582,
      "learning_rate": 0.00036777057016046437,
      "loss": 0.3618,
      "step": 237
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.20931850373744965,
      "learning_rate": 0.0003676340047797883,
      "loss": 0.3573,
      "step": 238
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.18935449421405792,
      "learning_rate": 0.00036749743939911236,
      "loss": 0.4016,
      "step": 239
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.2249639332294464,
      "learning_rate": 0.00036736087401843635,
      "loss": 0.398,
      "step": 240
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.1690995693206787,
      "learning_rate": 0.00036722430863776035,
      "loss": 0.3921,
      "step": 241
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.19712598621845245,
      "learning_rate": 0.00036708774325708434,
      "loss": 0.3927,
      "step": 242
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.19995993375778198,
      "learning_rate": 0.00036695117787640834,
      "loss": 0.3432,
      "step": 243
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.20136070251464844,
      "learning_rate": 0.00036681461249573233,
      "loss": 0.3823,
      "step": 244
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.1755421757698059,
      "learning_rate": 0.0003666780471150563,
      "loss": 0.351,
      "step": 245
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.23074768483638763,
      "learning_rate": 0.00036654148173438037,
      "loss": 0.4405,
      "step": 246
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.17130251228809357,
      "learning_rate": 0.00036640491635370437,
      "loss": 0.3548,
      "step": 247
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.20049941539764404,
      "learning_rate": 0.00036626835097302836,
      "loss": 0.395,
      "step": 248
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.17307546734809875,
      "learning_rate": 0.00036613178559235236,
      "loss": 0.351,
      "step": 249
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.18956033885478973,
      "learning_rate": 0.00036599522021167635,
      "loss": 0.3732,
      "step": 250
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.19508998095989227,
      "learning_rate": 0.00036585865483100034,
      "loss": 0.37,
      "step": 251
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1894523650407791,
      "learning_rate": 0.0003657220894503244,
      "loss": 0.3617,
      "step": 252
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.18485723435878754,
      "learning_rate": 0.0003655855240696484,
      "loss": 0.3227,
      "step": 253
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.19283626973628998,
      "learning_rate": 0.0003654489586889724,
      "loss": 0.3582,
      "step": 254
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.18002986907958984,
      "learning_rate": 0.0003653123933082964,
      "loss": 0.3563,
      "step": 255
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1734979748725891,
      "learning_rate": 0.00036517582792762037,
      "loss": 0.3242,
      "step": 256
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.19178953766822815,
      "learning_rate": 0.00036503926254694436,
      "loss": 0.3241,
      "step": 257
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.20438987016677856,
      "learning_rate": 0.00036490269716626836,
      "loss": 0.3719,
      "step": 258
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.2484029084444046,
      "learning_rate": 0.0003647661317855924,
      "loss": 0.3667,
      "step": 259
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.18747936189174652,
      "learning_rate": 0.00036462956640491634,
      "loss": 0.3318,
      "step": 260
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.19476965069770813,
      "learning_rate": 0.00036449300102424034,
      "loss": 0.3915,
      "step": 261
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.22352959215641022,
      "learning_rate": 0.0003643564356435644,
      "loss": 0.3976,
      "step": 262
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.16797375679016113,
      "learning_rate": 0.0003642198702628884,
      "loss": 0.293,
      "step": 263
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.1924566775560379,
      "learning_rate": 0.0003640833048822124,
      "loss": 0.3432,
      "step": 264
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.19407260417938232,
      "learning_rate": 0.00036394673950153637,
      "loss": 0.352,
      "step": 265
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.18697986006736755,
      "learning_rate": 0.00036381017412086036,
      "loss": 0.3711,
      "step": 266
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.19984957575798035,
      "learning_rate": 0.00036367360874018436,
      "loss": 0.3941,
      "step": 267
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.25614839792251587,
      "learning_rate": 0.0003635370433595084,
      "loss": 0.397,
      "step": 268
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.17615966498851776,
      "learning_rate": 0.0003634004779788324,
      "loss": 0.3398,
      "step": 269
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.16232623159885406,
      "learning_rate": 0.0003632639125981564,
      "loss": 0.3268,
      "step": 270
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.17790842056274414,
      "learning_rate": 0.0003631273472174804,
      "loss": 0.3425,
      "step": 271
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1584029346704483,
      "learning_rate": 0.0003629907818368044,
      "loss": 0.332,
      "step": 272
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.20034293830394745,
      "learning_rate": 0.0003628542164561284,
      "loss": 0.3941,
      "step": 273
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.20284485816955566,
      "learning_rate": 0.00036271765107545237,
      "loss": 0.3626,
      "step": 274
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.18261189758777618,
      "learning_rate": 0.0003625810856947764,
      "loss": 0.3115,
      "step": 275
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.2061653584241867,
      "learning_rate": 0.0003624445203141004,
      "loss": 0.3353,
      "step": 276
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.16379022598266602,
      "learning_rate": 0.00036230795493342435,
      "loss": 0.3147,
      "step": 277
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.18098846077919006,
      "learning_rate": 0.0003621713895527484,
      "loss": 0.3326,
      "step": 278
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.17694753408432007,
      "learning_rate": 0.0003620348241720724,
      "loss": 0.3147,
      "step": 279
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.21474365890026093,
      "learning_rate": 0.0003618982587913964,
      "loss": 0.3502,
      "step": 280
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1938004344701767,
      "learning_rate": 0.00036176169341072044,
      "loss": 0.3297,
      "step": 281
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1779995560646057,
      "learning_rate": 0.0003616251280300444,
      "loss": 0.36,
      "step": 282
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.2481638640165329,
      "learning_rate": 0.00036148856264936837,
      "loss": 0.357,
      "step": 283
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.19048528373241425,
      "learning_rate": 0.0003613519972686924,
      "loss": 0.3478,
      "step": 284
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.2661489248275757,
      "learning_rate": 0.0003612154318880164,
      "loss": 0.3242,
      "step": 285
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.18586614727973938,
      "learning_rate": 0.0003610788665073404,
      "loss": 0.3272,
      "step": 286
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.252966046333313,
      "learning_rate": 0.0003609423011266644,
      "loss": 0.3109,
      "step": 287
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.25187063217163086,
      "learning_rate": 0.0003608057357459884,
      "loss": 0.4313,
      "step": 288
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.2117471545934677,
      "learning_rate": 0.0003606691703653124,
      "loss": 0.3286,
      "step": 289
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.22412477433681488,
      "learning_rate": 0.0003605326049846364,
      "loss": 0.3466,
      "step": 290
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.16692133247852325,
      "learning_rate": 0.00036039603960396043,
      "loss": 0.3204,
      "step": 291
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.18807296454906464,
      "learning_rate": 0.00036025947422328443,
      "loss": 0.36,
      "step": 292
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.21419252455234528,
      "learning_rate": 0.0003601229088426084,
      "loss": 0.4177,
      "step": 293
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1749790906906128,
      "learning_rate": 0.0003599863434619324,
      "loss": 0.3243,
      "step": 294
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18493682146072388,
      "learning_rate": 0.0003598497780812564,
      "loss": 0.3404,
      "step": 295
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21522802114486694,
      "learning_rate": 0.0003597132127005804,
      "loss": 0.3183,
      "step": 296
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.24882280826568604,
      "learning_rate": 0.00035957664731990445,
      "loss": 0.3477,
      "step": 297
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21226254105567932,
      "learning_rate": 0.00035944008193922845,
      "loss": 0.3123,
      "step": 298
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23622505366802216,
      "learning_rate": 0.0003593035165585524,
      "loss": 0.3092,
      "step": 299
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24488712847232819,
      "learning_rate": 0.00035916695117787644,
      "loss": 0.3609,
      "step": 300
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.22958829998970032,
      "learning_rate": 0.00035903038579720043,
      "loss": 0.3381,
      "step": 301
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.19518715143203735,
      "learning_rate": 0.0003588938204165244,
      "loss": 0.3533,
      "step": 302
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.19504888355731964,
      "learning_rate": 0.00035875725503584847,
      "loss": 0.3366,
      "step": 303
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.197079136967659,
      "learning_rate": 0.0003586206896551724,
      "loss": 0.3084,
      "step": 304
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1875862032175064,
      "learning_rate": 0.0003584841242744964,
      "loss": 0.3312,
      "step": 305
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.17808176577091217,
      "learning_rate": 0.0003583475588938204,
      "loss": 0.3024,
      "step": 306
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.2030431032180786,
      "learning_rate": 0.00035821099351314445,
      "loss": 0.3211,
      "step": 307
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.21580669283866882,
      "learning_rate": 0.00035807442813246844,
      "loss": 0.3362,
      "step": 308
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.22665748000144958,
      "learning_rate": 0.00035793786275179244,
      "loss": 0.3744,
      "step": 309
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.26513639092445374,
      "learning_rate": 0.00035780129737111643,
      "loss": 0.3431,
      "step": 310
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.2653314769268036,
      "learning_rate": 0.0003576647319904404,
      "loss": 0.3648,
      "step": 311
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.2110290825366974,
      "learning_rate": 0.0003575281666097644,
      "loss": 0.3355,
      "step": 312
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.21307623386383057,
      "learning_rate": 0.00035739160122908847,
      "loss": 0.3231,
      "step": 313
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.1949010044336319,
      "learning_rate": 0.00035725503584841246,
      "loss": 0.3216,
      "step": 314
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.18773755431175232,
      "learning_rate": 0.00035711847046773646,
      "loss": 0.3268,
      "step": 315
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.21050895750522614,
      "learning_rate": 0.00035698190508706045,
      "loss": 0.3092,
      "step": 316
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.20176264643669128,
      "learning_rate": 0.00035684533970638444,
      "loss": 0.3042,
      "step": 317
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.22255906462669373,
      "learning_rate": 0.00035670877432570844,
      "loss": 0.3286,
      "step": 318
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.24059513211250305,
      "learning_rate": 0.0003565722089450325,
      "loss": 0.3196,
      "step": 319
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.21301156282424927,
      "learning_rate": 0.0003564356435643565,
      "loss": 0.3136,
      "step": 320
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.29737719893455505,
      "learning_rate": 0.0003562990781836804,
      "loss": 0.3965,
      "step": 321
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.2317172735929489,
      "learning_rate": 0.0003561625128030044,
      "loss": 0.3584,
      "step": 322
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.23438389599323273,
      "learning_rate": 0.00035602594742232846,
      "loss": 0.3545,
      "step": 323
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.20273594558238983,
      "learning_rate": 0.00035588938204165246,
      "loss": 0.3382,
      "step": 324
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.24612386524677277,
      "learning_rate": 0.00035575281666097645,
      "loss": 0.3547,
      "step": 325
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.21637634932994843,
      "learning_rate": 0.00035561625128030045,
      "loss": 0.365,
      "step": 326
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.19678835570812225,
      "learning_rate": 0.00035547968589962444,
      "loss": 0.3382,
      "step": 327
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.24516811966896057,
      "learning_rate": 0.00035534312051894843,
      "loss": 0.3723,
      "step": 328
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.18380539119243622,
      "learning_rate": 0.0003552065551382725,
      "loss": 0.3422,
      "step": 329
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.19929836690425873,
      "learning_rate": 0.0003550699897575965,
      "loss": 0.3239,
      "step": 330
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.18697336316108704,
      "learning_rate": 0.00035493342437692047,
      "loss": 0.2937,
      "step": 331
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.17347358167171478,
      "learning_rate": 0.00035479685899624447,
      "loss": 0.3093,
      "step": 332
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.19448332488536835,
      "learning_rate": 0.00035466029361556846,
      "loss": 0.3532,
      "step": 333
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.19622744619846344,
      "learning_rate": 0.00035452372823489245,
      "loss": 0.3364,
      "step": 334
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.20212899148464203,
      "learning_rate": 0.0003543871628542165,
      "loss": 0.332,
      "step": 335
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.17936906218528748,
      "learning_rate": 0.0003542505974735405,
      "loss": 0.278,
      "step": 336
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.23737987875938416,
      "learning_rate": 0.0003541140320928645,
      "loss": 0.3577,
      "step": 337
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.24131621420383453,
      "learning_rate": 0.0003539774667121885,
      "loss": 0.3918,
      "step": 338
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1995277851819992,
      "learning_rate": 0.0003538409013315125,
      "loss": 0.3512,
      "step": 339
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1794193983078003,
      "learning_rate": 0.00035370433595083647,
      "loss": 0.2991,
      "step": 340
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.19475747644901276,
      "learning_rate": 0.00035356777057016047,
      "loss": 0.319,
      "step": 341
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.20989356935024261,
      "learning_rate": 0.0003534312051894845,
      "loss": 0.3302,
      "step": 342
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.23322360217571259,
      "learning_rate": 0.00035329463980880845,
      "loss": 0.334,
      "step": 343
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.22068044543266296,
      "learning_rate": 0.00035315807442813245,
      "loss": 0.3185,
      "step": 344
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.23216703534126282,
      "learning_rate": 0.0003530215090474565,
      "loss": 0.3536,
      "step": 345
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.2448900192975998,
      "learning_rate": 0.0003528849436667805,
      "loss": 0.4075,
      "step": 346
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.20112290978431702,
      "learning_rate": 0.0003527483782861045,
      "loss": 0.3363,
      "step": 347
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.21474134922027588,
      "learning_rate": 0.00035261181290542853,
      "loss": 0.311,
      "step": 348
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.20913651585578918,
      "learning_rate": 0.0003524752475247525,
      "loss": 0.3653,
      "step": 349
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.19747164845466614,
      "learning_rate": 0.00035233868214407647,
      "loss": 0.2868,
      "step": 350
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.23086903989315033,
      "learning_rate": 0.0003522021167634005,
      "loss": 0.3268,
      "step": 351
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.21606570482254028,
      "learning_rate": 0.0003520655513827245,
      "loss": 0.3174,
      "step": 352
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.20444978773593903,
      "learning_rate": 0.0003519289860020485,
      "loss": 0.3217,
      "step": 353
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.2465686947107315,
      "learning_rate": 0.0003517924206213725,
      "loss": 0.3473,
      "step": 354
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.22836992144584656,
      "learning_rate": 0.0003516558552406965,
      "loss": 0.2873,
      "step": 355
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.2218930572271347,
      "learning_rate": 0.0003515192898600205,
      "loss": 0.3336,
      "step": 356
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.2022252380847931,
      "learning_rate": 0.0003513827244793445,
      "loss": 0.3234,
      "step": 357
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.23240654170513153,
      "learning_rate": 0.00035124615909866853,
      "loss": 0.3148,
      "step": 358
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.22239798307418823,
      "learning_rate": 0.0003511095937179925,
      "loss": 0.3216,
      "step": 359
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.2224113494157791,
      "learning_rate": 0.00035097302833731646,
      "loss": 0.3409,
      "step": 360
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.19898109138011932,
      "learning_rate": 0.0003508364629566405,
      "loss": 0.3137,
      "step": 361
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.20596817135810852,
      "learning_rate": 0.0003506998975759645,
      "loss": 0.334,
      "step": 362
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.18799731135368347,
      "learning_rate": 0.0003505633321952885,
      "loss": 0.3147,
      "step": 363
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.18455596268177032,
      "learning_rate": 0.00035042676681461255,
      "loss": 0.2958,
      "step": 364
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.2187097817659378,
      "learning_rate": 0.00035029020143393654,
      "loss": 0.3683,
      "step": 365
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.2159241884946823,
      "learning_rate": 0.0003501536360532605,
      "loss": 0.3344,
      "step": 366
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.20640219748020172,
      "learning_rate": 0.00035001707067258453,
      "loss": 0.3263,
      "step": 367
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.21508823335170746,
      "learning_rate": 0.0003498805052919085,
      "loss": 0.3229,
      "step": 368
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.24084541201591492,
      "learning_rate": 0.0003497439399112325,
      "loss": 0.3392,
      "step": 369
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.23376256227493286,
      "learning_rate": 0.00034960737453055657,
      "loss": 0.3675,
      "step": 370
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.20889417827129364,
      "learning_rate": 0.0003494708091498805,
      "loss": 0.3022,
      "step": 371
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1714739352464676,
      "learning_rate": 0.0003493342437692045,
      "loss": 0.31,
      "step": 372
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.19280219078063965,
      "learning_rate": 0.0003491976783885285,
      "loss": 0.3031,
      "step": 373
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.19822730123996735,
      "learning_rate": 0.00034906111300785254,
      "loss": 0.3435,
      "step": 374
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.21925927698612213,
      "learning_rate": 0.00034892454762717654,
      "loss": 0.3515,
      "step": 375
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.21244312822818756,
      "learning_rate": 0.00034878798224650053,
      "loss": 0.3401,
      "step": 376
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.23074650764465332,
      "learning_rate": 0.0003486514168658245,
      "loss": 0.3356,
      "step": 377
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.22382019460201263,
      "learning_rate": 0.0003485148514851485,
      "loss": 0.3319,
      "step": 378
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.21527686715126038,
      "learning_rate": 0.0003483782861044725,
      "loss": 0.3348,
      "step": 379
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.21716850996017456,
      "learning_rate": 0.00034824172072379656,
      "loss": 0.3042,
      "step": 380
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.26965954899787903,
      "learning_rate": 0.00034810515534312056,
      "loss": 0.3617,
      "step": 381
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.2109793722629547,
      "learning_rate": 0.0003479685899624445,
      "loss": 0.3115,
      "step": 382
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.23406080901622772,
      "learning_rate": 0.00034783202458176855,
      "loss": 0.3562,
      "step": 383
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1885213404893875,
      "learning_rate": 0.00034769545920109254,
      "loss": 0.3125,
      "step": 384
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.20651307702064514,
      "learning_rate": 0.00034755889382041653,
      "loss": 0.3176,
      "step": 385
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.20523285865783691,
      "learning_rate": 0.0003474223284397406,
      "loss": 0.3181,
      "step": 386
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.20894725620746613,
      "learning_rate": 0.0003472857630590646,
      "loss": 0.3556,
      "step": 387
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.18450474739074707,
      "learning_rate": 0.0003471491976783885,
      "loss": 0.3165,
      "step": 388
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.23721225559711456,
      "learning_rate": 0.0003470126322977125,
      "loss": 0.3318,
      "step": 389
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1889929473400116,
      "learning_rate": 0.00034687606691703656,
      "loss": 0.279,
      "step": 390
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.21711833775043488,
      "learning_rate": 0.00034673950153636055,
      "loss": 0.332,
      "step": 391
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.24192307889461517,
      "learning_rate": 0.00034660293615568455,
      "loss": 0.3613,
      "step": 392
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.26290762424468994,
      "learning_rate": 0.00034646637077500854,
      "loss": 0.3123,
      "step": 393
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.22642219066619873,
      "learning_rate": 0.00034632980539433254,
      "loss": 0.3161,
      "step": 394
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.2525891661643982,
      "learning_rate": 0.00034619324001365653,
      "loss": 0.3138,
      "step": 395
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.21142880618572235,
      "learning_rate": 0.0003460566746329806,
      "loss": 0.3353,
      "step": 396
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.18987533450126648,
      "learning_rate": 0.00034592010925230457,
      "loss": 0.3014,
      "step": 397
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.18728755414485931,
      "learning_rate": 0.00034578354387162857,
      "loss": 0.3026,
      "step": 398
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.21900956332683563,
      "learning_rate": 0.00034564697849095256,
      "loss": 0.3904,
      "step": 399
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.24834366142749786,
      "learning_rate": 0.00034551041311027655,
      "loss": 0.3508,
      "step": 400
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.20587611198425293,
      "learning_rate": 0.00034537384772960055,
      "loss": 0.3082,
      "step": 401
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.23933079838752747,
      "learning_rate": 0.0003452372823489246,
      "loss": 0.3478,
      "step": 402
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.18723377585411072,
      "learning_rate": 0.0003451007169682486,
      "loss": 0.2832,
      "step": 403
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.21344821155071259,
      "learning_rate": 0.0003449641515875726,
      "loss": 0.337,
      "step": 404
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.22146761417388916,
      "learning_rate": 0.0003448275862068965,
      "loss": 0.3173,
      "step": 405
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.21174845099449158,
      "learning_rate": 0.0003446910208262206,
      "loss": 0.3551,
      "step": 406
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.24281994998455048,
      "learning_rate": 0.00034455445544554457,
      "loss": 0.3679,
      "step": 407
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.21000364422798157,
      "learning_rate": 0.00034441789006486856,
      "loss": 0.3787,
      "step": 408
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.18209049105644226,
      "learning_rate": 0.0003442813246841926,
      "loss": 0.3194,
      "step": 409
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.23496213555335999,
      "learning_rate": 0.00034414475930351655,
      "loss": 0.3729,
      "step": 410
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1980510652065277,
      "learning_rate": 0.00034400819392284054,
      "loss": 0.344,
      "step": 411
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.20585277676582336,
      "learning_rate": 0.0003438716285421646,
      "loss": 0.3242,
      "step": 412
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.2242691069841385,
      "learning_rate": 0.0003437350631614886,
      "loss": 0.3205,
      "step": 413
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.23390519618988037,
      "learning_rate": 0.0003435984977808126,
      "loss": 0.3585,
      "step": 414
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.2117650955915451,
      "learning_rate": 0.0003434619324001366,
      "loss": 0.3268,
      "step": 415
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.21375177800655365,
      "learning_rate": 0.00034332536701946057,
      "loss": 0.3127,
      "step": 416
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.20376719534397125,
      "learning_rate": 0.00034318880163878456,
      "loss": 0.3235,
      "step": 417
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.20974870026111603,
      "learning_rate": 0.0003430522362581086,
      "loss": 0.3004,
      "step": 418
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.20580217242240906,
      "learning_rate": 0.0003429156708774326,
      "loss": 0.3068,
      "step": 419
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.2302500307559967,
      "learning_rate": 0.0003427791054967566,
      "loss": 0.3041,
      "step": 420
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.22961857914924622,
      "learning_rate": 0.0003426425401160806,
      "loss": 0.3224,
      "step": 421
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.2238655835390091,
      "learning_rate": 0.0003425059747354046,
      "loss": 0.2925,
      "step": 422
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.2443244457244873,
      "learning_rate": 0.0003423694093547286,
      "loss": 0.3017,
      "step": 423
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.21487785875797272,
      "learning_rate": 0.0003422328439740526,
      "loss": 0.3128,
      "step": 424
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.2441122829914093,
      "learning_rate": 0.0003420962785933766,
      "loss": 0.3173,
      "step": 425
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.24611538648605347,
      "learning_rate": 0.0003419597132127006,
      "loss": 0.3416,
      "step": 426
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.22902363538742065,
      "learning_rate": 0.00034182314783202456,
      "loss": 0.3812,
      "step": 427
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.23213110864162445,
      "learning_rate": 0.0003416865824513486,
      "loss": 0.312,
      "step": 428
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.20174476504325867,
      "learning_rate": 0.0003415500170706726,
      "loss": 0.2927,
      "step": 429
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.20617976784706116,
      "learning_rate": 0.0003414134516899966,
      "loss": 0.3195,
      "step": 430
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.21369288861751556,
      "learning_rate": 0.00034127688630932064,
      "loss": 0.3053,
      "step": 431
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.19960172474384308,
      "learning_rate": 0.0003411403209286446,
      "loss": 0.3164,
      "step": 432
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.1865237057209015,
      "learning_rate": 0.0003410037555479686,
      "loss": 0.2988,
      "step": 433
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.2161438763141632,
      "learning_rate": 0.0003408671901672926,
      "loss": 0.3183,
      "step": 434
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.20188391208648682,
      "learning_rate": 0.0003407306247866166,
      "loss": 0.2683,
      "step": 435
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.22893966734409332,
      "learning_rate": 0.0003405940594059406,
      "loss": 0.311,
      "step": 436
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.24851582944393158,
      "learning_rate": 0.0003404574940252646,
      "loss": 0.2843,
      "step": 437
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.2697020173072815,
      "learning_rate": 0.0003403209286445886,
      "loss": 0.345,
      "step": 438
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.2721976935863495,
      "learning_rate": 0.0003401843632639126,
      "loss": 0.3698,
      "step": 439
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.23578594624996185,
      "learning_rate": 0.0003400477978832366,
      "loss": 0.3229,
      "step": 440
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.19231589138507843,
      "learning_rate": 0.00033991123250256064,
      "loss": 0.3193,
      "step": 441
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.2158489227294922,
      "learning_rate": 0.00033977466712188463,
      "loss": 0.3128,
      "step": 442
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.2037849724292755,
      "learning_rate": 0.00033963810174120863,
      "loss": 0.3262,
      "step": 443
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.18851549923419952,
      "learning_rate": 0.0003395015363605326,
      "loss": 0.2829,
      "step": 444
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.19197121262550354,
      "learning_rate": 0.0003393649709798566,
      "loss": 0.2819,
      "step": 445
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.26434674859046936,
      "learning_rate": 0.0003392284055991806,
      "loss": 0.3649,
      "step": 446
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.2117290496826172,
      "learning_rate": 0.00033909184021850466,
      "loss": 0.3086,
      "step": 447
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2356727421283722,
      "learning_rate": 0.00033895527483782865,
      "loss": 0.2908,
      "step": 448
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2894708216190338,
      "learning_rate": 0.0003388187094571526,
      "loss": 0.3109,
      "step": 449
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2802561819553375,
      "learning_rate": 0.00033868214407647664,
      "loss": 0.3419,
      "step": 450
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.21933603286743164,
      "learning_rate": 0.00033854557869580064,
      "loss": 0.2609,
      "step": 451
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.2017894983291626,
      "learning_rate": 0.00033840901331512463,
      "loss": 0.2575,
      "step": 452
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.20970788598060608,
      "learning_rate": 0.0003382724479344487,
      "loss": 0.3213,
      "step": 453
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.22622358798980713,
      "learning_rate": 0.0003381358825537726,
      "loss": 0.3154,
      "step": 454
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.20292894542217255,
      "learning_rate": 0.0003379993171730966,
      "loss": 0.2695,
      "step": 455
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.21411782503128052,
      "learning_rate": 0.0003378627517924206,
      "loss": 0.3132,
      "step": 456
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.2978256344795227,
      "learning_rate": 0.00033772618641174465,
      "loss": 0.3191,
      "step": 457
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.28505149483680725,
      "learning_rate": 0.00033758962103106865,
      "loss": 0.3431,
      "step": 458
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.29751160740852356,
      "learning_rate": 0.00033745305565039264,
      "loss": 0.342,
      "step": 459
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.22977152466773987,
      "learning_rate": 0.00033731649026971664,
      "loss": 0.298,
      "step": 460
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.18935450911521912,
      "learning_rate": 0.00033717992488904063,
      "loss": 0.3123,
      "step": 461
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.23792827129364014,
      "learning_rate": 0.0003370433595083646,
      "loss": 0.2989,
      "step": 462
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.20273086428642273,
      "learning_rate": 0.0003369067941276887,
      "loss": 0.3033,
      "step": 463
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.2046014666557312,
      "learning_rate": 0.00033677022874701267,
      "loss": 0.298,
      "step": 464
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.22221295535564423,
      "learning_rate": 0.00033663366336633666,
      "loss": 0.2824,
      "step": 465
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.23686303198337555,
      "learning_rate": 0.00033649709798566066,
      "loss": 0.3344,
      "step": 466
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.22441580891609192,
      "learning_rate": 0.00033636053260498465,
      "loss": 0.3016,
      "step": 467
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.23785005509853363,
      "learning_rate": 0.00033622396722430864,
      "loss": 0.2959,
      "step": 468
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2760114371776581,
      "learning_rate": 0.0003360874018436327,
      "loss": 0.3011,
      "step": 469
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2698655426502228,
      "learning_rate": 0.0003359508364629567,
      "loss": 0.3742,
      "step": 470
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.24856457114219666,
      "learning_rate": 0.0003358142710822806,
      "loss": 0.2879,
      "step": 471
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.2138814479112625,
      "learning_rate": 0.0003356777057016046,
      "loss": 0.2859,
      "step": 472
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.21407762169837952,
      "learning_rate": 0.00033554114032092867,
      "loss": 0.3243,
      "step": 473
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.2208736091852188,
      "learning_rate": 0.00033540457494025266,
      "loss": 0.3095,
      "step": 474
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.21401436626911163,
      "learning_rate": 0.00033526800955957666,
      "loss": 0.3483,
      "step": 475
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.21205928921699524,
      "learning_rate": 0.00033513144417890065,
      "loss": 0.3197,
      "step": 476
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.21503736078739166,
      "learning_rate": 0.00033499487879822465,
      "loss": 0.3251,
      "step": 477
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.19942706823349,
      "learning_rate": 0.00033485831341754864,
      "loss": 0.3062,
      "step": 478
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.22622978687286377,
      "learning_rate": 0.0003347217480368727,
      "loss": 0.314,
      "step": 479
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.23547393083572388,
      "learning_rate": 0.0003345851826561967,
      "loss": 0.2996,
      "step": 480
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.2636096179485321,
      "learning_rate": 0.0003344486172755207,
      "loss": 0.3596,
      "step": 481
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.2560253143310547,
      "learning_rate": 0.00033431205189484467,
      "loss": 0.3362,
      "step": 482
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2340826541185379,
      "learning_rate": 0.00033417548651416866,
      "loss": 0.2961,
      "step": 483
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2092929631471634,
      "learning_rate": 0.00033403892113349266,
      "loss": 0.3003,
      "step": 484
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2335752695798874,
      "learning_rate": 0.0003339023557528167,
      "loss": 0.3416,
      "step": 485
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.24169817566871643,
      "learning_rate": 0.0003337657903721407,
      "loss": 0.3562,
      "step": 486
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.2404930740594864,
      "learning_rate": 0.0003336292249914647,
      "loss": 0.36,
      "step": 487
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.2303403615951538,
      "learning_rate": 0.00033349265961078864,
      "loss": 0.2881,
      "step": 488
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.23361048102378845,
      "learning_rate": 0.0003333560942301127,
      "loss": 0.3023,
      "step": 489
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.23842883110046387,
      "learning_rate": 0.0003332195288494367,
      "loss": 0.3118,
      "step": 490
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.21191640198230743,
      "learning_rate": 0.00033308296346876067,
      "loss": 0.2952,
      "step": 491
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1997518390417099,
      "learning_rate": 0.0003329463980880847,
      "loss": 0.3121,
      "step": 492
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.22100260853767395,
      "learning_rate": 0.00033280983270740866,
      "loss": 0.2995,
      "step": 493
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.20040227472782135,
      "learning_rate": 0.00033267326732673265,
      "loss": 0.2794,
      "step": 494
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.24342064559459686,
      "learning_rate": 0.0003325367019460567,
      "loss": 0.2881,
      "step": 495
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.24706287682056427,
      "learning_rate": 0.0003324001365653807,
      "loss": 0.3222,
      "step": 496
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.2307801991701126,
      "learning_rate": 0.0003322635711847047,
      "loss": 0.302,
      "step": 497
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.2536643147468567,
      "learning_rate": 0.00033212700580402874,
      "loss": 0.3103,
      "step": 498
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.23330727219581604,
      "learning_rate": 0.0003319904404233527,
      "loss": 0.3139,
      "step": 499
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.25033849477767944,
      "learning_rate": 0.0003318538750426767,
      "loss": 0.3299,
      "step": 500
    }
  ],
  "logging_steps": 1,
  "max_steps": 2930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 7.115682308586701e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
