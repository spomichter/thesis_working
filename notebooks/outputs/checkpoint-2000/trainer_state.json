{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.820119352088661,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.11932601034641266,
      "learning_rate": 0.0004,
      "loss": 0.8959,
      "step": 1
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.12995079159736633,
      "learning_rate": 0.000399863434619324,
      "loss": 0.9509,
      "step": 2
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1028643399477005,
      "learning_rate": 0.00039972686923864806,
      "loss": 0.8057,
      "step": 3
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.11891897022724152,
      "learning_rate": 0.000399590303857972,
      "loss": 0.781,
      "step": 4
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11693283915519714,
      "learning_rate": 0.000399453738477296,
      "loss": 0.7576,
      "step": 5
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11341890692710876,
      "learning_rate": 0.00039931717309662004,
      "loss": 0.798,
      "step": 6
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.122858926653862,
      "learning_rate": 0.00039918060771594404,
      "loss": 0.7117,
      "step": 7
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12956611812114716,
      "learning_rate": 0.00039904404233526803,
      "loss": 0.6596,
      "step": 8
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.21965965628623962,
      "learning_rate": 0.000398907476954592,
      "loss": 0.6033,
      "step": 9
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1176835373044014,
      "learning_rate": 0.000398770911573916,
      "loss": 0.5973,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11746004223823547,
      "learning_rate": 0.00039863434619324,
      "loss": 0.6031,
      "step": 11
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10500402748584747,
      "learning_rate": 0.000398497780812564,
      "loss": 0.5548,
      "step": 12
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.13920103013515472,
      "learning_rate": 0.00039836121543188806,
      "loss": 0.6046,
      "step": 13
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13967584073543549,
      "learning_rate": 0.00039822465005121205,
      "loss": 0.5541,
      "step": 14
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13367138803005219,
      "learning_rate": 0.00039808808467053605,
      "loss": 0.5453,
      "step": 15
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1382903754711151,
      "learning_rate": 0.00039795151928986004,
      "loss": 0.5255,
      "step": 16
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.16521431505680084,
      "learning_rate": 0.00039781495390918403,
      "loss": 0.5806,
      "step": 17
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.14018790423870087,
      "learning_rate": 0.00039767838852850803,
      "loss": 0.5837,
      "step": 18
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.20510762929916382,
      "learning_rate": 0.0003975418231478321,
      "loss": 0.5877,
      "step": 19
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15951736271381378,
      "learning_rate": 0.00039740525776715607,
      "loss": 0.5098,
      "step": 20
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.18222330510616302,
      "learning_rate": 0.00039726869238648,
      "loss": 0.5985,
      "step": 21
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.12442512810230255,
      "learning_rate": 0.00039713212700580406,
      "loss": 0.5194,
      "step": 22
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1894417256116867,
      "learning_rate": 0.00039699556162512805,
      "loss": 0.5462,
      "step": 23
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.12953850626945496,
      "learning_rate": 0.00039685899624445205,
      "loss": 0.4865,
      "step": 24
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.19135719537734985,
      "learning_rate": 0.0003967224308637761,
      "loss": 0.4825,
      "step": 25
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1669173687696457,
      "learning_rate": 0.00039658586548310004,
      "loss": 0.5047,
      "step": 26
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1852615624666214,
      "learning_rate": 0.00039644930010242403,
      "loss": 0.4946,
      "step": 27
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19344154000282288,
      "learning_rate": 0.000396312734721748,
      "loss": 0.5015,
      "step": 28
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.14693255722522736,
      "learning_rate": 0.00039617616934107207,
      "loss": 0.5102,
      "step": 29
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.15513701736927032,
      "learning_rate": 0.00039603960396039607,
      "loss": 0.5022,
      "step": 30
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.16791105270385742,
      "learning_rate": 0.00039590303857972006,
      "loss": 0.5442,
      "step": 31
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.17000769078731537,
      "learning_rate": 0.00039576647319904405,
      "loss": 0.4718,
      "step": 32
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.15345706045627594,
      "learning_rate": 0.00039562990781836805,
      "loss": 0.4348,
      "step": 33
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.19199515879154205,
      "learning_rate": 0.00039549334243769204,
      "loss": 0.4994,
      "step": 34
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.19298982620239258,
      "learning_rate": 0.0003953567770570161,
      "loss": 0.5367,
      "step": 35
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.18228675425052643,
      "learning_rate": 0.0003952202116763401,
      "loss": 0.4753,
      "step": 36
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.22715966403484344,
      "learning_rate": 0.0003950836462956641,
      "loss": 0.4911,
      "step": 37
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.17330849170684814,
      "learning_rate": 0.0003949470809149881,
      "loss": 0.4644,
      "step": 38
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3439425230026245,
      "learning_rate": 0.00039481051553431207,
      "loss": 0.5084,
      "step": 39
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2567111551761627,
      "learning_rate": 0.00039467395015363606,
      "loss": 0.5116,
      "step": 40
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.20711593329906464,
      "learning_rate": 0.0003945373847729601,
      "loss": 0.4745,
      "step": 41
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.18716032803058624,
      "learning_rate": 0.0003944008193922841,
      "loss": 0.4883,
      "step": 42
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.20658157765865326,
      "learning_rate": 0.00039426425401160804,
      "loss": 0.4738,
      "step": 43
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.19123712182044983,
      "learning_rate": 0.00039412768863093204,
      "loss": 0.4835,
      "step": 44
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.1860593855381012,
      "learning_rate": 0.0003939911232502561,
      "loss": 0.4783,
      "step": 45
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.16982242465019226,
      "learning_rate": 0.0003938545578695801,
      "loss": 0.4701,
      "step": 46
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.19591237604618073,
      "learning_rate": 0.0003937179924889041,
      "loss": 0.4279,
      "step": 47
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2108498215675354,
      "learning_rate": 0.00039358142710822807,
      "loss": 0.4391,
      "step": 48
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.1974157989025116,
      "learning_rate": 0.00039344486172755206,
      "loss": 0.501,
      "step": 49
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.1864587962627411,
      "learning_rate": 0.00039330829634687606,
      "loss": 0.4348,
      "step": 50
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.18650147318840027,
      "learning_rate": 0.0003931717309662001,
      "loss": 0.481,
      "step": 51
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.16282854974269867,
      "learning_rate": 0.0003930351655855241,
      "loss": 0.4605,
      "step": 52
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.18192808330059052,
      "learning_rate": 0.0003928986002048481,
      "loss": 0.4911,
      "step": 53
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.14408214390277863,
      "learning_rate": 0.0003927620348241721,
      "loss": 0.4521,
      "step": 54
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.16893240809440613,
      "learning_rate": 0.0003926254694434961,
      "loss": 0.4622,
      "step": 55
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.20898085832595825,
      "learning_rate": 0.0003924889040628201,
      "loss": 0.4969,
      "step": 56
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.19083088636398315,
      "learning_rate": 0.0003923523386821441,
      "loss": 0.5239,
      "step": 57
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1833944469690323,
      "learning_rate": 0.0003922157733014681,
      "loss": 0.5189,
      "step": 58
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.17402781546115875,
      "learning_rate": 0.0003920792079207921,
      "loss": 0.4416,
      "step": 59
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1983473300933838,
      "learning_rate": 0.00039194264254011605,
      "loss": 0.4058,
      "step": 60
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.198753222823143,
      "learning_rate": 0.0003918060771594401,
      "loss": 0.4304,
      "step": 61
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.19336481392383575,
      "learning_rate": 0.0003916695117787641,
      "loss": 0.4343,
      "step": 62
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.16549089550971985,
      "learning_rate": 0.0003915329463980881,
      "loss": 0.4663,
      "step": 63
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.18489280343055725,
      "learning_rate": 0.00039139638101741214,
      "loss": 0.4779,
      "step": 64
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.17566567659378052,
      "learning_rate": 0.0003912598156367361,
      "loss": 0.4406,
      "step": 65
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1636786162853241,
      "learning_rate": 0.00039112325025606007,
      "loss": 0.432,
      "step": 66
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1571778953075409,
      "learning_rate": 0.0003909866848753841,
      "loss": 0.4013,
      "step": 67
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1813317984342575,
      "learning_rate": 0.0003908501194947081,
      "loss": 0.453,
      "step": 68
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.15979111194610596,
      "learning_rate": 0.0003907135541140321,
      "loss": 0.4955,
      "step": 69
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.18714825809001923,
      "learning_rate": 0.00039057698873335616,
      "loss": 0.3917,
      "step": 70
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.16007860004901886,
      "learning_rate": 0.0003904404233526801,
      "loss": 0.4404,
      "step": 71
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18033036589622498,
      "learning_rate": 0.0003903038579720041,
      "loss": 0.4495,
      "step": 72
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18039646744728088,
      "learning_rate": 0.00039016729259132814,
      "loss": 0.4508,
      "step": 73
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18390505015850067,
      "learning_rate": 0.00039003072721065213,
      "loss": 0.4633,
      "step": 74
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.21328343451023102,
      "learning_rate": 0.00038989416182997613,
      "loss": 0.4402,
      "step": 75
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.20199717581272125,
      "learning_rate": 0.0003897575964493001,
      "loss": 0.4346,
      "step": 76
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.21577580273151398,
      "learning_rate": 0.0003896210310686241,
      "loss": 0.4383,
      "step": 77
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.17391496896743774,
      "learning_rate": 0.0003894844656879481,
      "loss": 0.4184,
      "step": 78
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.17531253397464752,
      "learning_rate": 0.0003893479003072721,
      "loss": 0.5059,
      "step": 79
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.25591975450515747,
      "learning_rate": 0.00038921133492659615,
      "loss": 0.4707,
      "step": 80
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.16724248230457306,
      "learning_rate": 0.00038907476954592015,
      "loss": 0.4205,
      "step": 81
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.18535126745700836,
      "learning_rate": 0.0003889382041652441,
      "loss": 0.4157,
      "step": 82
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1879180371761322,
      "learning_rate": 0.00038880163878456814,
      "loss": 0.4128,
      "step": 83
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.22169995307922363,
      "learning_rate": 0.00038866507340389213,
      "loss": 0.4654,
      "step": 84
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.22645032405853271,
      "learning_rate": 0.0003885285080232161,
      "loss": 0.4889,
      "step": 85
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.17365556955337524,
      "learning_rate": 0.00038839194264254017,
      "loss": 0.467,
      "step": 86
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.21194802224636078,
      "learning_rate": 0.00038825537726186417,
      "loss": 0.3815,
      "step": 87
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.21270978450775146,
      "learning_rate": 0.0003881188118811881,
      "loss": 0.4285,
      "step": 88
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.2029954493045807,
      "learning_rate": 0.00038798224650051215,
      "loss": 0.3947,
      "step": 89
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.17495183646678925,
      "learning_rate": 0.00038784568111983615,
      "loss": 0.3947,
      "step": 90
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.21961523592472076,
      "learning_rate": 0.00038770911573916014,
      "loss": 0.4331,
      "step": 91
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.17954495549201965,
      "learning_rate": 0.00038757255035848414,
      "loss": 0.4189,
      "step": 92
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.18917836248874664,
      "learning_rate": 0.00038743598497780813,
      "loss": 0.4617,
      "step": 93
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1711726039648056,
      "learning_rate": 0.0003872994195971321,
      "loss": 0.3694,
      "step": 94
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.18672242760658264,
      "learning_rate": 0.0003871628542164561,
      "loss": 0.3997,
      "step": 95
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1815706193447113,
      "learning_rate": 0.00038702628883578017,
      "loss": 0.4099,
      "step": 96
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.21121686697006226,
      "learning_rate": 0.00038688972345510416,
      "loss": 0.4231,
      "step": 97
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.24120746552944183,
      "learning_rate": 0.00038675315807442816,
      "loss": 0.4756,
      "step": 98
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.18905414640903473,
      "learning_rate": 0.00038661659269375215,
      "loss": 0.4366,
      "step": 99
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.2789367735385895,
      "learning_rate": 0.00038648002731307614,
      "loss": 0.4429,
      "step": 100
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.17393247783184052,
      "learning_rate": 0.00038634346193240014,
      "loss": 0.4259,
      "step": 101
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1679239571094513,
      "learning_rate": 0.0003862068965517242,
      "loss": 0.3994,
      "step": 102
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.19263914227485657,
      "learning_rate": 0.0003860703311710482,
      "loss": 0.4222,
      "step": 103
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1893499195575714,
      "learning_rate": 0.0003859337657903722,
      "loss": 0.4206,
      "step": 104
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.283657431602478,
      "learning_rate": 0.00038579720040969617,
      "loss": 0.4698,
      "step": 105
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.17698688805103302,
      "learning_rate": 0.00038566063502902016,
      "loss": 0.4357,
      "step": 106
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.20826728641986847,
      "learning_rate": 0.00038552406964834416,
      "loss": 0.3977,
      "step": 107
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1877846121788025,
      "learning_rate": 0.00038538750426766815,
      "loss": 0.4299,
      "step": 108
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.19921369850635529,
      "learning_rate": 0.0003852509388869922,
      "loss": 0.411,
      "step": 109
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.25177013874053955,
      "learning_rate": 0.00038511437350631614,
      "loss": 0.4259,
      "step": 110
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.23400160670280457,
      "learning_rate": 0.00038497780812564013,
      "loss": 0.3981,
      "step": 111
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.20995192229747772,
      "learning_rate": 0.0003848412427449642,
      "loss": 0.3497,
      "step": 112
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.18908075988292694,
      "learning_rate": 0.0003847046773642882,
      "loss": 0.3957,
      "step": 113
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.20198990404605865,
      "learning_rate": 0.00038456811198361217,
      "loss": 0.4369,
      "step": 114
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1864842027425766,
      "learning_rate": 0.00038443154660293616,
      "loss": 0.4417,
      "step": 115
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.20353202521800995,
      "learning_rate": 0.00038429498122226016,
      "loss": 0.4059,
      "step": 116
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.20620527863502502,
      "learning_rate": 0.00038415841584158415,
      "loss": 0.4505,
      "step": 117
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.17421503365039825,
      "learning_rate": 0.0003840218504609082,
      "loss": 0.4064,
      "step": 118
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.2056753933429718,
      "learning_rate": 0.0003838852850802322,
      "loss": 0.4032,
      "step": 119
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.189042329788208,
      "learning_rate": 0.0003837487196995562,
      "loss": 0.4334,
      "step": 120
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.19650782644748688,
      "learning_rate": 0.0003836121543188802,
      "loss": 0.3631,
      "step": 121
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.18814721703529358,
      "learning_rate": 0.0003834755889382042,
      "loss": 0.3932,
      "step": 122
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.17587293684482574,
      "learning_rate": 0.00038333902355752817,
      "loss": 0.4532,
      "step": 123
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.16995179653167725,
      "learning_rate": 0.0003832024581768522,
      "loss": 0.4116,
      "step": 124
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1828056275844574,
      "learning_rate": 0.0003830658927961762,
      "loss": 0.395,
      "step": 125
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.18312714993953705,
      "learning_rate": 0.0003829293274155002,
      "loss": 0.4075,
      "step": 126
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.17621472477912903,
      "learning_rate": 0.00038279276203482415,
      "loss": 0.4385,
      "step": 127
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1863430142402649,
      "learning_rate": 0.0003826561966541482,
      "loss": 0.3993,
      "step": 128
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.19096267223358154,
      "learning_rate": 0.0003825196312734722,
      "loss": 0.3839,
      "step": 129
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.21727265417575836,
      "learning_rate": 0.0003823830658927962,
      "loss": 0.4004,
      "step": 130
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.19263474643230438,
      "learning_rate": 0.00038224650051212023,
      "loss": 0.3918,
      "step": 131
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1866053193807602,
      "learning_rate": 0.0003821099351314442,
      "loss": 0.3859,
      "step": 132
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.18332050740718842,
      "learning_rate": 0.00038197336975076817,
      "loss": 0.4111,
      "step": 133
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.22084063291549683,
      "learning_rate": 0.0003818368043700922,
      "loss": 0.3605,
      "step": 134
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.21410885453224182,
      "learning_rate": 0.0003817002389894162,
      "loss": 0.4081,
      "step": 135
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.2135201394557953,
      "learning_rate": 0.0003815636736087402,
      "loss": 0.4057,
      "step": 136
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.2088382989168167,
      "learning_rate": 0.0003814271082280642,
      "loss": 0.3873,
      "step": 137
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.20540077984333038,
      "learning_rate": 0.0003812905428473882,
      "loss": 0.4035,
      "step": 138
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.20161038637161255,
      "learning_rate": 0.0003811539774667122,
      "loss": 0.4043,
      "step": 139
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.17132288217544556,
      "learning_rate": 0.00038101741208603623,
      "loss": 0.3702,
      "step": 140
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1865415871143341,
      "learning_rate": 0.00038088084670536023,
      "loss": 0.4161,
      "step": 141
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.19205421209335327,
      "learning_rate": 0.0003807442813246842,
      "loss": 0.3748,
      "step": 142
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.17669232189655304,
      "learning_rate": 0.0003806077159440082,
      "loss": 0.395,
      "step": 143
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.2023332417011261,
      "learning_rate": 0.0003804711505633322,
      "loss": 0.37,
      "step": 144
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.18515044450759888,
      "learning_rate": 0.0003803345851826562,
      "loss": 0.3901,
      "step": 145
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2399897426366806,
      "learning_rate": 0.0003801980198019802,
      "loss": 0.4218,
      "step": 146
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2420056313276291,
      "learning_rate": 0.00038006145442130425,
      "loss": 0.412,
      "step": 147
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.23440030217170715,
      "learning_rate": 0.00037992488904062824,
      "loss": 0.364,
      "step": 148
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.20118071138858795,
      "learning_rate": 0.0003797883236599522,
      "loss": 0.4022,
      "step": 149
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1706302911043167,
      "learning_rate": 0.00037965175827927623,
      "loss": 0.3944,
      "step": 150
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.19102372229099274,
      "learning_rate": 0.0003795151928986002,
      "loss": 0.3301,
      "step": 151
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.18222784996032715,
      "learning_rate": 0.0003793786275179242,
      "loss": 0.3984,
      "step": 152
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.17706440389156342,
      "learning_rate": 0.00037924206213724827,
      "loss": 0.4145,
      "step": 153
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.19225913286209106,
      "learning_rate": 0.0003791054967565722,
      "loss": 0.3456,
      "step": 154
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.19951173663139343,
      "learning_rate": 0.0003789689313758962,
      "loss": 0.3633,
      "step": 155
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.21073518693447113,
      "learning_rate": 0.00037883236599522025,
      "loss": 0.3773,
      "step": 156
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.17023064196109772,
      "learning_rate": 0.00037869580061454424,
      "loss": 0.3456,
      "step": 157
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.20859971642494202,
      "learning_rate": 0.00037855923523386824,
      "loss": 0.3543,
      "step": 158
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.23133733868598938,
      "learning_rate": 0.00037842266985319223,
      "loss": 0.3414,
      "step": 159
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1911781132221222,
      "learning_rate": 0.0003782861044725162,
      "loss": 0.3705,
      "step": 160
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.21870696544647217,
      "learning_rate": 0.0003781495390918402,
      "loss": 0.3987,
      "step": 161
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.16268710792064667,
      "learning_rate": 0.0003780129737111642,
      "loss": 0.364,
      "step": 162
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.21182574331760406,
      "learning_rate": 0.00037787640833048826,
      "loss": 0.3685,
      "step": 163
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.19948598742485046,
      "learning_rate": 0.00037773984294981226,
      "loss": 0.3888,
      "step": 164
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.16624271869659424,
      "learning_rate": 0.00037760327756913625,
      "loss": 0.3684,
      "step": 165
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.168888121843338,
      "learning_rate": 0.00037746671218846025,
      "loss": 0.4106,
      "step": 166
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1666525900363922,
      "learning_rate": 0.00037733014680778424,
      "loss": 0.4125,
      "step": 167
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1948082447052002,
      "learning_rate": 0.00037719358142710823,
      "loss": 0.3576,
      "step": 168
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.19242322444915771,
      "learning_rate": 0.0003770570160464323,
      "loss": 0.369,
      "step": 169
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1987505406141281,
      "learning_rate": 0.0003769204506657563,
      "loss": 0.4216,
      "step": 170
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.2443125993013382,
      "learning_rate": 0.0003767838852850802,
      "loss": 0.4162,
      "step": 171
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1850782334804535,
      "learning_rate": 0.00037664731990440426,
      "loss": 0.3304,
      "step": 172
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1918804794549942,
      "learning_rate": 0.00037651075452372826,
      "loss": 0.3673,
      "step": 173
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.22750459611415863,
      "learning_rate": 0.00037637418914305225,
      "loss": 0.4014,
      "step": 174
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.17416325211524963,
      "learning_rate": 0.00037623762376237625,
      "loss": 0.3891,
      "step": 175
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.16330155730247498,
      "learning_rate": 0.00037610105838170024,
      "loss": 0.3864,
      "step": 176
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.18479983508586884,
      "learning_rate": 0.00037596449300102423,
      "loss": 0.3783,
      "step": 177
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.19715462625026703,
      "learning_rate": 0.00037582792762034823,
      "loss": 0.3807,
      "step": 178
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1924590915441513,
      "learning_rate": 0.0003756913622396723,
      "loss": 0.3633,
      "step": 179
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.20747852325439453,
      "learning_rate": 0.00037555479685899627,
      "loss": 0.3715,
      "step": 180
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.2685392200946808,
      "learning_rate": 0.00037541823147832027,
      "loss": 0.4609,
      "step": 181
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.20092441141605377,
      "learning_rate": 0.00037528166609764426,
      "loss": 0.4046,
      "step": 182
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.19370871782302856,
      "learning_rate": 0.00037514510071696825,
      "loss": 0.4211,
      "step": 183
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.17117629945278168,
      "learning_rate": 0.00037500853533629225,
      "loss": 0.3857,
      "step": 184
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1688281148672104,
      "learning_rate": 0.0003748719699556163,
      "loss": 0.3542,
      "step": 185
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.18875424563884735,
      "learning_rate": 0.0003747354045749403,
      "loss": 0.4098,
      "step": 186
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.18127739429473877,
      "learning_rate": 0.0003745988391942643,
      "loss": 0.3278,
      "step": 187
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.17721326649188995,
      "learning_rate": 0.0003744622738135883,
      "loss": 0.3473,
      "step": 188
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1865159273147583,
      "learning_rate": 0.0003743257084329123,
      "loss": 0.3639,
      "step": 189
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.17829829454421997,
      "learning_rate": 0.00037418914305223627,
      "loss": 0.3781,
      "step": 190
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.18134117126464844,
      "learning_rate": 0.00037405257767156026,
      "loss": 0.3628,
      "step": 191
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.19378823041915894,
      "learning_rate": 0.0003739160122908843,
      "loss": 0.4108,
      "step": 192
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.18632633984088898,
      "learning_rate": 0.00037377944691020825,
      "loss": 0.4174,
      "step": 193
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.22484908998012543,
      "learning_rate": 0.00037364288152953224,
      "loss": 0.3919,
      "step": 194
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.17331703007221222,
      "learning_rate": 0.0003735063161488563,
      "loss": 0.3811,
      "step": 195
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16882792115211487,
      "learning_rate": 0.0003733697507681803,
      "loss": 0.382,
      "step": 196
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16708339750766754,
      "learning_rate": 0.0003732331853875043,
      "loss": 0.392,
      "step": 197
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.17704758048057556,
      "learning_rate": 0.0003730966200068283,
      "loss": 0.3711,
      "step": 198
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.16114240884780884,
      "learning_rate": 0.00037296005462615227,
      "loss": 0.3362,
      "step": 199
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.20022638142108917,
      "learning_rate": 0.00037282348924547626,
      "loss": 0.3806,
      "step": 200
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.18744675815105438,
      "learning_rate": 0.0003726869238648003,
      "loss": 0.3319,
      "step": 201
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.21558323502540588,
      "learning_rate": 0.0003725503584841243,
      "loss": 0.3529,
      "step": 202
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.21583403646945953,
      "learning_rate": 0.0003724137931034483,
      "loss": 0.39,
      "step": 203
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.19908298552036285,
      "learning_rate": 0.0003722772277227723,
      "loss": 0.351,
      "step": 204
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1802712231874466,
      "learning_rate": 0.0003721406623420963,
      "loss": 0.4298,
      "step": 205
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.19505298137664795,
      "learning_rate": 0.0003720040969614203,
      "loss": 0.3494,
      "step": 206
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.16028131544589996,
      "learning_rate": 0.0003718675315807443,
      "loss": 0.3365,
      "step": 207
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.17946474254131317,
      "learning_rate": 0.0003717309662000683,
      "loss": 0.3766,
      "step": 208
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1911803036928177,
      "learning_rate": 0.0003715944008193923,
      "loss": 0.3829,
      "step": 209
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.19979660212993622,
      "learning_rate": 0.00037145783543871626,
      "loss": 0.3937,
      "step": 210
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.17798380553722382,
      "learning_rate": 0.0003713212700580403,
      "loss": 0.3842,
      "step": 211
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.19575877487659454,
      "learning_rate": 0.0003711847046773643,
      "loss": 0.375,
      "step": 212
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.19981318712234497,
      "learning_rate": 0.0003710481392966883,
      "loss": 0.3749,
      "step": 213
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.1978575438261032,
      "learning_rate": 0.00037091157391601234,
      "loss": 0.343,
      "step": 214
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.16956236958503723,
      "learning_rate": 0.0003707750085353363,
      "loss": 0.3663,
      "step": 215
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.19567793607711792,
      "learning_rate": 0.0003706384431546603,
      "loss": 0.3659,
      "step": 216
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.18070311844348907,
      "learning_rate": 0.0003705018777739843,
      "loss": 0.3589,
      "step": 217
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.17055091261863708,
      "learning_rate": 0.0003703653123933083,
      "loss": 0.3523,
      "step": 218
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.18255577981472015,
      "learning_rate": 0.0003702287470126323,
      "loss": 0.3442,
      "step": 219
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.2007906138896942,
      "learning_rate": 0.00037009218163195636,
      "loss": 0.3675,
      "step": 220
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.2507295608520508,
      "learning_rate": 0.0003699556162512803,
      "loss": 0.3583,
      "step": 221
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18266668915748596,
      "learning_rate": 0.0003698190508706043,
      "loss": 0.3814,
      "step": 222
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18681594729423523,
      "learning_rate": 0.00036968248548992834,
      "loss": 0.3498,
      "step": 223
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18366739153862,
      "learning_rate": 0.00036954592010925234,
      "loss": 0.3385,
      "step": 224
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.17412066459655762,
      "learning_rate": 0.00036940935472857633,
      "loss": 0.3846,
      "step": 225
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1903606355190277,
      "learning_rate": 0.00036927278934790033,
      "loss": 0.376,
      "step": 226
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1933138221502304,
      "learning_rate": 0.0003691362239672243,
      "loss": 0.3759,
      "step": 227
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.22036446630954742,
      "learning_rate": 0.0003689996585865483,
      "loss": 0.4055,
      "step": 228
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.2663576900959015,
      "learning_rate": 0.0003688630932058723,
      "loss": 0.409,
      "step": 229
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.21347099542617798,
      "learning_rate": 0.00036872652782519636,
      "loss": 0.3664,
      "step": 230
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1852015256881714,
      "learning_rate": 0.00036858996244452035,
      "loss": 0.3758,
      "step": 231
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.19410254061222076,
      "learning_rate": 0.0003684533970638443,
      "loss": 0.3577,
      "step": 232
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1948726326227188,
      "learning_rate": 0.00036831683168316834,
      "loss": 0.3637,
      "step": 233
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.17496037483215332,
      "learning_rate": 0.00036818026630249233,
      "loss": 0.35,
      "step": 234
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.18115025758743286,
      "learning_rate": 0.00036804370092181633,
      "loss": 0.3865,
      "step": 235
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.20185108482837677,
      "learning_rate": 0.0003679071355411404,
      "loss": 0.364,
      "step": 236
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1938481330871582,
      "learning_rate": 0.00036777057016046437,
      "loss": 0.3618,
      "step": 237
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.20931850373744965,
      "learning_rate": 0.0003676340047797883,
      "loss": 0.3573,
      "step": 238
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.18935449421405792,
      "learning_rate": 0.00036749743939911236,
      "loss": 0.4016,
      "step": 239
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.2249639332294464,
      "learning_rate": 0.00036736087401843635,
      "loss": 0.398,
      "step": 240
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.1690995693206787,
      "learning_rate": 0.00036722430863776035,
      "loss": 0.3921,
      "step": 241
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.19712598621845245,
      "learning_rate": 0.00036708774325708434,
      "loss": 0.3927,
      "step": 242
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.19995993375778198,
      "learning_rate": 0.00036695117787640834,
      "loss": 0.3432,
      "step": 243
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.20136070251464844,
      "learning_rate": 0.00036681461249573233,
      "loss": 0.3823,
      "step": 244
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.1755421757698059,
      "learning_rate": 0.0003666780471150563,
      "loss": 0.351,
      "step": 245
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.23074768483638763,
      "learning_rate": 0.00036654148173438037,
      "loss": 0.4405,
      "step": 246
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.17130251228809357,
      "learning_rate": 0.00036640491635370437,
      "loss": 0.3548,
      "step": 247
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.20049941539764404,
      "learning_rate": 0.00036626835097302836,
      "loss": 0.395,
      "step": 248
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.17307546734809875,
      "learning_rate": 0.00036613178559235236,
      "loss": 0.351,
      "step": 249
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.18956033885478973,
      "learning_rate": 0.00036599522021167635,
      "loss": 0.3732,
      "step": 250
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.19508998095989227,
      "learning_rate": 0.00036585865483100034,
      "loss": 0.37,
      "step": 251
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1894523650407791,
      "learning_rate": 0.0003657220894503244,
      "loss": 0.3617,
      "step": 252
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.18485723435878754,
      "learning_rate": 0.0003655855240696484,
      "loss": 0.3227,
      "step": 253
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.19283626973628998,
      "learning_rate": 0.0003654489586889724,
      "loss": 0.3582,
      "step": 254
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.18002986907958984,
      "learning_rate": 0.0003653123933082964,
      "loss": 0.3563,
      "step": 255
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1734979748725891,
      "learning_rate": 0.00036517582792762037,
      "loss": 0.3242,
      "step": 256
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.19178953766822815,
      "learning_rate": 0.00036503926254694436,
      "loss": 0.3241,
      "step": 257
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.20438987016677856,
      "learning_rate": 0.00036490269716626836,
      "loss": 0.3719,
      "step": 258
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.2484029084444046,
      "learning_rate": 0.0003647661317855924,
      "loss": 0.3667,
      "step": 259
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.18747936189174652,
      "learning_rate": 0.00036462956640491634,
      "loss": 0.3318,
      "step": 260
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.19476965069770813,
      "learning_rate": 0.00036449300102424034,
      "loss": 0.3915,
      "step": 261
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.22352959215641022,
      "learning_rate": 0.0003643564356435644,
      "loss": 0.3976,
      "step": 262
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.16797375679016113,
      "learning_rate": 0.0003642198702628884,
      "loss": 0.293,
      "step": 263
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.1924566775560379,
      "learning_rate": 0.0003640833048822124,
      "loss": 0.3432,
      "step": 264
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.19407260417938232,
      "learning_rate": 0.00036394673950153637,
      "loss": 0.352,
      "step": 265
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.18697986006736755,
      "learning_rate": 0.00036381017412086036,
      "loss": 0.3711,
      "step": 266
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.19984957575798035,
      "learning_rate": 0.00036367360874018436,
      "loss": 0.3941,
      "step": 267
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.25614839792251587,
      "learning_rate": 0.0003635370433595084,
      "loss": 0.397,
      "step": 268
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.17615966498851776,
      "learning_rate": 0.0003634004779788324,
      "loss": 0.3398,
      "step": 269
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.16232623159885406,
      "learning_rate": 0.0003632639125981564,
      "loss": 0.3268,
      "step": 270
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.17790842056274414,
      "learning_rate": 0.0003631273472174804,
      "loss": 0.3425,
      "step": 271
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1584029346704483,
      "learning_rate": 0.0003629907818368044,
      "loss": 0.332,
      "step": 272
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.20034293830394745,
      "learning_rate": 0.0003628542164561284,
      "loss": 0.3941,
      "step": 273
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.20284485816955566,
      "learning_rate": 0.00036271765107545237,
      "loss": 0.3626,
      "step": 274
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.18261189758777618,
      "learning_rate": 0.0003625810856947764,
      "loss": 0.3115,
      "step": 275
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.2061653584241867,
      "learning_rate": 0.0003624445203141004,
      "loss": 0.3353,
      "step": 276
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.16379022598266602,
      "learning_rate": 0.00036230795493342435,
      "loss": 0.3147,
      "step": 277
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.18098846077919006,
      "learning_rate": 0.0003621713895527484,
      "loss": 0.3326,
      "step": 278
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.17694753408432007,
      "learning_rate": 0.0003620348241720724,
      "loss": 0.3147,
      "step": 279
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.21474365890026093,
      "learning_rate": 0.0003618982587913964,
      "loss": 0.3502,
      "step": 280
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1938004344701767,
      "learning_rate": 0.00036176169341072044,
      "loss": 0.3297,
      "step": 281
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1779995560646057,
      "learning_rate": 0.0003616251280300444,
      "loss": 0.36,
      "step": 282
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.2481638640165329,
      "learning_rate": 0.00036148856264936837,
      "loss": 0.357,
      "step": 283
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.19048528373241425,
      "learning_rate": 0.0003613519972686924,
      "loss": 0.3478,
      "step": 284
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.2661489248275757,
      "learning_rate": 0.0003612154318880164,
      "loss": 0.3242,
      "step": 285
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.18586614727973938,
      "learning_rate": 0.0003610788665073404,
      "loss": 0.3272,
      "step": 286
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.252966046333313,
      "learning_rate": 0.0003609423011266644,
      "loss": 0.3109,
      "step": 287
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.25187063217163086,
      "learning_rate": 0.0003608057357459884,
      "loss": 0.4313,
      "step": 288
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.2117471545934677,
      "learning_rate": 0.0003606691703653124,
      "loss": 0.3286,
      "step": 289
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.22412477433681488,
      "learning_rate": 0.0003605326049846364,
      "loss": 0.3466,
      "step": 290
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.16692133247852325,
      "learning_rate": 0.00036039603960396043,
      "loss": 0.3204,
      "step": 291
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.18807296454906464,
      "learning_rate": 0.00036025947422328443,
      "loss": 0.36,
      "step": 292
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.21419252455234528,
      "learning_rate": 0.0003601229088426084,
      "loss": 0.4177,
      "step": 293
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1749790906906128,
      "learning_rate": 0.0003599863434619324,
      "loss": 0.3243,
      "step": 294
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18493682146072388,
      "learning_rate": 0.0003598497780812564,
      "loss": 0.3404,
      "step": 295
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21522802114486694,
      "learning_rate": 0.0003597132127005804,
      "loss": 0.3183,
      "step": 296
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.24882280826568604,
      "learning_rate": 0.00035957664731990445,
      "loss": 0.3477,
      "step": 297
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21226254105567932,
      "learning_rate": 0.00035944008193922845,
      "loss": 0.3123,
      "step": 298
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23622505366802216,
      "learning_rate": 0.0003593035165585524,
      "loss": 0.3092,
      "step": 299
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24488712847232819,
      "learning_rate": 0.00035916695117787644,
      "loss": 0.3609,
      "step": 300
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.22958829998970032,
      "learning_rate": 0.00035903038579720043,
      "loss": 0.3381,
      "step": 301
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.19518715143203735,
      "learning_rate": 0.0003588938204165244,
      "loss": 0.3533,
      "step": 302
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.19504888355731964,
      "learning_rate": 0.00035875725503584847,
      "loss": 0.3366,
      "step": 303
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.197079136967659,
      "learning_rate": 0.0003586206896551724,
      "loss": 0.3084,
      "step": 304
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1875862032175064,
      "learning_rate": 0.0003584841242744964,
      "loss": 0.3312,
      "step": 305
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.17808176577091217,
      "learning_rate": 0.0003583475588938204,
      "loss": 0.3024,
      "step": 306
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.2030431032180786,
      "learning_rate": 0.00035821099351314445,
      "loss": 0.3211,
      "step": 307
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.21580669283866882,
      "learning_rate": 0.00035807442813246844,
      "loss": 0.3362,
      "step": 308
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.22665748000144958,
      "learning_rate": 0.00035793786275179244,
      "loss": 0.3744,
      "step": 309
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.26513639092445374,
      "learning_rate": 0.00035780129737111643,
      "loss": 0.3431,
      "step": 310
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.2653314769268036,
      "learning_rate": 0.0003576647319904404,
      "loss": 0.3648,
      "step": 311
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.2110290825366974,
      "learning_rate": 0.0003575281666097644,
      "loss": 0.3355,
      "step": 312
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.21307623386383057,
      "learning_rate": 0.00035739160122908847,
      "loss": 0.3231,
      "step": 313
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.1949010044336319,
      "learning_rate": 0.00035725503584841246,
      "loss": 0.3216,
      "step": 314
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.18773755431175232,
      "learning_rate": 0.00035711847046773646,
      "loss": 0.3268,
      "step": 315
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.21050895750522614,
      "learning_rate": 0.00035698190508706045,
      "loss": 0.3092,
      "step": 316
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.20176264643669128,
      "learning_rate": 0.00035684533970638444,
      "loss": 0.3042,
      "step": 317
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.22255906462669373,
      "learning_rate": 0.00035670877432570844,
      "loss": 0.3286,
      "step": 318
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.24059513211250305,
      "learning_rate": 0.0003565722089450325,
      "loss": 0.3196,
      "step": 319
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.21301156282424927,
      "learning_rate": 0.0003564356435643565,
      "loss": 0.3136,
      "step": 320
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.29737719893455505,
      "learning_rate": 0.0003562990781836804,
      "loss": 0.3965,
      "step": 321
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.2317172735929489,
      "learning_rate": 0.0003561625128030044,
      "loss": 0.3584,
      "step": 322
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.23438389599323273,
      "learning_rate": 0.00035602594742232846,
      "loss": 0.3545,
      "step": 323
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.20273594558238983,
      "learning_rate": 0.00035588938204165246,
      "loss": 0.3382,
      "step": 324
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.24612386524677277,
      "learning_rate": 0.00035575281666097645,
      "loss": 0.3547,
      "step": 325
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.21637634932994843,
      "learning_rate": 0.00035561625128030045,
      "loss": 0.365,
      "step": 326
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.19678835570812225,
      "learning_rate": 0.00035547968589962444,
      "loss": 0.3382,
      "step": 327
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.24516811966896057,
      "learning_rate": 0.00035534312051894843,
      "loss": 0.3723,
      "step": 328
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.18380539119243622,
      "learning_rate": 0.0003552065551382725,
      "loss": 0.3422,
      "step": 329
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.19929836690425873,
      "learning_rate": 0.0003550699897575965,
      "loss": 0.3239,
      "step": 330
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.18697336316108704,
      "learning_rate": 0.00035493342437692047,
      "loss": 0.2937,
      "step": 331
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.17347358167171478,
      "learning_rate": 0.00035479685899624447,
      "loss": 0.3093,
      "step": 332
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.19448332488536835,
      "learning_rate": 0.00035466029361556846,
      "loss": 0.3532,
      "step": 333
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.19622744619846344,
      "learning_rate": 0.00035452372823489245,
      "loss": 0.3364,
      "step": 334
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.20212899148464203,
      "learning_rate": 0.0003543871628542165,
      "loss": 0.332,
      "step": 335
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.17936906218528748,
      "learning_rate": 0.0003542505974735405,
      "loss": 0.278,
      "step": 336
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.23737987875938416,
      "learning_rate": 0.0003541140320928645,
      "loss": 0.3577,
      "step": 337
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.24131621420383453,
      "learning_rate": 0.0003539774667121885,
      "loss": 0.3918,
      "step": 338
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1995277851819992,
      "learning_rate": 0.0003538409013315125,
      "loss": 0.3512,
      "step": 339
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1794193983078003,
      "learning_rate": 0.00035370433595083647,
      "loss": 0.2991,
      "step": 340
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.19475747644901276,
      "learning_rate": 0.00035356777057016047,
      "loss": 0.319,
      "step": 341
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.20989356935024261,
      "learning_rate": 0.0003534312051894845,
      "loss": 0.3302,
      "step": 342
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.23322360217571259,
      "learning_rate": 0.00035329463980880845,
      "loss": 0.334,
      "step": 343
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.22068044543266296,
      "learning_rate": 0.00035315807442813245,
      "loss": 0.3185,
      "step": 344
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.23216703534126282,
      "learning_rate": 0.0003530215090474565,
      "loss": 0.3536,
      "step": 345
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.2448900192975998,
      "learning_rate": 0.0003528849436667805,
      "loss": 0.4075,
      "step": 346
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.20112290978431702,
      "learning_rate": 0.0003527483782861045,
      "loss": 0.3363,
      "step": 347
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.21474134922027588,
      "learning_rate": 0.00035261181290542853,
      "loss": 0.311,
      "step": 348
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.20913651585578918,
      "learning_rate": 0.0003524752475247525,
      "loss": 0.3653,
      "step": 349
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.19747164845466614,
      "learning_rate": 0.00035233868214407647,
      "loss": 0.2868,
      "step": 350
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.23086903989315033,
      "learning_rate": 0.0003522021167634005,
      "loss": 0.3268,
      "step": 351
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.21606570482254028,
      "learning_rate": 0.0003520655513827245,
      "loss": 0.3174,
      "step": 352
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.20444978773593903,
      "learning_rate": 0.0003519289860020485,
      "loss": 0.3217,
      "step": 353
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.2465686947107315,
      "learning_rate": 0.0003517924206213725,
      "loss": 0.3473,
      "step": 354
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.22836992144584656,
      "learning_rate": 0.0003516558552406965,
      "loss": 0.2873,
      "step": 355
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.2218930572271347,
      "learning_rate": 0.0003515192898600205,
      "loss": 0.3336,
      "step": 356
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.2022252380847931,
      "learning_rate": 0.0003513827244793445,
      "loss": 0.3234,
      "step": 357
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.23240654170513153,
      "learning_rate": 0.00035124615909866853,
      "loss": 0.3148,
      "step": 358
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.22239798307418823,
      "learning_rate": 0.0003511095937179925,
      "loss": 0.3216,
      "step": 359
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.2224113494157791,
      "learning_rate": 0.00035097302833731646,
      "loss": 0.3409,
      "step": 360
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.19898109138011932,
      "learning_rate": 0.0003508364629566405,
      "loss": 0.3137,
      "step": 361
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.20596817135810852,
      "learning_rate": 0.0003506998975759645,
      "loss": 0.334,
      "step": 362
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.18799731135368347,
      "learning_rate": 0.0003505633321952885,
      "loss": 0.3147,
      "step": 363
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.18455596268177032,
      "learning_rate": 0.00035042676681461255,
      "loss": 0.2958,
      "step": 364
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.2187097817659378,
      "learning_rate": 0.00035029020143393654,
      "loss": 0.3683,
      "step": 365
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.2159241884946823,
      "learning_rate": 0.0003501536360532605,
      "loss": 0.3344,
      "step": 366
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.20640219748020172,
      "learning_rate": 0.00035001707067258453,
      "loss": 0.3263,
      "step": 367
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.21508823335170746,
      "learning_rate": 0.0003498805052919085,
      "loss": 0.3229,
      "step": 368
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.24084541201591492,
      "learning_rate": 0.0003497439399112325,
      "loss": 0.3392,
      "step": 369
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.23376256227493286,
      "learning_rate": 0.00034960737453055657,
      "loss": 0.3675,
      "step": 370
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.20889417827129364,
      "learning_rate": 0.0003494708091498805,
      "loss": 0.3022,
      "step": 371
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1714739352464676,
      "learning_rate": 0.0003493342437692045,
      "loss": 0.31,
      "step": 372
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.19280219078063965,
      "learning_rate": 0.0003491976783885285,
      "loss": 0.3031,
      "step": 373
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.19822730123996735,
      "learning_rate": 0.00034906111300785254,
      "loss": 0.3435,
      "step": 374
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.21925927698612213,
      "learning_rate": 0.00034892454762717654,
      "loss": 0.3515,
      "step": 375
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.21244312822818756,
      "learning_rate": 0.00034878798224650053,
      "loss": 0.3401,
      "step": 376
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.23074650764465332,
      "learning_rate": 0.0003486514168658245,
      "loss": 0.3356,
      "step": 377
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.22382019460201263,
      "learning_rate": 0.0003485148514851485,
      "loss": 0.3319,
      "step": 378
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.21527686715126038,
      "learning_rate": 0.0003483782861044725,
      "loss": 0.3348,
      "step": 379
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.21716850996017456,
      "learning_rate": 0.00034824172072379656,
      "loss": 0.3042,
      "step": 380
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.26965954899787903,
      "learning_rate": 0.00034810515534312056,
      "loss": 0.3617,
      "step": 381
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.2109793722629547,
      "learning_rate": 0.0003479685899624445,
      "loss": 0.3115,
      "step": 382
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.23406080901622772,
      "learning_rate": 0.00034783202458176855,
      "loss": 0.3562,
      "step": 383
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1885213404893875,
      "learning_rate": 0.00034769545920109254,
      "loss": 0.3125,
      "step": 384
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.20651307702064514,
      "learning_rate": 0.00034755889382041653,
      "loss": 0.3176,
      "step": 385
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.20523285865783691,
      "learning_rate": 0.0003474223284397406,
      "loss": 0.3181,
      "step": 386
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.20894725620746613,
      "learning_rate": 0.0003472857630590646,
      "loss": 0.3556,
      "step": 387
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.18450474739074707,
      "learning_rate": 0.0003471491976783885,
      "loss": 0.3165,
      "step": 388
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.23721225559711456,
      "learning_rate": 0.0003470126322977125,
      "loss": 0.3318,
      "step": 389
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1889929473400116,
      "learning_rate": 0.00034687606691703656,
      "loss": 0.279,
      "step": 390
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.21711833775043488,
      "learning_rate": 0.00034673950153636055,
      "loss": 0.332,
      "step": 391
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.24192307889461517,
      "learning_rate": 0.00034660293615568455,
      "loss": 0.3613,
      "step": 392
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.26290762424468994,
      "learning_rate": 0.00034646637077500854,
      "loss": 0.3123,
      "step": 393
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.22642219066619873,
      "learning_rate": 0.00034632980539433254,
      "loss": 0.3161,
      "step": 394
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.2525891661643982,
      "learning_rate": 0.00034619324001365653,
      "loss": 0.3138,
      "step": 395
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.21142880618572235,
      "learning_rate": 0.0003460566746329806,
      "loss": 0.3353,
      "step": 396
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.18987533450126648,
      "learning_rate": 0.00034592010925230457,
      "loss": 0.3014,
      "step": 397
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.18728755414485931,
      "learning_rate": 0.00034578354387162857,
      "loss": 0.3026,
      "step": 398
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.21900956332683563,
      "learning_rate": 0.00034564697849095256,
      "loss": 0.3904,
      "step": 399
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.24834366142749786,
      "learning_rate": 0.00034551041311027655,
      "loss": 0.3508,
      "step": 400
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.20587611198425293,
      "learning_rate": 0.00034537384772960055,
      "loss": 0.3082,
      "step": 401
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.23933079838752747,
      "learning_rate": 0.0003452372823489246,
      "loss": 0.3478,
      "step": 402
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.18723377585411072,
      "learning_rate": 0.0003451007169682486,
      "loss": 0.2832,
      "step": 403
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.21344821155071259,
      "learning_rate": 0.0003449641515875726,
      "loss": 0.337,
      "step": 404
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.22146761417388916,
      "learning_rate": 0.0003448275862068965,
      "loss": 0.3173,
      "step": 405
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.21174845099449158,
      "learning_rate": 0.0003446910208262206,
      "loss": 0.3551,
      "step": 406
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.24281994998455048,
      "learning_rate": 0.00034455445544554457,
      "loss": 0.3679,
      "step": 407
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.21000364422798157,
      "learning_rate": 0.00034441789006486856,
      "loss": 0.3787,
      "step": 408
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.18209049105644226,
      "learning_rate": 0.0003442813246841926,
      "loss": 0.3194,
      "step": 409
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.23496213555335999,
      "learning_rate": 0.00034414475930351655,
      "loss": 0.3729,
      "step": 410
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1980510652065277,
      "learning_rate": 0.00034400819392284054,
      "loss": 0.344,
      "step": 411
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.20585277676582336,
      "learning_rate": 0.0003438716285421646,
      "loss": 0.3242,
      "step": 412
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.2242691069841385,
      "learning_rate": 0.0003437350631614886,
      "loss": 0.3205,
      "step": 413
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.23390519618988037,
      "learning_rate": 0.0003435984977808126,
      "loss": 0.3585,
      "step": 414
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.2117650955915451,
      "learning_rate": 0.0003434619324001366,
      "loss": 0.3268,
      "step": 415
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.21375177800655365,
      "learning_rate": 0.00034332536701946057,
      "loss": 0.3127,
      "step": 416
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.20376719534397125,
      "learning_rate": 0.00034318880163878456,
      "loss": 0.3235,
      "step": 417
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.20974870026111603,
      "learning_rate": 0.0003430522362581086,
      "loss": 0.3004,
      "step": 418
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.20580217242240906,
      "learning_rate": 0.0003429156708774326,
      "loss": 0.3068,
      "step": 419
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.2302500307559967,
      "learning_rate": 0.0003427791054967566,
      "loss": 0.3041,
      "step": 420
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.22961857914924622,
      "learning_rate": 0.0003426425401160806,
      "loss": 0.3224,
      "step": 421
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.2238655835390091,
      "learning_rate": 0.0003425059747354046,
      "loss": 0.2925,
      "step": 422
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.2443244457244873,
      "learning_rate": 0.0003423694093547286,
      "loss": 0.3017,
      "step": 423
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.21487785875797272,
      "learning_rate": 0.0003422328439740526,
      "loss": 0.3128,
      "step": 424
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.2441122829914093,
      "learning_rate": 0.0003420962785933766,
      "loss": 0.3173,
      "step": 425
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.24611538648605347,
      "learning_rate": 0.0003419597132127006,
      "loss": 0.3416,
      "step": 426
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.22902363538742065,
      "learning_rate": 0.00034182314783202456,
      "loss": 0.3812,
      "step": 427
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.23213110864162445,
      "learning_rate": 0.0003416865824513486,
      "loss": 0.312,
      "step": 428
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.20174476504325867,
      "learning_rate": 0.0003415500170706726,
      "loss": 0.2927,
      "step": 429
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.20617976784706116,
      "learning_rate": 0.0003414134516899966,
      "loss": 0.3195,
      "step": 430
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.21369288861751556,
      "learning_rate": 0.00034127688630932064,
      "loss": 0.3053,
      "step": 431
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.19960172474384308,
      "learning_rate": 0.0003411403209286446,
      "loss": 0.3164,
      "step": 432
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.1865237057209015,
      "learning_rate": 0.0003410037555479686,
      "loss": 0.2988,
      "step": 433
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.2161438763141632,
      "learning_rate": 0.0003408671901672926,
      "loss": 0.3183,
      "step": 434
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.20188391208648682,
      "learning_rate": 0.0003407306247866166,
      "loss": 0.2683,
      "step": 435
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.22893966734409332,
      "learning_rate": 0.0003405940594059406,
      "loss": 0.311,
      "step": 436
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.24851582944393158,
      "learning_rate": 0.0003404574940252646,
      "loss": 0.2843,
      "step": 437
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.2697020173072815,
      "learning_rate": 0.0003403209286445886,
      "loss": 0.345,
      "step": 438
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.2721976935863495,
      "learning_rate": 0.0003401843632639126,
      "loss": 0.3698,
      "step": 439
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.23578594624996185,
      "learning_rate": 0.0003400477978832366,
      "loss": 0.3229,
      "step": 440
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.19231589138507843,
      "learning_rate": 0.00033991123250256064,
      "loss": 0.3193,
      "step": 441
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.2158489227294922,
      "learning_rate": 0.00033977466712188463,
      "loss": 0.3128,
      "step": 442
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.2037849724292755,
      "learning_rate": 0.00033963810174120863,
      "loss": 0.3262,
      "step": 443
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.18851549923419952,
      "learning_rate": 0.0003395015363605326,
      "loss": 0.2829,
      "step": 444
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.19197121262550354,
      "learning_rate": 0.0003393649709798566,
      "loss": 0.2819,
      "step": 445
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.26434674859046936,
      "learning_rate": 0.0003392284055991806,
      "loss": 0.3649,
      "step": 446
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.2117290496826172,
      "learning_rate": 0.00033909184021850466,
      "loss": 0.3086,
      "step": 447
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2356727421283722,
      "learning_rate": 0.00033895527483782865,
      "loss": 0.2908,
      "step": 448
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2894708216190338,
      "learning_rate": 0.0003388187094571526,
      "loss": 0.3109,
      "step": 449
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2802561819553375,
      "learning_rate": 0.00033868214407647664,
      "loss": 0.3419,
      "step": 450
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.21933603286743164,
      "learning_rate": 0.00033854557869580064,
      "loss": 0.2609,
      "step": 451
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.2017894983291626,
      "learning_rate": 0.00033840901331512463,
      "loss": 0.2575,
      "step": 452
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.20970788598060608,
      "learning_rate": 0.0003382724479344487,
      "loss": 0.3213,
      "step": 453
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.22622358798980713,
      "learning_rate": 0.0003381358825537726,
      "loss": 0.3154,
      "step": 454
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.20292894542217255,
      "learning_rate": 0.0003379993171730966,
      "loss": 0.2695,
      "step": 455
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.21411782503128052,
      "learning_rate": 0.0003378627517924206,
      "loss": 0.3132,
      "step": 456
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.2978256344795227,
      "learning_rate": 0.00033772618641174465,
      "loss": 0.3191,
      "step": 457
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.28505149483680725,
      "learning_rate": 0.00033758962103106865,
      "loss": 0.3431,
      "step": 458
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.29751160740852356,
      "learning_rate": 0.00033745305565039264,
      "loss": 0.342,
      "step": 459
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.22977152466773987,
      "learning_rate": 0.00033731649026971664,
      "loss": 0.298,
      "step": 460
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.18935450911521912,
      "learning_rate": 0.00033717992488904063,
      "loss": 0.3123,
      "step": 461
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.23792827129364014,
      "learning_rate": 0.0003370433595083646,
      "loss": 0.2989,
      "step": 462
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.20273086428642273,
      "learning_rate": 0.0003369067941276887,
      "loss": 0.3033,
      "step": 463
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.2046014666557312,
      "learning_rate": 0.00033677022874701267,
      "loss": 0.298,
      "step": 464
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.22221295535564423,
      "learning_rate": 0.00033663366336633666,
      "loss": 0.2824,
      "step": 465
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.23686303198337555,
      "learning_rate": 0.00033649709798566066,
      "loss": 0.3344,
      "step": 466
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.22441580891609192,
      "learning_rate": 0.00033636053260498465,
      "loss": 0.3016,
      "step": 467
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.23785005509853363,
      "learning_rate": 0.00033622396722430864,
      "loss": 0.2959,
      "step": 468
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2760114371776581,
      "learning_rate": 0.0003360874018436327,
      "loss": 0.3011,
      "step": 469
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2698655426502228,
      "learning_rate": 0.0003359508364629567,
      "loss": 0.3742,
      "step": 470
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.24856457114219666,
      "learning_rate": 0.0003358142710822806,
      "loss": 0.2879,
      "step": 471
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.2138814479112625,
      "learning_rate": 0.0003356777057016046,
      "loss": 0.2859,
      "step": 472
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.21407762169837952,
      "learning_rate": 0.00033554114032092867,
      "loss": 0.3243,
      "step": 473
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.2208736091852188,
      "learning_rate": 0.00033540457494025266,
      "loss": 0.3095,
      "step": 474
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.21401436626911163,
      "learning_rate": 0.00033526800955957666,
      "loss": 0.3483,
      "step": 475
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.21205928921699524,
      "learning_rate": 0.00033513144417890065,
      "loss": 0.3197,
      "step": 476
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.21503736078739166,
      "learning_rate": 0.00033499487879822465,
      "loss": 0.3251,
      "step": 477
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.19942706823349,
      "learning_rate": 0.00033485831341754864,
      "loss": 0.3062,
      "step": 478
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.22622978687286377,
      "learning_rate": 0.0003347217480368727,
      "loss": 0.314,
      "step": 479
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.23547393083572388,
      "learning_rate": 0.0003345851826561967,
      "loss": 0.2996,
      "step": 480
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.2636096179485321,
      "learning_rate": 0.0003344486172755207,
      "loss": 0.3596,
      "step": 481
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.2560253143310547,
      "learning_rate": 0.00033431205189484467,
      "loss": 0.3362,
      "step": 482
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2340826541185379,
      "learning_rate": 0.00033417548651416866,
      "loss": 0.2961,
      "step": 483
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2092929631471634,
      "learning_rate": 0.00033403892113349266,
      "loss": 0.3003,
      "step": 484
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2335752695798874,
      "learning_rate": 0.0003339023557528167,
      "loss": 0.3416,
      "step": 485
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.24169817566871643,
      "learning_rate": 0.0003337657903721407,
      "loss": 0.3562,
      "step": 486
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.2404930740594864,
      "learning_rate": 0.0003336292249914647,
      "loss": 0.36,
      "step": 487
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.2303403615951538,
      "learning_rate": 0.00033349265961078864,
      "loss": 0.2881,
      "step": 488
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.23361048102378845,
      "learning_rate": 0.0003333560942301127,
      "loss": 0.3023,
      "step": 489
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.23842883110046387,
      "learning_rate": 0.0003332195288494367,
      "loss": 0.3118,
      "step": 490
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.21191640198230743,
      "learning_rate": 0.00033308296346876067,
      "loss": 0.2952,
      "step": 491
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1997518390417099,
      "learning_rate": 0.0003329463980880847,
      "loss": 0.3121,
      "step": 492
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.22100260853767395,
      "learning_rate": 0.00033280983270740866,
      "loss": 0.2995,
      "step": 493
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.20040227472782135,
      "learning_rate": 0.00033267326732673265,
      "loss": 0.2794,
      "step": 494
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.24342064559459686,
      "learning_rate": 0.0003325367019460567,
      "loss": 0.2881,
      "step": 495
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.24706287682056427,
      "learning_rate": 0.0003324001365653807,
      "loss": 0.3222,
      "step": 496
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.2307801991701126,
      "learning_rate": 0.0003322635711847047,
      "loss": 0.302,
      "step": 497
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.2536643147468567,
      "learning_rate": 0.00033212700580402874,
      "loss": 0.3103,
      "step": 498
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.23330727219581604,
      "learning_rate": 0.0003319904404233527,
      "loss": 0.3139,
      "step": 499
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.25033849477767944,
      "learning_rate": 0.0003318538750426767,
      "loss": 0.3299,
      "step": 500
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.2157747745513916,
      "learning_rate": 0.0003317173096620007,
      "loss": 0.3286,
      "step": 501
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.24722754955291748,
      "learning_rate": 0.0003315807442813247,
      "loss": 0.3528,
      "step": 502
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.2099849134683609,
      "learning_rate": 0.0003314441789006487,
      "loss": 0.2754,
      "step": 503
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.25216421484947205,
      "learning_rate": 0.0003313076135199727,
      "loss": 0.2993,
      "step": 504
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.2387196570634842,
      "learning_rate": 0.0003311710481392967,
      "loss": 0.3358,
      "step": 505
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.2207803875207901,
      "learning_rate": 0.0003310344827586207,
      "loss": 0.3022,
      "step": 506
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.23718354105949402,
      "learning_rate": 0.0003308979173779447,
      "loss": 0.2872,
      "step": 507
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.22435124218463898,
      "learning_rate": 0.00033076135199726873,
      "loss": 0.3053,
      "step": 508
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.22459182143211365,
      "learning_rate": 0.00033062478661659273,
      "loss": 0.2837,
      "step": 509
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.23864047229290009,
      "learning_rate": 0.00033048822123591667,
      "loss": 0.3076,
      "step": 510
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.2538717985153198,
      "learning_rate": 0.0003303516558552407,
      "loss": 0.3137,
      "step": 511
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.21586747467517853,
      "learning_rate": 0.0003302150904745647,
      "loss": 0.2911,
      "step": 512
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.2315429300069809,
      "learning_rate": 0.0003300785250938887,
      "loss": 0.2651,
      "step": 513
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.22632360458374023,
      "learning_rate": 0.00032994195971321275,
      "loss": 0.2836,
      "step": 514
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.2672441601753235,
      "learning_rate": 0.00032980539433253675,
      "loss": 0.3378,
      "step": 515
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.21000726521015167,
      "learning_rate": 0.0003296688289518607,
      "loss": 0.2736,
      "step": 516
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.21258525550365448,
      "learning_rate": 0.00032953226357118474,
      "loss": 0.2708,
      "step": 517
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.21957795321941376,
      "learning_rate": 0.00032939569819050873,
      "loss": 0.2903,
      "step": 518
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.2004522681236267,
      "learning_rate": 0.0003292591328098327,
      "loss": 0.2851,
      "step": 519
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.19407841563224792,
      "learning_rate": 0.0003291225674291567,
      "loss": 0.2544,
      "step": 520
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.22608740627765656,
      "learning_rate": 0.0003289860020484807,
      "loss": 0.3095,
      "step": 521
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.2553013563156128,
      "learning_rate": 0.0003288494366678047,
      "loss": 0.3426,
      "step": 522
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.24679940938949585,
      "learning_rate": 0.0003287128712871287,
      "loss": 0.3162,
      "step": 523
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.21840453147888184,
      "learning_rate": 0.00032857630590645275,
      "loss": 0.2986,
      "step": 524
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.26539304852485657,
      "learning_rate": 0.00032843974052577674,
      "loss": 0.3693,
      "step": 525
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.23466843366622925,
      "learning_rate": 0.00032830317514510074,
      "loss": 0.2956,
      "step": 526
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.2602140009403229,
      "learning_rate": 0.00032816660976442473,
      "loss": 0.3152,
      "step": 527
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.2120136022567749,
      "learning_rate": 0.0003280300443837487,
      "loss": 0.2698,
      "step": 528
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.2200935184955597,
      "learning_rate": 0.0003278934790030727,
      "loss": 0.2849,
      "step": 529
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.24048815667629242,
      "learning_rate": 0.00032775691362239677,
      "loss": 0.2752,
      "step": 530
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.24697589874267578,
      "learning_rate": 0.00032762034824172076,
      "loss": 0.3048,
      "step": 531
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.25353580713272095,
      "learning_rate": 0.00032748378286104476,
      "loss": 0.3104,
      "step": 532
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.22914521396160126,
      "learning_rate": 0.00032734721748036875,
      "loss": 0.2587,
      "step": 533
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.25223249197006226,
      "learning_rate": 0.00032721065209969275,
      "loss": 0.2857,
      "step": 534
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.20144064724445343,
      "learning_rate": 0.00032707408671901674,
      "loss": 0.2587,
      "step": 535
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.2628914415836334,
      "learning_rate": 0.00032693752133834073,
      "loss": 0.3164,
      "step": 536
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.23092570900917053,
      "learning_rate": 0.0003268009559576648,
      "loss": 0.2955,
      "step": 537
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.2483551949262619,
      "learning_rate": 0.0003266643905769887,
      "loss": 0.3197,
      "step": 538
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.24644523859024048,
      "learning_rate": 0.0003265278251963127,
      "loss": 0.2975,
      "step": 539
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.2311246246099472,
      "learning_rate": 0.00032639125981563676,
      "loss": 0.3007,
      "step": 540
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.2329186201095581,
      "learning_rate": 0.00032625469443496076,
      "loss": 0.2746,
      "step": 541
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.253858357667923,
      "learning_rate": 0.00032611812905428475,
      "loss": 0.2713,
      "step": 542
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.24943000078201294,
      "learning_rate": 0.00032598156367360875,
      "loss": 0.2987,
      "step": 543
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.2607397735118866,
      "learning_rate": 0.00032584499829293274,
      "loss": 0.3128,
      "step": 544
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.21323326230049133,
      "learning_rate": 0.00032570843291225673,
      "loss": 0.2911,
      "step": 545
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.22772394120693207,
      "learning_rate": 0.0003255718675315808,
      "loss": 0.2973,
      "step": 546
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.22225059568881989,
      "learning_rate": 0.0003254353021509048,
      "loss": 0.3252,
      "step": 547
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.23616188764572144,
      "learning_rate": 0.00032529873677022877,
      "loss": 0.3225,
      "step": 548
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.226515531539917,
      "learning_rate": 0.00032516217138955277,
      "loss": 0.3006,
      "step": 549
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.2777732014656067,
      "learning_rate": 0.00032502560600887676,
      "loss": 0.3376,
      "step": 550
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.23271530866622925,
      "learning_rate": 0.00032488904062820075,
      "loss": 0.3051,
      "step": 551
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.26344048976898193,
      "learning_rate": 0.0003247524752475248,
      "loss": 0.3008,
      "step": 552
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.20472854375839233,
      "learning_rate": 0.0003246159098668488,
      "loss": 0.2644,
      "step": 553
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.2197595089673996,
      "learning_rate": 0.0003244793444861728,
      "loss": 0.2784,
      "step": 554
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.29249078035354614,
      "learning_rate": 0.00032434277910549673,
      "loss": 0.3303,
      "step": 555
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.27194032073020935,
      "learning_rate": 0.0003242062137248208,
      "loss": 0.3077,
      "step": 556
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.2777726948261261,
      "learning_rate": 0.0003240696483441448,
      "loss": 0.3073,
      "step": 557
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.27145203948020935,
      "learning_rate": 0.00032393308296346877,
      "loss": 0.3358,
      "step": 558
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.22894646227359772,
      "learning_rate": 0.0003237965175827928,
      "loss": 0.274,
      "step": 559
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.2698633372783661,
      "learning_rate": 0.00032365995220211676,
      "loss": 0.3112,
      "step": 560
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.20423170924186707,
      "learning_rate": 0.00032352338682144075,
      "loss": 0.2698,
      "step": 561
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.22150705754756927,
      "learning_rate": 0.0003233868214407648,
      "loss": 0.2845,
      "step": 562
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.2498629093170166,
      "learning_rate": 0.0003232502560600888,
      "loss": 0.2854,
      "step": 563
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.24699947237968445,
      "learning_rate": 0.0003231136906794128,
      "loss": 0.2792,
      "step": 564
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.29410219192504883,
      "learning_rate": 0.0003229771252987368,
      "loss": 0.2915,
      "step": 565
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.24067720770835876,
      "learning_rate": 0.0003228405599180608,
      "loss": 0.2697,
      "step": 566
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.23433727025985718,
      "learning_rate": 0.00032270399453738477,
      "loss": 0.2973,
      "step": 567
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.22253163158893585,
      "learning_rate": 0.0003225674291567088,
      "loss": 0.2654,
      "step": 568
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.260884165763855,
      "learning_rate": 0.0003224308637760328,
      "loss": 0.2877,
      "step": 569
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.26322606205940247,
      "learning_rate": 0.0003222942983953568,
      "loss": 0.2949,
      "step": 570
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.2531607449054718,
      "learning_rate": 0.0003221577330146808,
      "loss": 0.2831,
      "step": 571
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.2755001187324524,
      "learning_rate": 0.0003220211676340048,
      "loss": 0.3091,
      "step": 572
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.25070714950561523,
      "learning_rate": 0.0003218846022533288,
      "loss": 0.3104,
      "step": 573
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.21333590149879456,
      "learning_rate": 0.0003217480368726528,
      "loss": 0.2738,
      "step": 574
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.23027096688747406,
      "learning_rate": 0.00032161147149197683,
      "loss": 0.2718,
      "step": 575
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.24842569231987,
      "learning_rate": 0.0003214749061113008,
      "loss": 0.306,
      "step": 576
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.26059767603874207,
      "learning_rate": 0.00032133834073062476,
      "loss": 0.3247,
      "step": 577
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.24429315328598022,
      "learning_rate": 0.0003212017753499488,
      "loss": 0.2858,
      "step": 578
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.23248037695884705,
      "learning_rate": 0.0003210652099692728,
      "loss": 0.2937,
      "step": 579
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.24480308592319489,
      "learning_rate": 0.0003209286445885968,
      "loss": 0.2705,
      "step": 580
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.2592727243900299,
      "learning_rate": 0.00032079207920792085,
      "loss": 0.2723,
      "step": 581
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.3040045499801636,
      "learning_rate": 0.0003206555138272448,
      "loss": 0.3344,
      "step": 582
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.2486877590417862,
      "learning_rate": 0.0003205189484465688,
      "loss": 0.2937,
      "step": 583
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.291645348072052,
      "learning_rate": 0.00032038238306589283,
      "loss": 0.2812,
      "step": 584
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.22450725734233856,
      "learning_rate": 0.0003202458176852168,
      "loss": 0.2687,
      "step": 585
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.23074780404567719,
      "learning_rate": 0.0003201092523045408,
      "loss": 0.2607,
      "step": 586
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2545883059501648,
      "learning_rate": 0.0003199726869238648,
      "loss": 0.2747,
      "step": 587
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.23479263484477997,
      "learning_rate": 0.0003198361215431888,
      "loss": 0.2426,
      "step": 588
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26226720213890076,
      "learning_rate": 0.0003196995561625128,
      "loss": 0.2492,
      "step": 589
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.32191288471221924,
      "learning_rate": 0.0003195629907818368,
      "loss": 0.2697,
      "step": 590
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2786462604999542,
      "learning_rate": 0.00031942642540116084,
      "loss": 0.2388,
      "step": 591
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.32363754510879517,
      "learning_rate": 0.00031928986002048484,
      "loss": 0.2911,
      "step": 592
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2995135486125946,
      "learning_rate": 0.00031915329463980883,
      "loss": 0.2821,
      "step": 593
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.2548411786556244,
      "learning_rate": 0.00031901672925913283,
      "loss": 0.2705,
      "step": 594
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.2622937262058258,
      "learning_rate": 0.0003188801638784568,
      "loss": 0.2637,
      "step": 595
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.22986482083797455,
      "learning_rate": 0.0003187435984977808,
      "loss": 0.2369,
      "step": 596
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.24805472791194916,
      "learning_rate": 0.00031860703311710486,
      "loss": 0.2636,
      "step": 597
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.24748413264751434,
      "learning_rate": 0.00031847046773642886,
      "loss": 0.2378,
      "step": 598
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.2822194993495941,
      "learning_rate": 0.0003183339023557528,
      "loss": 0.2636,
      "step": 599
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.28365758061408997,
      "learning_rate": 0.00031819733697507685,
      "loss": 0.2585,
      "step": 600
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.31404346227645874,
      "learning_rate": 0.00031806077159440084,
      "loss": 0.2571,
      "step": 601
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.30190208554267883,
      "learning_rate": 0.00031792420621372483,
      "loss": 0.267,
      "step": 602
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.3302168548107147,
      "learning_rate": 0.00031778764083304883,
      "loss": 0.2702,
      "step": 603
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.3031648099422455,
      "learning_rate": 0.0003176510754523728,
      "loss": 0.2824,
      "step": 604
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.30199965834617615,
      "learning_rate": 0.0003175145100716968,
      "loss": 0.2681,
      "step": 605
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.2609722316265106,
      "learning_rate": 0.0003173779446910208,
      "loss": 0.2647,
      "step": 606
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.24228164553642273,
      "learning_rate": 0.00031724137931034486,
      "loss": 0.2591,
      "step": 607
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.23881682753562927,
      "learning_rate": 0.00031710481392966885,
      "loss": 0.2157,
      "step": 608
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.28731048107147217,
      "learning_rate": 0.00031696824854899285,
      "loss": 0.2697,
      "step": 609
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.303299218416214,
      "learning_rate": 0.00031683168316831684,
      "loss": 0.2759,
      "step": 610
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.30895745754241943,
      "learning_rate": 0.00031669511778764084,
      "loss": 0.2786,
      "step": 611
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.27508968114852905,
      "learning_rate": 0.00031655855240696483,
      "loss": 0.2549,
      "step": 612
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.2568661570549011,
      "learning_rate": 0.0003164219870262889,
      "loss": 0.2403,
      "step": 613
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.28074145317077637,
      "learning_rate": 0.00031628542164561287,
      "loss": 0.2315,
      "step": 614
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.24714379012584686,
      "learning_rate": 0.00031614885626493687,
      "loss": 0.2242,
      "step": 615
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.32963407039642334,
      "learning_rate": 0.00031601229088426086,
      "loss": 0.2765,
      "step": 616
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.3279256224632263,
      "learning_rate": 0.00031587572550358486,
      "loss": 0.2933,
      "step": 617
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.28644028306007385,
      "learning_rate": 0.00031573916012290885,
      "loss": 0.2803,
      "step": 618
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.28528892993927,
      "learning_rate": 0.00031560259474223284,
      "loss": 0.2875,
      "step": 619
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.2486429065465927,
      "learning_rate": 0.0003154660293615569,
      "loss": 0.2468,
      "step": 620
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.2676497995853424,
      "learning_rate": 0.00031532946398088083,
      "loss": 0.2454,
      "step": 621
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.2713560461997986,
      "learning_rate": 0.0003151928986002048,
      "loss": 0.2564,
      "step": 622
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.2803455591201782,
      "learning_rate": 0.0003150563332195289,
      "loss": 0.2607,
      "step": 623
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.2626256048679352,
      "learning_rate": 0.00031491976783885287,
      "loss": 0.2485,
      "step": 624
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.3161276876926422,
      "learning_rate": 0.00031478320245817686,
      "loss": 0.2538,
      "step": 625
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.29687508940696716,
      "learning_rate": 0.00031464663707750086,
      "loss": 0.2382,
      "step": 626
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.3442644476890564,
      "learning_rate": 0.00031451007169682485,
      "loss": 0.2692,
      "step": 627
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.3355252742767334,
      "learning_rate": 0.00031437350631614884,
      "loss": 0.2888,
      "step": 628
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.2590068280696869,
      "learning_rate": 0.0003142369409354729,
      "loss": 0.2425,
      "step": 629
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.2568148076534271,
      "learning_rate": 0.0003141003755547969,
      "loss": 0.2341,
      "step": 630
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.2782413959503174,
      "learning_rate": 0.0003139638101741209,
      "loss": 0.2554,
      "step": 631
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.2784276604652405,
      "learning_rate": 0.0003138272447934449,
      "loss": 0.2816,
      "step": 632
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.304522305727005,
      "learning_rate": 0.00031369067941276887,
      "loss": 0.2946,
      "step": 633
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.27047568559646606,
      "learning_rate": 0.00031355411403209286,
      "loss": 0.2604,
      "step": 634
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.26798924803733826,
      "learning_rate": 0.00031341754865141686,
      "loss": 0.2788,
      "step": 635
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.29893046617507935,
      "learning_rate": 0.0003132809832707409,
      "loss": 0.2736,
      "step": 636
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.2836349606513977,
      "learning_rate": 0.0003131444178900649,
      "loss": 0.2585,
      "step": 637
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.3224533796310425,
      "learning_rate": 0.00031300785250938884,
      "loss": 0.2661,
      "step": 638
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.2459944635629654,
      "learning_rate": 0.0003128712871287129,
      "loss": 0.2407,
      "step": 639
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.255055695772171,
      "learning_rate": 0.0003127347217480369,
      "loss": 0.2456,
      "step": 640
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.2923852205276489,
      "learning_rate": 0.0003125981563673609,
      "loss": 0.2471,
      "step": 641
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.28309422731399536,
      "learning_rate": 0.0003124615909866849,
      "loss": 0.2529,
      "step": 642
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.28973591327667236,
      "learning_rate": 0.00031232502560600887,
      "loss": 0.2577,
      "step": 643
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.29402920603752136,
      "learning_rate": 0.00031218846022533286,
      "loss": 0.2638,
      "step": 644
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.27947381138801575,
      "learning_rate": 0.0003120518948446569,
      "loss": 0.2384,
      "step": 645
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.26717349886894226,
      "learning_rate": 0.0003119153294639809,
      "loss": 0.2245,
      "step": 646
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.36581602692604065,
      "learning_rate": 0.0003117787640833049,
      "loss": 0.2745,
      "step": 647
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.3059908151626587,
      "learning_rate": 0.00031164219870262894,
      "loss": 0.2733,
      "step": 648
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.35893580317497253,
      "learning_rate": 0.0003115056333219529,
      "loss": 0.2511,
      "step": 649
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.2775363624095917,
      "learning_rate": 0.0003113690679412769,
      "loss": 0.2584,
      "step": 650
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.295235812664032,
      "learning_rate": 0.00031123250256060087,
      "loss": 0.2459,
      "step": 651
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.3265732228755951,
      "learning_rate": 0.0003110959371799249,
      "loss": 0.2744,
      "step": 652
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.2942526936531067,
      "learning_rate": 0.0003109593717992489,
      "loss": 0.2437,
      "step": 653
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.32908937335014343,
      "learning_rate": 0.0003108228064185729,
      "loss": 0.2634,
      "step": 654
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.36819320917129517,
      "learning_rate": 0.0003106862410378969,
      "loss": 0.3239,
      "step": 655
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.2666073143482208,
      "learning_rate": 0.0003105496756572209,
      "loss": 0.2268,
      "step": 656
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3843906819820404,
      "learning_rate": 0.0003104131102765449,
      "loss": 0.2783,
      "step": 657
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.2553766369819641,
      "learning_rate": 0.00031027654489586894,
      "loss": 0.2411,
      "step": 658
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.3624238669872284,
      "learning_rate": 0.00031013997951519293,
      "loss": 0.2722,
      "step": 659
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.31297534704208374,
      "learning_rate": 0.0003100034141345169,
      "loss": 0.2706,
      "step": 660
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.31684568524360657,
      "learning_rate": 0.0003098668487538409,
      "loss": 0.2538,
      "step": 661
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.3213319778442383,
      "learning_rate": 0.0003097302833731649,
      "loss": 0.2523,
      "step": 662
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.4779462218284607,
      "learning_rate": 0.0003095937179924889,
      "loss": 0.2927,
      "step": 663
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.3026541471481323,
      "learning_rate": 0.00030945715261181296,
      "loss": 0.2551,
      "step": 664
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.3311305642127991,
      "learning_rate": 0.00030932058723113695,
      "loss": 0.2208,
      "step": 665
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.3042091429233551,
      "learning_rate": 0.0003091840218504609,
      "loss": 0.231,
      "step": 666
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.265809565782547,
      "learning_rate": 0.00030904745646978494,
      "loss": 0.2502,
      "step": 667
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.3381834924221039,
      "learning_rate": 0.00030891089108910894,
      "loss": 0.2285,
      "step": 668
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.35733169317245483,
      "learning_rate": 0.00030877432570843293,
      "loss": 0.28,
      "step": 669
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.2805085778236389,
      "learning_rate": 0.0003086377603277569,
      "loss": 0.2507,
      "step": 670
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.3854765295982361,
      "learning_rate": 0.0003085011949470809,
      "loss": 0.2766,
      "step": 671
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.3840591311454773,
      "learning_rate": 0.0003083646295664049,
      "loss": 0.2768,
      "step": 672
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.29096904397010803,
      "learning_rate": 0.0003082280641857289,
      "loss": 0.2436,
      "step": 673
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.30415967106819153,
      "learning_rate": 0.00030809149880505295,
      "loss": 0.2251,
      "step": 674
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.2738903760910034,
      "learning_rate": 0.00030795493342437695,
      "loss": 0.2451,
      "step": 675
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.2681007981300354,
      "learning_rate": 0.00030781836804370094,
      "loss": 0.2268,
      "step": 676
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.30679404735565186,
      "learning_rate": 0.00030768180266302494,
      "loss": 0.2847,
      "step": 677
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.2807861864566803,
      "learning_rate": 0.00030754523728234893,
      "loss": 0.2263,
      "step": 678
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.33048173785209656,
      "learning_rate": 0.0003074086719016729,
      "loss": 0.2678,
      "step": 679
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.2610887885093689,
      "learning_rate": 0.000307272106520997,
      "loss": 0.2201,
      "step": 680
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.27570798993110657,
      "learning_rate": 0.00030713554114032097,
      "loss": 0.2441,
      "step": 681
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.30896615982055664,
      "learning_rate": 0.00030699897575964496,
      "loss": 0.2555,
      "step": 682
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.2746807336807251,
      "learning_rate": 0.00030686241037896896,
      "loss": 0.2416,
      "step": 683
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.34921547770500183,
      "learning_rate": 0.00030672584499829295,
      "loss": 0.3002,
      "step": 684
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.3305409252643585,
      "learning_rate": 0.00030658927961761694,
      "loss": 0.2758,
      "step": 685
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.3247512876987457,
      "learning_rate": 0.00030645271423694094,
      "loss": 0.2483,
      "step": 686
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.2827194631099701,
      "learning_rate": 0.000306316148856265,
      "loss": 0.251,
      "step": 687
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.2888502776622772,
      "learning_rate": 0.00030617958347558893,
      "loss": 0.2535,
      "step": 688
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.3101057708263397,
      "learning_rate": 0.0003060430180949129,
      "loss": 0.2353,
      "step": 689
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.34698182344436646,
      "learning_rate": 0.00030590645271423697,
      "loss": 0.2497,
      "step": 690
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.27240321040153503,
      "learning_rate": 0.00030576988733356096,
      "loss": 0.2407,
      "step": 691
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.2992326319217682,
      "learning_rate": 0.00030563332195288496,
      "loss": 0.2575,
      "step": 692
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.34528520703315735,
      "learning_rate": 0.00030549675657220895,
      "loss": 0.2733,
      "step": 693
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.27604684233665466,
      "learning_rate": 0.00030536019119153295,
      "loss": 0.2616,
      "step": 694
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.25040870904922485,
      "learning_rate": 0.00030522362581085694,
      "loss": 0.2289,
      "step": 695
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.2581034302711487,
      "learning_rate": 0.000305087060430181,
      "loss": 0.2281,
      "step": 696
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.27292492985725403,
      "learning_rate": 0.000304950495049505,
      "loss": 0.2348,
      "step": 697
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.2997443675994873,
      "learning_rate": 0.000304813929668829,
      "loss": 0.2575,
      "step": 698
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.3166705071926117,
      "learning_rate": 0.00030467736428815297,
      "loss": 0.2651,
      "step": 699
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.3317769467830658,
      "learning_rate": 0.00030454079890747697,
      "loss": 0.2571,
      "step": 700
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.3580833673477173,
      "learning_rate": 0.00030440423352680096,
      "loss": 0.2978,
      "step": 701
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.3152810335159302,
      "learning_rate": 0.00030426766814612495,
      "loss": 0.2732,
      "step": 702
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.290412575006485,
      "learning_rate": 0.000304131102765449,
      "loss": 0.2467,
      "step": 703
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.24854081869125366,
      "learning_rate": 0.000303994537384773,
      "loss": 0.243,
      "step": 704
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.251250684261322,
      "learning_rate": 0.00030385797200409694,
      "loss": 0.2484,
      "step": 705
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.24387232959270477,
      "learning_rate": 0.000303721406623421,
      "loss": 0.2406,
      "step": 706
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.25394347310066223,
      "learning_rate": 0.000303584841242745,
      "loss": 0.2228,
      "step": 707
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.2663169205188751,
      "learning_rate": 0.00030344827586206897,
      "loss": 0.2362,
      "step": 708
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.3247399926185608,
      "learning_rate": 0.000303311710481393,
      "loss": 0.2778,
      "step": 709
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.33574846386909485,
      "learning_rate": 0.00030317514510071696,
      "loss": 0.2594,
      "step": 710
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.409232497215271,
      "learning_rate": 0.00030303857972004096,
      "loss": 0.2642,
      "step": 711
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.30598199367523193,
      "learning_rate": 0.000302902014339365,
      "loss": 0.2354,
      "step": 712
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.3022158145904541,
      "learning_rate": 0.000302765448958689,
      "loss": 0.2427,
      "step": 713
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.29933327436447144,
      "learning_rate": 0.000302628883578013,
      "loss": 0.2441,
      "step": 714
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.25995954871177673,
      "learning_rate": 0.000302492318197337,
      "loss": 0.2218,
      "step": 715
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.2721095085144043,
      "learning_rate": 0.000302355752816661,
      "loss": 0.2136,
      "step": 716
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.3313751518726349,
      "learning_rate": 0.000302219187435985,
      "loss": 0.2405,
      "step": 717
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.31067144870758057,
      "learning_rate": 0.00030208262205530897,
      "loss": 0.2452,
      "step": 718
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.3437124192714691,
      "learning_rate": 0.000301946056674633,
      "loss": 0.2425,
      "step": 719
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.34595808386802673,
      "learning_rate": 0.000301809491293957,
      "loss": 0.2535,
      "step": 720
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.257402628660202,
      "learning_rate": 0.000301672925913281,
      "loss": 0.2009,
      "step": 721
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.2982734441757202,
      "learning_rate": 0.000301536360532605,
      "loss": 0.2296,
      "step": 722
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.3877638578414917,
      "learning_rate": 0.000301399795151929,
      "loss": 0.2951,
      "step": 723
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.2884873151779175,
      "learning_rate": 0.000301263229771253,
      "loss": 0.2408,
      "step": 724
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.28140708804130554,
      "learning_rate": 0.00030112666439057704,
      "loss": 0.2342,
      "step": 725
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.3028900623321533,
      "learning_rate": 0.00030099009900990103,
      "loss": 0.2549,
      "step": 726
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.3004824221134186,
      "learning_rate": 0.00030085353362922497,
      "loss": 0.2295,
      "step": 727
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.34865355491638184,
      "learning_rate": 0.000300716968248549,
      "loss": 0.2497,
      "step": 728
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.31758394837379456,
      "learning_rate": 0.000300580402867873,
      "loss": 0.2412,
      "step": 729
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.3228558301925659,
      "learning_rate": 0.000300443837487197,
      "loss": 0.2548,
      "step": 730
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.2849781811237335,
      "learning_rate": 0.00030030727210652105,
      "loss": 0.2171,
      "step": 731
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.31990668177604675,
      "learning_rate": 0.000300170706725845,
      "loss": 0.2482,
      "step": 732
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.3424624502658844,
      "learning_rate": 0.000300034141345169,
      "loss": 0.2606,
      "step": 733
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.3061659634113312,
      "learning_rate": 0.000299897575964493,
      "loss": 0.2258,
      "step": 734
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.31414079666137695,
      "learning_rate": 0.00029976101058381703,
      "loss": 0.2361,
      "step": 735
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.35448431968688965,
      "learning_rate": 0.000299624445203141,
      "loss": 0.2367,
      "step": 736
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.3284408748149872,
      "learning_rate": 0.000299487879822465,
      "loss": 0.2501,
      "step": 737
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.30347174406051636,
      "learning_rate": 0.000299351314441789,
      "loss": 0.2437,
      "step": 738
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.307405561208725,
      "learning_rate": 0.000299214749061113,
      "loss": 0.2213,
      "step": 739
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.2793098986148834,
      "learning_rate": 0.000299078183680437,
      "loss": 0.2254,
      "step": 740
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.29770147800445557,
      "learning_rate": 0.00029894161829976105,
      "loss": 0.2429,
      "step": 741
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.30253463983535767,
      "learning_rate": 0.00029880505291908504,
      "loss": 0.2317,
      "step": 742
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.3387569189071655,
      "learning_rate": 0.00029866848753840904,
      "loss": 0.267,
      "step": 743
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.3045158088207245,
      "learning_rate": 0.00029853192215773303,
      "loss": 0.2554,
      "step": 744
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.28460338711738586,
      "learning_rate": 0.000298395356777057,
      "loss": 0.2355,
      "step": 745
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.3839372396469116,
      "learning_rate": 0.000298258791396381,
      "loss": 0.2754,
      "step": 746
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.31111642718315125,
      "learning_rate": 0.00029812222601570507,
      "loss": 0.2418,
      "step": 747
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.3175371587276459,
      "learning_rate": 0.00029798566063502906,
      "loss": 0.2695,
      "step": 748
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.29508957266807556,
      "learning_rate": 0.000297849095254353,
      "loss": 0.2235,
      "step": 749
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.30835410952568054,
      "learning_rate": 0.000297712529873677,
      "loss": 0.2414,
      "step": 750
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.3015405833721161,
      "learning_rate": 0.00029757596449300105,
      "loss": 0.2428,
      "step": 751
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.2813645899295807,
      "learning_rate": 0.00029743939911232504,
      "loss": 0.2195,
      "step": 752
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.375727117061615,
      "learning_rate": 0.00029730283373164903,
      "loss": 0.272,
      "step": 753
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.29679930210113525,
      "learning_rate": 0.00029716626835097303,
      "loss": 0.2239,
      "step": 754
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.32407018542289734,
      "learning_rate": 0.000297029702970297,
      "loss": 0.2487,
      "step": 755
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.3077021837234497,
      "learning_rate": 0.000296893137589621,
      "loss": 0.2168,
      "step": 756
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.29967018961906433,
      "learning_rate": 0.00029675657220894506,
      "loss": 0.2255,
      "step": 757
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.2915712594985962,
      "learning_rate": 0.00029662000682826906,
      "loss": 0.237,
      "step": 758
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.30048152804374695,
      "learning_rate": 0.00029648344144759305,
      "loss": 0.2386,
      "step": 759
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.33901247382164,
      "learning_rate": 0.00029634687606691705,
      "loss": 0.2408,
      "step": 760
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.3419017195701599,
      "learning_rate": 0.00029621031068624104,
      "loss": 0.2563,
      "step": 761
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.2807473838329315,
      "learning_rate": 0.00029607374530556504,
      "loss": 0.2121,
      "step": 762
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.3045010268688202,
      "learning_rate": 0.0002959371799248891,
      "loss": 0.236,
      "step": 763
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.40098056197166443,
      "learning_rate": 0.0002958006145442131,
      "loss": 0.2852,
      "step": 764
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.32072681188583374,
      "learning_rate": 0.00029566404916353707,
      "loss": 0.2587,
      "step": 765
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.25665050745010376,
      "learning_rate": 0.00029552748378286107,
      "loss": 0.2168,
      "step": 766
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.331119179725647,
      "learning_rate": 0.00029539091840218506,
      "loss": 0.2753,
      "step": 767
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.3061767816543579,
      "learning_rate": 0.00029525435302150905,
      "loss": 0.2432,
      "step": 768
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.25391489267349243,
      "learning_rate": 0.00029511778764083305,
      "loss": 0.209,
      "step": 769
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.2607884407043457,
      "learning_rate": 0.0002949812222601571,
      "loss": 0.2001,
      "step": 770
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.3020077645778656,
      "learning_rate": 0.00029484465687948104,
      "loss": 0.2128,
      "step": 771
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.2972436547279358,
      "learning_rate": 0.00029470809149880503,
      "loss": 0.2163,
      "step": 772
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.3389706015586853,
      "learning_rate": 0.0002945715261181291,
      "loss": 0.239,
      "step": 773
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.3657676875591278,
      "learning_rate": 0.0002944349607374531,
      "loss": 0.2604,
      "step": 774
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.30844593048095703,
      "learning_rate": 0.00029429839535677707,
      "loss": 0.2204,
      "step": 775
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.40547457337379456,
      "learning_rate": 0.00029416182997610106,
      "loss": 0.267,
      "step": 776
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.3053847551345825,
      "learning_rate": 0.00029402526459542506,
      "loss": 0.2142,
      "step": 777
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.33917510509490967,
      "learning_rate": 0.00029388869921474905,
      "loss": 0.2655,
      "step": 778
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.2928614914417267,
      "learning_rate": 0.0002937521338340731,
      "loss": 0.2176,
      "step": 779
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.33835721015930176,
      "learning_rate": 0.0002936155684533971,
      "loss": 0.2429,
      "step": 780
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.28479239344596863,
      "learning_rate": 0.0002934790030727211,
      "loss": 0.25,
      "step": 781
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.30384114384651184,
      "learning_rate": 0.0002933424376920451,
      "loss": 0.2693,
      "step": 782
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.31234925985336304,
      "learning_rate": 0.0002932058723113691,
      "loss": 0.228,
      "step": 783
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.29555395245552063,
      "learning_rate": 0.00029306930693069307,
      "loss": 0.2324,
      "step": 784
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.3023376762866974,
      "learning_rate": 0.00029293274155001706,
      "loss": 0.2271,
      "step": 785
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.337980717420578,
      "learning_rate": 0.0002927961761693411,
      "loss": 0.2309,
      "step": 786
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.34002307057380676,
      "learning_rate": 0.0002926596107886651,
      "loss": 0.2522,
      "step": 787
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.29265618324279785,
      "learning_rate": 0.00029252304540798905,
      "loss": 0.2241,
      "step": 788
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.31291118264198303,
      "learning_rate": 0.0002923864800273131,
      "loss": 0.2481,
      "step": 789
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.2775956690311432,
      "learning_rate": 0.0002922499146466371,
      "loss": 0.2058,
      "step": 790
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.2999938726425171,
      "learning_rate": 0.0002921133492659611,
      "loss": 0.233,
      "step": 791
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.2878982126712799,
      "learning_rate": 0.00029197678388528513,
      "loss": 0.2262,
      "step": 792
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.32835647463798523,
      "learning_rate": 0.00029184021850460907,
      "loss": 0.2343,
      "step": 793
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.35022467374801636,
      "learning_rate": 0.00029170365312393307,
      "loss": 0.2597,
      "step": 794
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.3087023198604584,
      "learning_rate": 0.0002915670877432571,
      "loss": 0.2295,
      "step": 795
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.289816290140152,
      "learning_rate": 0.0002914305223625811,
      "loss": 0.2306,
      "step": 796
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.2709210515022278,
      "learning_rate": 0.0002912939569819051,
      "loss": 0.225,
      "step": 797
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.27896231412887573,
      "learning_rate": 0.00029115739160122915,
      "loss": 0.2105,
      "step": 798
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.2858116924762726,
      "learning_rate": 0.0002910208262205531,
      "loss": 0.2105,
      "step": 799
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.277883380651474,
      "learning_rate": 0.0002908842608398771,
      "loss": 0.2157,
      "step": 800
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.33724647760391235,
      "learning_rate": 0.0002907476954592011,
      "loss": 0.2287,
      "step": 801
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.3286634385585785,
      "learning_rate": 0.0002906111300785251,
      "loss": 0.2178,
      "step": 802
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.3831334710121155,
      "learning_rate": 0.0002904745646978491,
      "loss": 0.2333,
      "step": 803
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.29567062854766846,
      "learning_rate": 0.0002903379993171731,
      "loss": 0.1906,
      "step": 804
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.3941294550895691,
      "learning_rate": 0.0002902014339364971,
      "loss": 0.2605,
      "step": 805
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.32062381505966187,
      "learning_rate": 0.0002900648685558211,
      "loss": 0.2251,
      "step": 806
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.2895907759666443,
      "learning_rate": 0.0002899283031751451,
      "loss": 0.2225,
      "step": 807
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.3003113269805908,
      "learning_rate": 0.00028979173779446915,
      "loss": 0.229,
      "step": 808
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.3109486997127533,
      "learning_rate": 0.00028965517241379314,
      "loss": 0.271,
      "step": 809
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.27477288246154785,
      "learning_rate": 0.0002895186070331171,
      "loss": 0.2098,
      "step": 810
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.26171064376831055,
      "learning_rate": 0.00028938204165244113,
      "loss": 0.2158,
      "step": 811
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.31512537598609924,
      "learning_rate": 0.0002892454762717651,
      "loss": 0.2542,
      "step": 812
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.2640608549118042,
      "learning_rate": 0.0002891089108910891,
      "loss": 0.2014,
      "step": 813
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.3081047832965851,
      "learning_rate": 0.00028897234551041316,
      "loss": 0.2184,
      "step": 814
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.3164066672325134,
      "learning_rate": 0.00028883578012973716,
      "loss": 0.2097,
      "step": 815
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.37459537386894226,
      "learning_rate": 0.0002886992147490611,
      "loss": 0.225,
      "step": 816
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.385387659072876,
      "learning_rate": 0.0002885626493683851,
      "loss": 0.224,
      "step": 817
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.3204666078090668,
      "learning_rate": 0.00028842608398770914,
      "loss": 0.2188,
      "step": 818
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.2979351282119751,
      "learning_rate": 0.00028828951860703314,
      "loss": 0.1942,
      "step": 819
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.2948337197303772,
      "learning_rate": 0.00028815295322635713,
      "loss": 0.2156,
      "step": 820
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.29753392934799194,
      "learning_rate": 0.0002880163878456811,
      "loss": 0.2009,
      "step": 821
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.3556009531021118,
      "learning_rate": 0.0002878798224650051,
      "loss": 0.2272,
      "step": 822
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.3112938106060028,
      "learning_rate": 0.0002877432570843291,
      "loss": 0.2069,
      "step": 823
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.32406190037727356,
      "learning_rate": 0.00028760669170365316,
      "loss": 0.2376,
      "step": 824
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.28721246123313904,
      "learning_rate": 0.00028747012632297715,
      "loss": 0.2058,
      "step": 825
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.3482193946838379,
      "learning_rate": 0.00028733356094230115,
      "loss": 0.2429,
      "step": 826
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.31544020771980286,
      "learning_rate": 0.00028719699556162514,
      "loss": 0.2124,
      "step": 827
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.3302372395992279,
      "learning_rate": 0.00028706043018094914,
      "loss": 0.2158,
      "step": 828
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.4201676547527313,
      "learning_rate": 0.00028692386480027313,
      "loss": 0.235,
      "step": 829
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.36885708570480347,
      "learning_rate": 0.0002867872994195972,
      "loss": 0.2338,
      "step": 830
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.32017508149147034,
      "learning_rate": 0.0002866507340389212,
      "loss": 0.2322,
      "step": 831
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.29086485505104065,
      "learning_rate": 0.00028651416865824517,
      "loss": 0.2192,
      "step": 832
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.27868613600730896,
      "learning_rate": 0.0002863776032775691,
      "loss": 0.2202,
      "step": 833
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.3060135841369629,
      "learning_rate": 0.00028624103789689316,
      "loss": 0.2256,
      "step": 834
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.37719663977622986,
      "learning_rate": 0.00028610447251621715,
      "loss": 0.2933,
      "step": 835
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.2985701560974121,
      "learning_rate": 0.00028596790713554114,
      "loss": 0.2059,
      "step": 836
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.28321656584739685,
      "learning_rate": 0.0002858313417548652,
      "loss": 0.2138,
      "step": 837
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.35457703471183777,
      "learning_rate": 0.00028569477637418913,
      "loss": 0.2475,
      "step": 838
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.3412846624851227,
      "learning_rate": 0.0002855582109935131,
      "loss": 0.2512,
      "step": 839
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.3182961344718933,
      "learning_rate": 0.0002854216456128372,
      "loss": 0.2417,
      "step": 840
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.3019261360168457,
      "learning_rate": 0.00028528508023216117,
      "loss": 0.2087,
      "step": 841
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.33955439925193787,
      "learning_rate": 0.00028514851485148516,
      "loss": 0.2004,
      "step": 842
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.2843453288078308,
      "learning_rate": 0.00028501194947080916,
      "loss": 0.2051,
      "step": 843
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.33285313844680786,
      "learning_rate": 0.00028487538409013315,
      "loss": 0.2256,
      "step": 844
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.3417319357395172,
      "learning_rate": 0.00028473881870945715,
      "loss": 0.2525,
      "step": 845
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.307253897190094,
      "learning_rate": 0.0002846022533287812,
      "loss": 0.2183,
      "step": 846
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.31560319662094116,
      "learning_rate": 0.0002844656879481052,
      "loss": 0.2245,
      "step": 847
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.30729740858078003,
      "learning_rate": 0.0002843291225674292,
      "loss": 0.24,
      "step": 848
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.3633016049861908,
      "learning_rate": 0.0002841925571867532,
      "loss": 0.2405,
      "step": 849
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.3415476083755493,
      "learning_rate": 0.00028405599180607717,
      "loss": 0.2162,
      "step": 850
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.2885994613170624,
      "learning_rate": 0.00028391942642540116,
      "loss": 0.1985,
      "step": 851
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.3241797983646393,
      "learning_rate": 0.00028378286104472516,
      "loss": 0.2253,
      "step": 852
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.3000405728816986,
      "learning_rate": 0.0002836462956640492,
      "loss": 0.212,
      "step": 853
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.31546875834465027,
      "learning_rate": 0.0002835097302833732,
      "loss": 0.197,
      "step": 854
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.36185017228126526,
      "learning_rate": 0.00028337316490269714,
      "loss": 0.2417,
      "step": 855
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.3032544255256653,
      "learning_rate": 0.0002832365995220212,
      "loss": 0.188,
      "step": 856
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.34311795234680176,
      "learning_rate": 0.0002831000341413452,
      "loss": 0.2197,
      "step": 857
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.36230790615081787,
      "learning_rate": 0.0002829634687606692,
      "loss": 0.2491,
      "step": 858
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.3379611670970917,
      "learning_rate": 0.0002828269033799932,
      "loss": 0.2287,
      "step": 859
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.3311735987663269,
      "learning_rate": 0.00028269033799931717,
      "loss": 0.2269,
      "step": 860
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.44382908940315247,
      "learning_rate": 0.00028255377261864116,
      "loss": 0.2073,
      "step": 861
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.302861750125885,
      "learning_rate": 0.0002824172072379652,
      "loss": 0.2261,
      "step": 862
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.34865373373031616,
      "learning_rate": 0.0002822806418572892,
      "loss": 0.2323,
      "step": 863
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.3242364823818207,
      "learning_rate": 0.0002821440764766132,
      "loss": 0.2334,
      "step": 864
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.3911856412887573,
      "learning_rate": 0.0002820075110959372,
      "loss": 0.2311,
      "step": 865
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.3208194375038147,
      "learning_rate": 0.0002818709457152612,
      "loss": 0.222,
      "step": 866
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.35959184169769287,
      "learning_rate": 0.0002817343803345852,
      "loss": 0.227,
      "step": 867
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.36242541670799255,
      "learning_rate": 0.0002815978149539092,
      "loss": 0.2189,
      "step": 868
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.33084914088249207,
      "learning_rate": 0.0002814612495732332,
      "loss": 0.2055,
      "step": 869
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.3917248249053955,
      "learning_rate": 0.0002813246841925572,
      "loss": 0.2118,
      "step": 870
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.3457864820957184,
      "learning_rate": 0.0002811881188118812,
      "loss": 0.2173,
      "step": 871
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.3480873107910156,
      "learning_rate": 0.0002810515534312052,
      "loss": 0.2106,
      "step": 872
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.3174504041671753,
      "learning_rate": 0.0002809149880505292,
      "loss": 0.1929,
      "step": 873
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.3127475380897522,
      "learning_rate": 0.0002807784226698532,
      "loss": 0.204,
      "step": 874
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.34543007612228394,
      "learning_rate": 0.00028064185728917724,
      "loss": 0.2395,
      "step": 875
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.312093049287796,
      "learning_rate": 0.00028050529190850124,
      "loss": 0.2401,
      "step": 876
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.2829693555831909,
      "learning_rate": 0.0002803687265278252,
      "loss": 0.2174,
      "step": 877
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.3093150854110718,
      "learning_rate": 0.0002802321611471492,
      "loss": 0.2237,
      "step": 878
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.26797592639923096,
      "learning_rate": 0.0002800955957664732,
      "loss": 0.1952,
      "step": 879
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.32668888568878174,
      "learning_rate": 0.0002799590303857972,
      "loss": 0.2307,
      "step": 880
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2911737561225891,
      "learning_rate": 0.00027982246500512126,
      "loss": 0.1613,
      "step": 881
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3687017261981964,
      "learning_rate": 0.0002796858996244452,
      "loss": 0.1786,
      "step": 882
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.36060306429862976,
      "learning_rate": 0.0002795493342437692,
      "loss": 0.1829,
      "step": 883
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.5352655053138733,
      "learning_rate": 0.0002794127688630932,
      "loss": 0.1842,
      "step": 884
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3576361835002899,
      "learning_rate": 0.00027927620348241724,
      "loss": 0.1616,
      "step": 885
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.36187607049942017,
      "learning_rate": 0.00027913963810174123,
      "loss": 0.1793,
      "step": 886
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2912381887435913,
      "learning_rate": 0.0002790030727210652,
      "loss": 0.1438,
      "step": 887
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.3564930856227875,
      "learning_rate": 0.0002788665073403892,
      "loss": 0.163,
      "step": 888
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.37539878487586975,
      "learning_rate": 0.0002787299419597132,
      "loss": 0.1647,
      "step": 889
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.34697988629341125,
      "learning_rate": 0.0002785933765790372,
      "loss": 0.1623,
      "step": 890
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.3390069305896759,
      "learning_rate": 0.00027845681119836126,
      "loss": 0.1649,
      "step": 891
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.42260754108428955,
      "learning_rate": 0.00027832024581768525,
      "loss": 0.1948,
      "step": 892
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.37667495012283325,
      "learning_rate": 0.00027818368043700924,
      "loss": 0.1745,
      "step": 893
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.33015862107276917,
      "learning_rate": 0.00027804711505633324,
      "loss": 0.1706,
      "step": 894
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.41323158144950867,
      "learning_rate": 0.00027791054967565723,
      "loss": 0.1989,
      "step": 895
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.32872530817985535,
      "learning_rate": 0.0002777739842949812,
      "loss": 0.179,
      "step": 896
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.32055896520614624,
      "learning_rate": 0.0002776374189143053,
      "loss": 0.1684,
      "step": 897
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.3418472111225128,
      "learning_rate": 0.00027750085353362927,
      "loss": 0.1767,
      "step": 898
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.43275657296180725,
      "learning_rate": 0.0002773642881529532,
      "loss": 0.1859,
      "step": 899
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.3546399176120758,
      "learning_rate": 0.0002772277227722772,
      "loss": 0.1778,
      "step": 900
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.4182811677455902,
      "learning_rate": 0.00027709115739160125,
      "loss": 0.1915,
      "step": 901
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.4132921099662781,
      "learning_rate": 0.00027695459201092525,
      "loss": 0.1907,
      "step": 902
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.3578316271305084,
      "learning_rate": 0.00027681802663024924,
      "loss": 0.166,
      "step": 903
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.4101463556289673,
      "learning_rate": 0.00027668146124957323,
      "loss": 0.1865,
      "step": 904
    },
    {
      "epoch": 3.09,
      "grad_norm": 0.3503395915031433,
      "learning_rate": 0.00027654489586889723,
      "loss": 0.1871,
      "step": 905
    },
    {
      "epoch": 3.09,
      "grad_norm": 0.30999404191970825,
      "learning_rate": 0.0002764083304882212,
      "loss": 0.1705,
      "step": 906
    },
    {
      "epoch": 3.09,
      "grad_norm": 0.32750338315963745,
      "learning_rate": 0.00027627176510754527,
      "loss": 0.1556,
      "step": 907
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.3421001732349396,
      "learning_rate": 0.00027613519972686926,
      "loss": 0.1814,
      "step": 908
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.41279077529907227,
      "learning_rate": 0.00027599863434619326,
      "loss": 0.1917,
      "step": 909
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.3888916075229645,
      "learning_rate": 0.00027586206896551725,
      "loss": 0.195,
      "step": 910
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.3273974061012268,
      "learning_rate": 0.00027572550358484125,
      "loss": 0.1641,
      "step": 911
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.35132208466529846,
      "learning_rate": 0.00027558893820416524,
      "loss": 0.1896,
      "step": 912
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.3431086540222168,
      "learning_rate": 0.0002754523728234893,
      "loss": 0.186,
      "step": 913
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.3244113326072693,
      "learning_rate": 0.0002753158074428133,
      "loss": 0.1541,
      "step": 914
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.33612948656082153,
      "learning_rate": 0.0002751792420621373,
      "loss": 0.1827,
      "step": 915
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.3407977521419525,
      "learning_rate": 0.0002750426766814612,
      "loss": 0.1584,
      "step": 916
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.3577534258365631,
      "learning_rate": 0.00027490611130078527,
      "loss": 0.1655,
      "step": 917
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.4050396680831909,
      "learning_rate": 0.00027476954592010926,
      "loss": 0.1851,
      "step": 918
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.4126919209957123,
      "learning_rate": 0.00027463298053943325,
      "loss": 0.2033,
      "step": 919
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.3916444182395935,
      "learning_rate": 0.0002744964151587573,
      "loss": 0.1651,
      "step": 920
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.3322475850582123,
      "learning_rate": 0.00027435984977808124,
      "loss": 0.1736,
      "step": 921
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.3390955328941345,
      "learning_rate": 0.00027422328439740524,
      "loss": 0.1576,
      "step": 922
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.36328279972076416,
      "learning_rate": 0.0002740867190167293,
      "loss": 0.1699,
      "step": 923
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.4026196002960205,
      "learning_rate": 0.0002739501536360533,
      "loss": 0.1837,
      "step": 924
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.4087141752243042,
      "learning_rate": 0.0002738135882553773,
      "loss": 0.1813,
      "step": 925
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.376098096370697,
      "learning_rate": 0.00027367702287470127,
      "loss": 0.1868,
      "step": 926
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.3931495249271393,
      "learning_rate": 0.00027354045749402526,
      "loss": 0.1862,
      "step": 927
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.3501856327056885,
      "learning_rate": 0.00027340389211334926,
      "loss": 0.1652,
      "step": 928
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.3527006506919861,
      "learning_rate": 0.0002732673267326733,
      "loss": 0.1895,
      "step": 929
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.34535154700279236,
      "learning_rate": 0.0002731307613519973,
      "loss": 0.1835,
      "step": 930
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.38135215640068054,
      "learning_rate": 0.0002729941959713213,
      "loss": 0.1786,
      "step": 931
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.3445679843425751,
      "learning_rate": 0.0002728576305906453,
      "loss": 0.1778,
      "step": 932
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.323022723197937,
      "learning_rate": 0.0002727210652099693,
      "loss": 0.1586,
      "step": 933
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.3748306334018707,
      "learning_rate": 0.0002725844998292933,
      "loss": 0.178,
      "step": 934
    },
    {
      "epoch": 3.19,
      "grad_norm": 0.36419615149497986,
      "learning_rate": 0.00027244793444861727,
      "loss": 0.1732,
      "step": 935
    },
    {
      "epoch": 3.19,
      "grad_norm": 0.4152122437953949,
      "learning_rate": 0.0002723113690679413,
      "loss": 0.1877,
      "step": 936
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.39021027088165283,
      "learning_rate": 0.0002721748036872653,
      "loss": 0.1787,
      "step": 937
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.3665179908275604,
      "learning_rate": 0.00027203823830658925,
      "loss": 0.178,
      "step": 938
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.36268332600593567,
      "learning_rate": 0.0002719016729259133,
      "loss": 0.174,
      "step": 939
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.3188149034976959,
      "learning_rate": 0.0002717651075452373,
      "loss": 0.1662,
      "step": 940
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.31554487347602844,
      "learning_rate": 0.0002716285421645613,
      "loss": 0.166,
      "step": 941
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.329500287771225,
      "learning_rate": 0.00027149197678388534,
      "loss": 0.1708,
      "step": 942
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.33761778473854065,
      "learning_rate": 0.0002713554114032093,
      "loss": 0.1728,
      "step": 943
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.3661269247531891,
      "learning_rate": 0.00027121884602253327,
      "loss": 0.1841,
      "step": 944
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.3403746485710144,
      "learning_rate": 0.0002710822806418573,
      "loss": 0.147,
      "step": 945
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.3917948603630066,
      "learning_rate": 0.0002709457152611813,
      "loss": 0.1693,
      "step": 946
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.37389424443244934,
      "learning_rate": 0.0002708091498805053,
      "loss": 0.1584,
      "step": 947
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.3504187762737274,
      "learning_rate": 0.0002706725844998293,
      "loss": 0.1555,
      "step": 948
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.37423762679100037,
      "learning_rate": 0.0002705360191191533,
      "loss": 0.1828,
      "step": 949
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.37056103348731995,
      "learning_rate": 0.0002703994537384773,
      "loss": 0.1773,
      "step": 950
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.3522740304470062,
      "learning_rate": 0.0002702628883578013,
      "loss": 0.1615,
      "step": 951
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.32870739698410034,
      "learning_rate": 0.00027012632297712533,
      "loss": 0.1718,
      "step": 952
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.32489290833473206,
      "learning_rate": 0.0002699897575964493,
      "loss": 0.1632,
      "step": 953
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.34444108605384827,
      "learning_rate": 0.0002698531922157733,
      "loss": 0.1589,
      "step": 954
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.3620789051055908,
      "learning_rate": 0.0002697166268350973,
      "loss": 0.1776,
      "step": 955
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.4079180359840393,
      "learning_rate": 0.0002695800614544213,
      "loss": 0.1839,
      "step": 956
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.32887786626815796,
      "learning_rate": 0.0002694434960737453,
      "loss": 0.1541,
      "step": 957
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.365554541349411,
      "learning_rate": 0.00026930693069306935,
      "loss": 0.1674,
      "step": 958
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.33154651522636414,
      "learning_rate": 0.00026917036531239335,
      "loss": 0.1618,
      "step": 959
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.37256842851638794,
      "learning_rate": 0.0002690337999317173,
      "loss": 0.1746,
      "step": 960
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.2974895238876343,
      "learning_rate": 0.00026889723455104133,
      "loss": 0.147,
      "step": 961
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.29883691668510437,
      "learning_rate": 0.00026876066917036533,
      "loss": 0.1332,
      "step": 962
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.4404398798942566,
      "learning_rate": 0.0002686241037896893,
      "loss": 0.1951,
      "step": 963
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.4034886658191681,
      "learning_rate": 0.0002684875384090133,
      "loss": 0.1911,
      "step": 964
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.3069871664047241,
      "learning_rate": 0.00026835097302833736,
      "loss": 0.1435,
      "step": 965
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.3404713273048401,
      "learning_rate": 0.0002682144076476613,
      "loss": 0.1774,
      "step": 966
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.37029045820236206,
      "learning_rate": 0.0002680778422669853,
      "loss": 0.1645,
      "step": 967
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.3861466646194458,
      "learning_rate": 0.00026794127688630935,
      "loss": 0.1765,
      "step": 968
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.386334627866745,
      "learning_rate": 0.00026780471150563334,
      "loss": 0.1942,
      "step": 969
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.35139939188957214,
      "learning_rate": 0.00026766814612495733,
      "loss": 0.1698,
      "step": 970
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.3330991566181183,
      "learning_rate": 0.00026753158074428133,
      "loss": 0.1587,
      "step": 971
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.32738208770751953,
      "learning_rate": 0.0002673950153636053,
      "loss": 0.1615,
      "step": 972
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.3391670286655426,
      "learning_rate": 0.0002672584499829293,
      "loss": 0.1706,
      "step": 973
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.3766893744468689,
      "learning_rate": 0.00026712188460225337,
      "loss": 0.183,
      "step": 974
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.365605890750885,
      "learning_rate": 0.00026698531922157736,
      "loss": 0.1759,
      "step": 975
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.3761231303215027,
      "learning_rate": 0.00026684875384090135,
      "loss": 0.1803,
      "step": 976
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.43626147508621216,
      "learning_rate": 0.00026671218846022535,
      "loss": 0.1778,
      "step": 977
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.3760504424571991,
      "learning_rate": 0.00026657562307954934,
      "loss": 0.1728,
      "step": 978
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.36308005452156067,
      "learning_rate": 0.00026643905769887334,
      "loss": 0.1642,
      "step": 979
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.38514822721481323,
      "learning_rate": 0.0002663024923181974,
      "loss": 0.1806,
      "step": 980
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.38597121834754944,
      "learning_rate": 0.0002661659269375214,
      "loss": 0.1852,
      "step": 981
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.3139248192310333,
      "learning_rate": 0.0002660293615568454,
      "loss": 0.152,
      "step": 982
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.34472227096557617,
      "learning_rate": 0.0002658927961761693,
      "loss": 0.1642,
      "step": 983
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.4206332862377167,
      "learning_rate": 0.00026575623079549336,
      "loss": 0.1941,
      "step": 984
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.34616580605506897,
      "learning_rate": 0.00026561966541481736,
      "loss": 0.1961,
      "step": 985
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.3608883023262024,
      "learning_rate": 0.00026548310003414135,
      "loss": 0.182,
      "step": 986
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.30316489934921265,
      "learning_rate": 0.0002653465346534654,
      "loss": 0.1602,
      "step": 987
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.35452938079833984,
      "learning_rate": 0.00026520996927278934,
      "loss": 0.1753,
      "step": 988
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.3904125988483429,
      "learning_rate": 0.00026507340389211333,
      "loss": 0.2083,
      "step": 989
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.37211379408836365,
      "learning_rate": 0.0002649368385114374,
      "loss": 0.1691,
      "step": 990
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.3076159358024597,
      "learning_rate": 0.0002648002731307614,
      "loss": 0.1664,
      "step": 991
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.36583659052848816,
      "learning_rate": 0.00026466370775008537,
      "loss": 0.1741,
      "step": 992
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.38389262557029724,
      "learning_rate": 0.00026452714236940936,
      "loss": 0.1834,
      "step": 993
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.33549144864082336,
      "learning_rate": 0.00026439057698873336,
      "loss": 0.1653,
      "step": 994
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.3960261940956116,
      "learning_rate": 0.00026425401160805735,
      "loss": 0.1799,
      "step": 995
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.3106428384780884,
      "learning_rate": 0.0002641174462273814,
      "loss": 0.1378,
      "step": 996
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.4138626754283905,
      "learning_rate": 0.0002639808808467054,
      "loss": 0.1743,
      "step": 997
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.42327749729156494,
      "learning_rate": 0.0002638443154660294,
      "loss": 0.1725,
      "step": 998
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.4294850528240204,
      "learning_rate": 0.0002637077500853534,
      "loss": 0.1754,
      "step": 999
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.3817397356033325,
      "learning_rate": 0.0002635711847046774,
      "loss": 0.1596,
      "step": 1000
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.3629986047744751,
      "learning_rate": 0.00026343461932400137,
      "loss": 0.1703,
      "step": 1001
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.33184731006622314,
      "learning_rate": 0.00026329805394332536,
      "loss": 0.1593,
      "step": 1002
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.34640389680862427,
      "learning_rate": 0.0002631614885626494,
      "loss": 0.1572,
      "step": 1003
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.4185563921928406,
      "learning_rate": 0.0002630249231819734,
      "loss": 0.1934,
      "step": 1004
    },
    {
      "epoch": 3.43,
      "grad_norm": 0.35808274149894714,
      "learning_rate": 0.00026288835780129735,
      "loss": 0.1604,
      "step": 1005
    },
    {
      "epoch": 3.43,
      "grad_norm": 0.3085462152957916,
      "learning_rate": 0.0002627517924206214,
      "loss": 0.154,
      "step": 1006
    },
    {
      "epoch": 3.43,
      "grad_norm": 0.37019485235214233,
      "learning_rate": 0.0002626152270399454,
      "loss": 0.1722,
      "step": 1007
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.4001787006855011,
      "learning_rate": 0.0002624786616592694,
      "loss": 0.1886,
      "step": 1008
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.37132009863853455,
      "learning_rate": 0.00026234209627859343,
      "loss": 0.1583,
      "step": 1009
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.3759586811065674,
      "learning_rate": 0.00026220553089791737,
      "loss": 0.1559,
      "step": 1010
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.3872603476047516,
      "learning_rate": 0.00026206896551724137,
      "loss": 0.1593,
      "step": 1011
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.42793846130371094,
      "learning_rate": 0.0002619324001365654,
      "loss": 0.1773,
      "step": 1012
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.41991880536079407,
      "learning_rate": 0.0002617958347558894,
      "loss": 0.1908,
      "step": 1013
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.3740284740924835,
      "learning_rate": 0.0002616592693752134,
      "loss": 0.1916,
      "step": 1014
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.3566155731678009,
      "learning_rate": 0.0002615227039945374,
      "loss": 0.1677,
      "step": 1015
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.36681339144706726,
      "learning_rate": 0.0002613861386138614,
      "loss": 0.1946,
      "step": 1016
    },
    {
      "epoch": 3.47,
      "grad_norm": 0.3362199068069458,
      "learning_rate": 0.0002612495732331854,
      "loss": 0.1749,
      "step": 1017
    },
    {
      "epoch": 3.47,
      "grad_norm": 0.3777890205383301,
      "learning_rate": 0.0002611130078525094,
      "loss": 0.1689,
      "step": 1018
    },
    {
      "epoch": 3.47,
      "grad_norm": 0.36486953496932983,
      "learning_rate": 0.00026097644247183343,
      "loss": 0.1445,
      "step": 1019
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.4320841431617737,
      "learning_rate": 0.0002608398770911574,
      "loss": 0.1873,
      "step": 1020
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.37373948097229004,
      "learning_rate": 0.0002607033117104814,
      "loss": 0.1604,
      "step": 1021
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.3566828668117523,
      "learning_rate": 0.0002605667463298054,
      "loss": 0.164,
      "step": 1022
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.3633231818675995,
      "learning_rate": 0.0002604301809491294,
      "loss": 0.1454,
      "step": 1023
    },
    {
      "epoch": 3.49,
      "grad_norm": 0.4274308681488037,
      "learning_rate": 0.0002602936155684534,
      "loss": 0.1832,
      "step": 1024
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.36405718326568604,
      "learning_rate": 0.00026015705018777745,
      "loss": 0.1665,
      "step": 1025
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.3427641689777374,
      "learning_rate": 0.00026002048480710144,
      "loss": 0.1511,
      "step": 1026
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.34645405411720276,
      "learning_rate": 0.0002598839194264254,
      "loss": 0.1751,
      "step": 1027
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.35835638642311096,
      "learning_rate": 0.00025974735404574943,
      "loss": 0.1676,
      "step": 1028
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.3594391345977783,
      "learning_rate": 0.0002596107886650734,
      "loss": 0.1751,
      "step": 1029
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.43085435032844543,
      "learning_rate": 0.0002594742232843974,
      "loss": 0.1863,
      "step": 1030
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.32559487223625183,
      "learning_rate": 0.0002593376579037214,
      "loss": 0.1657,
      "step": 1031
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.31703299283981323,
      "learning_rate": 0.0002592010925230454,
      "loss": 0.1509,
      "step": 1032
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.329328715801239,
      "learning_rate": 0.0002590645271423694,
      "loss": 0.1577,
      "step": 1033
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.3928058445453644,
      "learning_rate": 0.0002589279617616934,
      "loss": 0.1827,
      "step": 1034
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.34431952238082886,
      "learning_rate": 0.00025879139638101744,
      "loss": 0.1575,
      "step": 1035
    },
    {
      "epoch": 3.53,
      "grad_norm": 0.46435725688934326,
      "learning_rate": 0.00025865483100034144,
      "loss": 0.1834,
      "step": 1036
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.37664994597435,
      "learning_rate": 0.00025851826561966543,
      "loss": 0.1699,
      "step": 1037
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.37631767988204956,
      "learning_rate": 0.0002583817002389894,
      "loss": 0.1639,
      "step": 1038
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.37205561995506287,
      "learning_rate": 0.0002582451348583134,
      "loss": 0.1702,
      "step": 1039
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.33830299973487854,
      "learning_rate": 0.0002581085694776374,
      "loss": 0.1528,
      "step": 1040
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.3643508851528168,
      "learning_rate": 0.00025797200409696146,
      "loss": 0.1734,
      "step": 1041
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.3442721664905548,
      "learning_rate": 0.00025783543871628546,
      "loss": 0.1649,
      "step": 1042
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.31444674730300903,
      "learning_rate": 0.00025769887333560945,
      "loss": 0.142,
      "step": 1043
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.3809274733066559,
      "learning_rate": 0.00025756230795493344,
      "loss": 0.1638,
      "step": 1044
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.3955625891685486,
      "learning_rate": 0.00025742574257425744,
      "loss": 0.1558,
      "step": 1045
    },
    {
      "epoch": 3.57,
      "grad_norm": 0.3090742826461792,
      "learning_rate": 0.00025728917719358143,
      "loss": 0.1315,
      "step": 1046
    },
    {
      "epoch": 3.57,
      "grad_norm": 0.3882386088371277,
      "learning_rate": 0.0002571526118129054,
      "loss": 0.1567,
      "step": 1047
    },
    {
      "epoch": 3.57,
      "grad_norm": 0.34428277611732483,
      "learning_rate": 0.0002570160464322295,
      "loss": 0.1459,
      "step": 1048
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.36404499411582947,
      "learning_rate": 0.0002568794810515534,
      "loss": 0.1559,
      "step": 1049
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.41500943899154663,
      "learning_rate": 0.0002567429156708774,
      "loss": 0.1658,
      "step": 1050
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.3768182694911957,
      "learning_rate": 0.00025660635029020146,
      "loss": 0.1687,
      "step": 1051
    },
    {
      "epoch": 3.59,
      "grad_norm": 0.38860490918159485,
      "learning_rate": 0.00025646978490952545,
      "loss": 0.1595,
      "step": 1052
    },
    {
      "epoch": 3.59,
      "grad_norm": 0.34335529804229736,
      "learning_rate": 0.00025633321952884944,
      "loss": 0.1627,
      "step": 1053
    },
    {
      "epoch": 3.59,
      "grad_norm": 0.36082351207733154,
      "learning_rate": 0.00025619665414817344,
      "loss": 0.1595,
      "step": 1054
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.35502609610557556,
      "learning_rate": 0.00025606008876749743,
      "loss": 0.1675,
      "step": 1055
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.3230530321598053,
      "learning_rate": 0.00025592352338682143,
      "loss": 0.1611,
      "step": 1056
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.352041095495224,
      "learning_rate": 0.0002557869580061455,
      "loss": 0.156,
      "step": 1057
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.33591896295547485,
      "learning_rate": 0.00025565039262546947,
      "loss": 0.1604,
      "step": 1058
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.39666086435317993,
      "learning_rate": 0.00025551382724479346,
      "loss": 0.171,
      "step": 1059
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.32352885603904724,
      "learning_rate": 0.00025537726186411746,
      "loss": 0.141,
      "step": 1060
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.35599127411842346,
      "learning_rate": 0.00025524069648344145,
      "loss": 0.1409,
      "step": 1061
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.3448888957500458,
      "learning_rate": 0.00025510413110276545,
      "loss": 0.1321,
      "step": 1062
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.3970230221748352,
      "learning_rate": 0.00025496756572208944,
      "loss": 0.174,
      "step": 1063
    },
    {
      "epoch": 3.63,
      "grad_norm": 0.3859904706478119,
      "learning_rate": 0.0002548310003414135,
      "loss": 0.162,
      "step": 1064
    },
    {
      "epoch": 3.63,
      "grad_norm": 0.45431312918663025,
      "learning_rate": 0.0002546944349607375,
      "loss": 0.19,
      "step": 1065
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.40570199489593506,
      "learning_rate": 0.0002545578695800614,
      "loss": 0.1778,
      "step": 1066
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.29514139890670776,
      "learning_rate": 0.00025442130419938547,
      "loss": 0.137,
      "step": 1067
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.4131338596343994,
      "learning_rate": 0.00025428473881870947,
      "loss": 0.1829,
      "step": 1068
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.3627215027809143,
      "learning_rate": 0.00025414817343803346,
      "loss": 0.168,
      "step": 1069
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.36570242047309875,
      "learning_rate": 0.0002540116080573575,
      "loss": 0.1814,
      "step": 1070
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.35977673530578613,
      "learning_rate": 0.00025387504267668145,
      "loss": 0.1747,
      "step": 1071
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.32684123516082764,
      "learning_rate": 0.00025373847729600544,
      "loss": 0.1335,
      "step": 1072
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.38243356347084045,
      "learning_rate": 0.0002536019119153295,
      "loss": 0.176,
      "step": 1073
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.3846552073955536,
      "learning_rate": 0.0002534653465346535,
      "loss": 0.1623,
      "step": 1074
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.38130009174346924,
      "learning_rate": 0.0002533287811539775,
      "loss": 0.1539,
      "step": 1075
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.39432498812675476,
      "learning_rate": 0.0002531922157733015,
      "loss": 0.1714,
      "step": 1076
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.3568190932273865,
      "learning_rate": 0.00025305565039262547,
      "loss": 0.1492,
      "step": 1077
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.37407949566841125,
      "learning_rate": 0.00025291908501194946,
      "loss": 0.1569,
      "step": 1078
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.38671618700027466,
      "learning_rate": 0.00025278251963127346,
      "loss": 0.1577,
      "step": 1079
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.32971104979515076,
      "learning_rate": 0.0002526459542505975,
      "loss": 0.1552,
      "step": 1080
    },
    {
      "epoch": 3.69,
      "grad_norm": 0.34972190856933594,
      "learning_rate": 0.0002525093888699215,
      "loss": 0.1631,
      "step": 1081
    },
    {
      "epoch": 3.69,
      "grad_norm": 0.38350269198417664,
      "learning_rate": 0.0002523728234892455,
      "loss": 0.1676,
      "step": 1082
    },
    {
      "epoch": 3.69,
      "grad_norm": 0.34857749938964844,
      "learning_rate": 0.0002522362581085695,
      "loss": 0.1559,
      "step": 1083
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.33727186918258667,
      "learning_rate": 0.0002520996927278935,
      "loss": 0.1496,
      "step": 1084
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.40153875946998596,
      "learning_rate": 0.0002519631273472175,
      "loss": 0.1715,
      "step": 1085
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.3432791829109192,
      "learning_rate": 0.0002518265619665415,
      "loss": 0.1402,
      "step": 1086
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.4188843369483948,
      "learning_rate": 0.0002516899965858655,
      "loss": 0.1635,
      "step": 1087
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.3490216135978699,
      "learning_rate": 0.00025155343120518946,
      "loss": 0.1489,
      "step": 1088
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.3465926945209503,
      "learning_rate": 0.0002514168658245135,
      "loss": 0.1489,
      "step": 1089
    },
    {
      "epoch": 3.72,
      "grad_norm": 0.37719425559043884,
      "learning_rate": 0.0002512803004438375,
      "loss": 0.1535,
      "step": 1090
    },
    {
      "epoch": 3.72,
      "grad_norm": 0.33232593536376953,
      "learning_rate": 0.0002511437350631615,
      "loss": 0.1434,
      "step": 1091
    },
    {
      "epoch": 3.72,
      "grad_norm": 0.3512352406978607,
      "learning_rate": 0.00025100716968248554,
      "loss": 0.1439,
      "step": 1092
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.37342727184295654,
      "learning_rate": 0.00025087060430180954,
      "loss": 0.1431,
      "step": 1093
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.2888205945491791,
      "learning_rate": 0.0002507340389211335,
      "loss": 0.1255,
      "step": 1094
    },
    {
      "epoch": 3.73,
      "grad_norm": 0.3708595335483551,
      "learning_rate": 0.0002505974735404575,
      "loss": 0.1564,
      "step": 1095
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.3968510031700134,
      "learning_rate": 0.0002504609081597815,
      "loss": 0.1512,
      "step": 1096
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.38682061433792114,
      "learning_rate": 0.0002503243427791055,
      "loss": 0.146,
      "step": 1097
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.4059889614582062,
      "learning_rate": 0.0002501877773984295,
      "loss": 0.1517,
      "step": 1098
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.4203929901123047,
      "learning_rate": 0.0002500512120177535,
      "loss": 0.1838,
      "step": 1099
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.3686433434486389,
      "learning_rate": 0.0002499146466370775,
      "loss": 0.174,
      "step": 1100
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.32293492555618286,
      "learning_rate": 0.0002497780812564015,
      "loss": 0.146,
      "step": 1101
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.34223106503486633,
      "learning_rate": 0.00024964151587572554,
      "loss": 0.1598,
      "step": 1102
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.4190748333930969,
      "learning_rate": 0.00024950495049504953,
      "loss": 0.1649,
      "step": 1103
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.3437836468219757,
      "learning_rate": 0.0002493683851143735,
      "loss": 0.1741,
      "step": 1104
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.2949671745300293,
      "learning_rate": 0.0002492318197336975,
      "loss": 0.1432,
      "step": 1105
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.30457019805908203,
      "learning_rate": 0.0002490952543530215,
      "loss": 0.1438,
      "step": 1106
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.31962963938713074,
      "learning_rate": 0.0002489586889723455,
      "loss": 0.1473,
      "step": 1107
    },
    {
      "epoch": 3.78,
      "grad_norm": 0.3690437972545624,
      "learning_rate": 0.00024882212359166956,
      "loss": 0.1486,
      "step": 1108
    },
    {
      "epoch": 3.78,
      "grad_norm": 0.4371497929096222,
      "learning_rate": 0.00024868555821099355,
      "loss": 0.1728,
      "step": 1109
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.38989201188087463,
      "learning_rate": 0.0002485489928303175,
      "loss": 0.1509,
      "step": 1110
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.3559280335903168,
      "learning_rate": 0.00024841242744964154,
      "loss": 0.137,
      "step": 1111
    },
    {
      "epoch": 3.79,
      "grad_norm": 0.38096359372138977,
      "learning_rate": 0.00024827586206896553,
      "loss": 0.1508,
      "step": 1112
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.3649703860282898,
      "learning_rate": 0.0002481392966882895,
      "loss": 0.1709,
      "step": 1113
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.37762463092803955,
      "learning_rate": 0.0002480027313076135,
      "loss": 0.1427,
      "step": 1114
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.31555861234664917,
      "learning_rate": 0.00024786616592693757,
      "loss": 0.1383,
      "step": 1115
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.3671024441719055,
      "learning_rate": 0.0002477296005462615,
      "loss": 0.1523,
      "step": 1116
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.381940633058548,
      "learning_rate": 0.0002475930351655855,
      "loss": 0.1566,
      "step": 1117
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.34536147117614746,
      "learning_rate": 0.00024745646978490955,
      "loss": 0.1327,
      "step": 1118
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.3689875900745392,
      "learning_rate": 0.00024731990440423355,
      "loss": 0.1452,
      "step": 1119
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.36557966470718384,
      "learning_rate": 0.00024718333902355754,
      "loss": 0.1405,
      "step": 1120
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.40611204504966736,
      "learning_rate": 0.00024704677364288153,
      "loss": 0.1631,
      "step": 1121
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.48750707507133484,
      "learning_rate": 0.00024691020826220553,
      "loss": 0.1978,
      "step": 1122
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.42314422130584717,
      "learning_rate": 0.0002467736428815295,
      "loss": 0.1861,
      "step": 1123
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.3630428612232208,
      "learning_rate": 0.00024663707750085357,
      "loss": 0.156,
      "step": 1124
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.3614494800567627,
      "learning_rate": 0.00024650051212017757,
      "loss": 0.1588,
      "step": 1125
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.3009279668331146,
      "learning_rate": 0.00024636394673950156,
      "loss": 0.1568,
      "step": 1126
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.32101866602897644,
      "learning_rate": 0.00024622738135882555,
      "loss": 0.1484,
      "step": 1127
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.3438771069049835,
      "learning_rate": 0.00024609081597814955,
      "loss": 0.1441,
      "step": 1128
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.3521000146865845,
      "learning_rate": 0.00024595425059747354,
      "loss": 0.1521,
      "step": 1129
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.38227248191833496,
      "learning_rate": 0.00024581768521679754,
      "loss": 0.1528,
      "step": 1130
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.4465169608592987,
      "learning_rate": 0.0002456811198361216,
      "loss": 0.1657,
      "step": 1131
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.3788412809371948,
      "learning_rate": 0.0002455445544554456,
      "loss": 0.1459,
      "step": 1132
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.37555691599845886,
      "learning_rate": 0.0002454079890747695,
      "loss": 0.1491,
      "step": 1133
    },
    {
      "epoch": 3.87,
      "grad_norm": 0.42666324973106384,
      "learning_rate": 0.00024527142369409357,
      "loss": 0.1655,
      "step": 1134
    },
    {
      "epoch": 3.87,
      "grad_norm": 0.40419694781303406,
      "learning_rate": 0.00024513485831341756,
      "loss": 0.1573,
      "step": 1135
    },
    {
      "epoch": 3.87,
      "grad_norm": 0.38826629519462585,
      "learning_rate": 0.00024499829293274155,
      "loss": 0.1521,
      "step": 1136
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.32776492834091187,
      "learning_rate": 0.0002448617275520656,
      "loss": 0.1313,
      "step": 1137
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.33157503604888916,
      "learning_rate": 0.00024472516217138954,
      "loss": 0.1427,
      "step": 1138
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.37755727767944336,
      "learning_rate": 0.00024458859679071354,
      "loss": 0.1496,
      "step": 1139
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.3339659869670868,
      "learning_rate": 0.0002444520314100376,
      "loss": 0.1517,
      "step": 1140
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.3460550308227539,
      "learning_rate": 0.0002443154660293616,
      "loss": 0.1404,
      "step": 1141
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.3632008731365204,
      "learning_rate": 0.0002441789006486856,
      "loss": 0.1522,
      "step": 1142
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.40042412281036377,
      "learning_rate": 0.0002440423352680096,
      "loss": 0.1454,
      "step": 1143
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.40733230113983154,
      "learning_rate": 0.0002439057698873336,
      "loss": 0.1608,
      "step": 1144
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.390065461397171,
      "learning_rate": 0.00024376920450665756,
      "loss": 0.1677,
      "step": 1145
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.3377401530742645,
      "learning_rate": 0.00024363263912598155,
      "loss": 0.1472,
      "step": 1146
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.3753320574760437,
      "learning_rate": 0.0002434960737453056,
      "loss": 0.1576,
      "step": 1147
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.36504435539245605,
      "learning_rate": 0.00024335950836462957,
      "loss": 0.1451,
      "step": 1148
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.3360435664653778,
      "learning_rate": 0.00024322294298395356,
      "loss": 0.1378,
      "step": 1149
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.34323692321777344,
      "learning_rate": 0.00024308637760327758,
      "loss": 0.1549,
      "step": 1150
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.4291425049304962,
      "learning_rate": 0.00024294981222260158,
      "loss": 0.165,
      "step": 1151
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.33287960290908813,
      "learning_rate": 0.00024281324684192557,
      "loss": 0.135,
      "step": 1152
    },
    {
      "epoch": 3.93,
      "grad_norm": 0.32875296473503113,
      "learning_rate": 0.0002426766814612496,
      "loss": 0.143,
      "step": 1153
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.34151187539100647,
      "learning_rate": 0.00024254011608057358,
      "loss": 0.1407,
      "step": 1154
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.3366103768348694,
      "learning_rate": 0.00024240355069989758,
      "loss": 0.1345,
      "step": 1155
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.4076521098613739,
      "learning_rate": 0.0002422669853192216,
      "loss": 0.1538,
      "step": 1156
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.36130526661872864,
      "learning_rate": 0.0002421304199385456,
      "loss": 0.1488,
      "step": 1157
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.38224804401397705,
      "learning_rate": 0.0002419938545578696,
      "loss": 0.1409,
      "step": 1158
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.36380407214164734,
      "learning_rate": 0.0002418572891771936,
      "loss": 0.1489,
      "step": 1159
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.34985655546188354,
      "learning_rate": 0.0002417207237965176,
      "loss": 0.1339,
      "step": 1160
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.3534083068370819,
      "learning_rate": 0.0002415841584158416,
      "loss": 0.1384,
      "step": 1161
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.410017728805542,
      "learning_rate": 0.00024144759303516557,
      "loss": 0.1743,
      "step": 1162
    },
    {
      "epoch": 3.97,
      "grad_norm": 0.32493481040000916,
      "learning_rate": 0.0002413110276544896,
      "loss": 0.1428,
      "step": 1163
    },
    {
      "epoch": 3.97,
      "grad_norm": 0.30838915705680847,
      "learning_rate": 0.0002411744622738136,
      "loss": 0.1359,
      "step": 1164
    },
    {
      "epoch": 3.97,
      "grad_norm": 0.3362458050251007,
      "learning_rate": 0.00024103789689313757,
      "loss": 0.133,
      "step": 1165
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.34494712948799133,
      "learning_rate": 0.00024090133151246162,
      "loss": 0.1374,
      "step": 1166
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.32820647954940796,
      "learning_rate": 0.0002407647661317856,
      "loss": 0.1286,
      "step": 1167
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.38277414441108704,
      "learning_rate": 0.00024062820075110958,
      "loss": 0.1451,
      "step": 1168
    },
    {
      "epoch": 3.99,
      "grad_norm": 0.4564221501350403,
      "learning_rate": 0.00024049163537043363,
      "loss": 0.1751,
      "step": 1169
    },
    {
      "epoch": 3.99,
      "grad_norm": 0.400677353143692,
      "learning_rate": 0.0002403550699897576,
      "loss": 0.1519,
      "step": 1170
    },
    {
      "epoch": 3.99,
      "grad_norm": 0.3510235846042633,
      "learning_rate": 0.0002402185046090816,
      "loss": 0.1336,
      "step": 1171
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.32338064908981323,
      "learning_rate": 0.00024008193922840562,
      "loss": 0.1443,
      "step": 1172
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.366676390171051,
      "learning_rate": 0.0002399453738477296,
      "loss": 0.1382,
      "step": 1173
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.30803582072257996,
      "learning_rate": 0.0002398088084670536,
      "loss": 0.1056,
      "step": 1174
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.2782321870326996,
      "learning_rate": 0.00023967224308637762,
      "loss": 0.1149,
      "step": 1175
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.3363230526447296,
      "learning_rate": 0.00023953567770570162,
      "loss": 0.113,
      "step": 1176
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.35087984800338745,
      "learning_rate": 0.0002393991123250256,
      "loss": 0.1147,
      "step": 1177
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3287426829338074,
      "learning_rate": 0.0002392625469443496,
      "loss": 0.0868,
      "step": 1178
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.3516135513782501,
      "learning_rate": 0.00023912598156367363,
      "loss": 0.0989,
      "step": 1179
    },
    {
      "epoch": 4.02,
      "grad_norm": 0.4272698760032654,
      "learning_rate": 0.00023898941618299762,
      "loss": 0.1368,
      "step": 1180
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.45487549901008606,
      "learning_rate": 0.00023885285080232162,
      "loss": 0.128,
      "step": 1181
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.3497222661972046,
      "learning_rate": 0.00023871628542164564,
      "loss": 0.0949,
      "step": 1182
    },
    {
      "epoch": 4.03,
      "grad_norm": 0.35345640778541565,
      "learning_rate": 0.00023857972004096963,
      "loss": 0.1012,
      "step": 1183
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.34546080231666565,
      "learning_rate": 0.0002384431546602936,
      "loss": 0.0966,
      "step": 1184
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.3523581624031067,
      "learning_rate": 0.00023830658927961765,
      "loss": 0.1059,
      "step": 1185
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.3271745443344116,
      "learning_rate": 0.00023817002389894164,
      "loss": 0.103,
      "step": 1186
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.3386284410953522,
      "learning_rate": 0.0002380334585182656,
      "loss": 0.1017,
      "step": 1187
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.39454829692840576,
      "learning_rate": 0.00023789689313758966,
      "loss": 0.1162,
      "step": 1188
    },
    {
      "epoch": 4.05,
      "grad_norm": 0.34064221382141113,
      "learning_rate": 0.00023776032775691362,
      "loss": 0.0954,
      "step": 1189
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.3554370403289795,
      "learning_rate": 0.00023762376237623762,
      "loss": 0.1066,
      "step": 1190
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.33314597606658936,
      "learning_rate": 0.00023748719699556167,
      "loss": 0.1026,
      "step": 1191
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.40034621953964233,
      "learning_rate": 0.00023735063161488563,
      "loss": 0.112,
      "step": 1192
    },
    {
      "epoch": 4.07,
      "grad_norm": 0.3640078902244568,
      "learning_rate": 0.00023721406623420963,
      "loss": 0.1042,
      "step": 1193
    },
    {
      "epoch": 4.07,
      "grad_norm": 0.3620778024196625,
      "learning_rate": 0.00023707750085353362,
      "loss": 0.1092,
      "step": 1194
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.34062379598617554,
      "learning_rate": 0.00023694093547285764,
      "loss": 0.1129,
      "step": 1195
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.33035242557525635,
      "learning_rate": 0.00023680437009218164,
      "loss": 0.1002,
      "step": 1196
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.3668656647205353,
      "learning_rate": 0.00023666780471150563,
      "loss": 0.1006,
      "step": 1197
    },
    {
      "epoch": 4.09,
      "grad_norm": 0.3612654209136963,
      "learning_rate": 0.00023653123933082965,
      "loss": 0.1165,
      "step": 1198
    },
    {
      "epoch": 4.09,
      "grad_norm": 0.3120172321796417,
      "learning_rate": 0.00023639467395015365,
      "loss": 0.0897,
      "step": 1199
    },
    {
      "epoch": 4.09,
      "grad_norm": 0.36515429615974426,
      "learning_rate": 0.00023625810856947764,
      "loss": 0.0998,
      "step": 1200
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.3658989667892456,
      "learning_rate": 0.00023612154318880166,
      "loss": 0.1069,
      "step": 1201
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.43850329518318176,
      "learning_rate": 0.00023598497780812566,
      "loss": 0.121,
      "step": 1202
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.3706657886505127,
      "learning_rate": 0.00023584841242744965,
      "loss": 0.1027,
      "step": 1203
    },
    {
      "epoch": 4.11,
      "grad_norm": 0.37414342164993286,
      "learning_rate": 0.00023571184704677367,
      "loss": 0.1204,
      "step": 1204
    },
    {
      "epoch": 4.11,
      "grad_norm": 0.3697146773338318,
      "learning_rate": 0.00023557528166609767,
      "loss": 0.1093,
      "step": 1205
    },
    {
      "epoch": 4.11,
      "grad_norm": 0.3823131024837494,
      "learning_rate": 0.00023543871628542163,
      "loss": 0.1123,
      "step": 1206
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.3625350296497345,
      "learning_rate": 0.00023530215090474568,
      "loss": 0.1134,
      "step": 1207
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.36021867394447327,
      "learning_rate": 0.00023516558552406968,
      "loss": 0.1165,
      "step": 1208
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.3381684422492981,
      "learning_rate": 0.00023502902014339364,
      "loss": 0.1009,
      "step": 1209
    },
    {
      "epoch": 4.13,
      "grad_norm": 0.34462082386016846,
      "learning_rate": 0.0002348924547627177,
      "loss": 0.1017,
      "step": 1210
    },
    {
      "epoch": 4.13,
      "grad_norm": 0.40987396240234375,
      "learning_rate": 0.00023475588938204168,
      "loss": 0.1276,
      "step": 1211
    },
    {
      "epoch": 4.13,
      "grad_norm": 0.3921017050743103,
      "learning_rate": 0.00023461932400136565,
      "loss": 0.1121,
      "step": 1212
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.39590439200401306,
      "learning_rate": 0.00023448275862068965,
      "loss": 0.1137,
      "step": 1213
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.3881707191467285,
      "learning_rate": 0.00023434619324001367,
      "loss": 0.1051,
      "step": 1214
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.35476046800613403,
      "learning_rate": 0.00023420962785933766,
      "loss": 0.1079,
      "step": 1215
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.400291383266449,
      "learning_rate": 0.00023407306247866166,
      "loss": 0.1164,
      "step": 1216
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.3155379593372345,
      "learning_rate": 0.00023393649709798568,
      "loss": 0.0984,
      "step": 1217
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.3774275779724121,
      "learning_rate": 0.00023379993171730967,
      "loss": 0.1058,
      "step": 1218
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.3685595989227295,
      "learning_rate": 0.00023366336633663366,
      "loss": 0.0999,
      "step": 1219
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.3295431137084961,
      "learning_rate": 0.00023352680095595769,
      "loss": 0.1082,
      "step": 1220
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.34490376710891724,
      "learning_rate": 0.00023339023557528168,
      "loss": 0.0996,
      "step": 1221
    },
    {
      "epoch": 4.17,
      "grad_norm": 0.35443416237831116,
      "learning_rate": 0.00023325367019460567,
      "loss": 0.1043,
      "step": 1222
    },
    {
      "epoch": 4.17,
      "grad_norm": 0.37805864214897156,
      "learning_rate": 0.0002331171048139297,
      "loss": 0.1016,
      "step": 1223
    },
    {
      "epoch": 4.17,
      "grad_norm": 0.3954890966415405,
      "learning_rate": 0.0002329805394332537,
      "loss": 0.1101,
      "step": 1224
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.3987889289855957,
      "learning_rate": 0.00023284397405257768,
      "loss": 0.1056,
      "step": 1225
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.37308165431022644,
      "learning_rate": 0.0002327074086719017,
      "loss": 0.1128,
      "step": 1226
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.35116440057754517,
      "learning_rate": 0.0002325708432912257,
      "loss": 0.111,
      "step": 1227
    },
    {
      "epoch": 4.19,
      "grad_norm": 0.28259575366973877,
      "learning_rate": 0.0002324342779105497,
      "loss": 0.0848,
      "step": 1228
    },
    {
      "epoch": 4.19,
      "grad_norm": 0.3517514765262604,
      "learning_rate": 0.00023229771252987366,
      "loss": 0.1115,
      "step": 1229
    },
    {
      "epoch": 4.19,
      "grad_norm": 0.3872342109680176,
      "learning_rate": 0.0002321611471491977,
      "loss": 0.1095,
      "step": 1230
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.3028417229652405,
      "learning_rate": 0.00023202458176852168,
      "loss": 0.0862,
      "step": 1231
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.3357841670513153,
      "learning_rate": 0.00023188801638784567,
      "loss": 0.0933,
      "step": 1232
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.40446117520332336,
      "learning_rate": 0.00023175145100716972,
      "loss": 0.1131,
      "step": 1233
    },
    {
      "epoch": 4.21,
      "grad_norm": 0.3738800883293152,
      "learning_rate": 0.00023161488562649369,
      "loss": 0.1041,
      "step": 1234
    },
    {
      "epoch": 4.21,
      "grad_norm": 0.4213985502719879,
      "learning_rate": 0.00023147832024581768,
      "loss": 0.1066,
      "step": 1235
    },
    {
      "epoch": 4.21,
      "grad_norm": 0.42464199662208557,
      "learning_rate": 0.0002313417548651417,
      "loss": 0.1015,
      "step": 1236
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.3962287902832031,
      "learning_rate": 0.0002312051894844657,
      "loss": 0.104,
      "step": 1237
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.3740456700325012,
      "learning_rate": 0.0002310686241037897,
      "loss": 0.1141,
      "step": 1238
    },
    {
      "epoch": 4.23,
      "grad_norm": 0.37326210737228394,
      "learning_rate": 0.0002309320587231137,
      "loss": 0.106,
      "step": 1239
    },
    {
      "epoch": 4.23,
      "grad_norm": 0.38100889325141907,
      "learning_rate": 0.0002307954933424377,
      "loss": 0.112,
      "step": 1240
    },
    {
      "epoch": 4.23,
      "grad_norm": 0.3355734646320343,
      "learning_rate": 0.0002306589279617617,
      "loss": 0.1065,
      "step": 1241
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.33029505610466003,
      "learning_rate": 0.00023052236258108572,
      "loss": 0.0975,
      "step": 1242
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.36362576484680176,
      "learning_rate": 0.00023038579720040971,
      "loss": 0.1051,
      "step": 1243
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.3711715638637543,
      "learning_rate": 0.0002302492318197337,
      "loss": 0.1045,
      "step": 1244
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.3576740026473999,
      "learning_rate": 0.0002301126664390577,
      "loss": 0.0959,
      "step": 1245
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.3996799886226654,
      "learning_rate": 0.00022997610105838172,
      "loss": 0.1201,
      "step": 1246
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.3714316189289093,
      "learning_rate": 0.00022983953567770572,
      "loss": 0.1088,
      "step": 1247
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.40470755100250244,
      "learning_rate": 0.00022970297029702968,
      "loss": 0.1223,
      "step": 1248
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.40810081362724304,
      "learning_rate": 0.00022956640491635373,
      "loss": 0.1344,
      "step": 1249
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.31901276111602783,
      "learning_rate": 0.00022942983953567773,
      "loss": 0.0982,
      "step": 1250
    },
    {
      "epoch": 4.27,
      "grad_norm": 0.36974531412124634,
      "learning_rate": 0.0002292932741550017,
      "loss": 0.1136,
      "step": 1251
    },
    {
      "epoch": 4.27,
      "grad_norm": 0.3801455795764923,
      "learning_rate": 0.00022915670877432574,
      "loss": 0.1212,
      "step": 1252
    },
    {
      "epoch": 4.27,
      "grad_norm": 0.3722931146621704,
      "learning_rate": 0.0002290201433936497,
      "loss": 0.1172,
      "step": 1253
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.3652172088623047,
      "learning_rate": 0.0002288835780129737,
      "loss": 0.1189,
      "step": 1254
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.36915603280067444,
      "learning_rate": 0.00022874701263229775,
      "loss": 0.1163,
      "step": 1255
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.35276147723197937,
      "learning_rate": 0.00022861044725162172,
      "loss": 0.1134,
      "step": 1256
    },
    {
      "epoch": 4.29,
      "grad_norm": 0.3547325134277344,
      "learning_rate": 0.0002284738818709457,
      "loss": 0.113,
      "step": 1257
    },
    {
      "epoch": 4.29,
      "grad_norm": 0.3617885112762451,
      "learning_rate": 0.00022833731649026976,
      "loss": 0.1181,
      "step": 1258
    },
    {
      "epoch": 4.29,
      "grad_norm": 0.3866473436355591,
      "learning_rate": 0.00022820075110959373,
      "loss": 0.1283,
      "step": 1259
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.34909480810165405,
      "learning_rate": 0.00022806418572891772,
      "loss": 0.1071,
      "step": 1260
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.32251983880996704,
      "learning_rate": 0.00022792762034824172,
      "loss": 0.0995,
      "step": 1261
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.3689984679222107,
      "learning_rate": 0.00022779105496756574,
      "loss": 0.1019,
      "step": 1262
    },
    {
      "epoch": 4.31,
      "grad_norm": 0.38297203183174133,
      "learning_rate": 0.00022765448958688973,
      "loss": 0.1085,
      "step": 1263
    },
    {
      "epoch": 4.31,
      "grad_norm": 0.3836141526699066,
      "learning_rate": 0.00022751792420621373,
      "loss": 0.1221,
      "step": 1264
    },
    {
      "epoch": 4.31,
      "grad_norm": 0.4087560176849365,
      "learning_rate": 0.00022738135882553775,
      "loss": 0.1266,
      "step": 1265
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.4035506844520569,
      "learning_rate": 0.00022724479344486174,
      "loss": 0.126,
      "step": 1266
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.3455239534378052,
      "learning_rate": 0.00022710822806418574,
      "loss": 0.0972,
      "step": 1267
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.34110090136528015,
      "learning_rate": 0.00022697166268350976,
      "loss": 0.115,
      "step": 1268
    },
    {
      "epoch": 4.33,
      "grad_norm": 0.3587521016597748,
      "learning_rate": 0.00022683509730283375,
      "loss": 0.1109,
      "step": 1269
    },
    {
      "epoch": 4.33,
      "grad_norm": 0.35279932618141174,
      "learning_rate": 0.00022669853192215772,
      "loss": 0.0959,
      "step": 1270
    },
    {
      "epoch": 4.33,
      "grad_norm": 0.3673732280731201,
      "learning_rate": 0.00022656196654148177,
      "loss": 0.105,
      "step": 1271
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.33731788396835327,
      "learning_rate": 0.00022642540116080576,
      "loss": 0.1009,
      "step": 1272
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.37158969044685364,
      "learning_rate": 0.00022628883578012973,
      "loss": 0.0989,
      "step": 1273
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.3682302236557007,
      "learning_rate": 0.00022615227039945378,
      "loss": 0.1143,
      "step": 1274
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.3883725702762604,
      "learning_rate": 0.00022601570501877777,
      "loss": 0.1018,
      "step": 1275
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.3468860685825348,
      "learning_rate": 0.00022587913963810174,
      "loss": 0.1004,
      "step": 1276
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.3566993176937103,
      "learning_rate": 0.00022574257425742573,
      "loss": 0.0989,
      "step": 1277
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.3518475890159607,
      "learning_rate": 0.00022560600887674975,
      "loss": 0.0955,
      "step": 1278
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.3828028738498688,
      "learning_rate": 0.00022546944349607375,
      "loss": 0.1157,
      "step": 1279
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.40711069107055664,
      "learning_rate": 0.00022533287811539774,
      "loss": 0.114,
      "step": 1280
    },
    {
      "epoch": 4.37,
      "grad_norm": 0.31608396768569946,
      "learning_rate": 0.00022519631273472176,
      "loss": 0.0973,
      "step": 1281
    },
    {
      "epoch": 4.37,
      "grad_norm": 0.3639872372150421,
      "learning_rate": 0.00022505974735404576,
      "loss": 0.1033,
      "step": 1282
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.3679070472717285,
      "learning_rate": 0.00022492318197336975,
      "loss": 0.0984,
      "step": 1283
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.34045636653900146,
      "learning_rate": 0.00022478661659269377,
      "loss": 0.0979,
      "step": 1284
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.38376671075820923,
      "learning_rate": 0.00022465005121201777,
      "loss": 0.1036,
      "step": 1285
    },
    {
      "epoch": 4.39,
      "grad_norm": 0.377642959356308,
      "learning_rate": 0.00022451348583134176,
      "loss": 0.1054,
      "step": 1286
    },
    {
      "epoch": 4.39,
      "grad_norm": 0.38423392176628113,
      "learning_rate": 0.00022437692045066578,
      "loss": 0.1039,
      "step": 1287
    },
    {
      "epoch": 4.39,
      "grad_norm": 0.3772263824939728,
      "learning_rate": 0.00022424035506998978,
      "loss": 0.1051,
      "step": 1288
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.3541126549243927,
      "learning_rate": 0.00022410378968931377,
      "loss": 0.1012,
      "step": 1289
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.41143283247947693,
      "learning_rate": 0.0002239672243086378,
      "loss": 0.1143,
      "step": 1290
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.3809244632720947,
      "learning_rate": 0.00022383065892796179,
      "loss": 0.1133,
      "step": 1291
    },
    {
      "epoch": 4.41,
      "grad_norm": 0.35734739899635315,
      "learning_rate": 0.00022369409354728575,
      "loss": 0.1061,
      "step": 1292
    },
    {
      "epoch": 4.41,
      "grad_norm": 0.3187236189842224,
      "learning_rate": 0.00022355752816660975,
      "loss": 0.1067,
      "step": 1293
    },
    {
      "epoch": 4.41,
      "grad_norm": 0.3712283968925476,
      "learning_rate": 0.0002234209627859338,
      "loss": 0.1046,
      "step": 1294
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.3823837339878082,
      "learning_rate": 0.00022328439740525776,
      "loss": 0.1118,
      "step": 1295
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.37083399295806885,
      "learning_rate": 0.00022314783202458176,
      "loss": 0.1083,
      "step": 1296
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.432931512594223,
      "learning_rate": 0.0002230112666439058,
      "loss": 0.1238,
      "step": 1297
    },
    {
      "epoch": 4.43,
      "grad_norm": 0.3532668352127075,
      "learning_rate": 0.00022287470126322977,
      "loss": 0.1031,
      "step": 1298
    },
    {
      "epoch": 4.43,
      "grad_norm": 0.3598916232585907,
      "learning_rate": 0.00022273813588255377,
      "loss": 0.1027,
      "step": 1299
    },
    {
      "epoch": 4.43,
      "grad_norm": 0.34165439009666443,
      "learning_rate": 0.0002226015705018778,
      "loss": 0.0999,
      "step": 1300
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.359994113445282,
      "learning_rate": 0.00022246500512120178,
      "loss": 0.0979,
      "step": 1301
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.3361303210258484,
      "learning_rate": 0.00022232843974052577,
      "loss": 0.0971,
      "step": 1302
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.3537121117115021,
      "learning_rate": 0.0002221918743598498,
      "loss": 0.1017,
      "step": 1303
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.3666740357875824,
      "learning_rate": 0.0002220553089791738,
      "loss": 0.1043,
      "step": 1304
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.36131811141967773,
      "learning_rate": 0.00022191874359849778,
      "loss": 0.1085,
      "step": 1305
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.35290417075157166,
      "learning_rate": 0.0002217821782178218,
      "loss": 0.0956,
      "step": 1306
    },
    {
      "epoch": 4.46,
      "grad_norm": 0.38197124004364014,
      "learning_rate": 0.0002216456128371458,
      "loss": 0.1189,
      "step": 1307
    },
    {
      "epoch": 4.46,
      "grad_norm": 0.3722735643386841,
      "learning_rate": 0.0002215090474564698,
      "loss": 0.1135,
      "step": 1308
    },
    {
      "epoch": 4.46,
      "grad_norm": 0.3898736238479614,
      "learning_rate": 0.00022137248207579382,
      "loss": 0.1077,
      "step": 1309
    },
    {
      "epoch": 4.47,
      "grad_norm": 0.3697137236595154,
      "learning_rate": 0.0002212359166951178,
      "loss": 0.1064,
      "step": 1310
    },
    {
      "epoch": 4.47,
      "grad_norm": 0.3959270417690277,
      "learning_rate": 0.0002210993513144418,
      "loss": 0.1078,
      "step": 1311
    },
    {
      "epoch": 4.47,
      "grad_norm": 0.4228207468986511,
      "learning_rate": 0.00022096278593376577,
      "loss": 0.1159,
      "step": 1312
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.3828580677509308,
      "learning_rate": 0.00022082622055308982,
      "loss": 0.1105,
      "step": 1313
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.3642544150352478,
      "learning_rate": 0.0002206896551724138,
      "loss": 0.1089,
      "step": 1314
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.400427907705307,
      "learning_rate": 0.00022055308979173778,
      "loss": 0.1312,
      "step": 1315
    },
    {
      "epoch": 4.49,
      "grad_norm": 0.33515945076942444,
      "learning_rate": 0.00022041652441106183,
      "loss": 0.0956,
      "step": 1316
    },
    {
      "epoch": 4.49,
      "grad_norm": 0.3612820506095886,
      "learning_rate": 0.0002202799590303858,
      "loss": 0.1087,
      "step": 1317
    },
    {
      "epoch": 4.49,
      "grad_norm": 0.3186860978603363,
      "learning_rate": 0.0002201433936497098,
      "loss": 0.111,
      "step": 1318
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.37013742327690125,
      "learning_rate": 0.00022000682826903384,
      "loss": 0.1172,
      "step": 1319
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.3472655415534973,
      "learning_rate": 0.0002198702628883578,
      "loss": 0.1072,
      "step": 1320
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.4035055339336395,
      "learning_rate": 0.0002197336975076818,
      "loss": 0.1242,
      "step": 1321
    },
    {
      "epoch": 4.51,
      "grad_norm": 0.36281511187553406,
      "learning_rate": 0.00021959713212700582,
      "loss": 0.1102,
      "step": 1322
    },
    {
      "epoch": 4.51,
      "grad_norm": 0.3819572329521179,
      "learning_rate": 0.00021946056674632981,
      "loss": 0.1135,
      "step": 1323
    },
    {
      "epoch": 4.51,
      "grad_norm": 0.4552781283855438,
      "learning_rate": 0.0002193240013656538,
      "loss": 0.1242,
      "step": 1324
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.35279056429862976,
      "learning_rate": 0.00021918743598497783,
      "loss": 0.1012,
      "step": 1325
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.36662715673446655,
      "learning_rate": 0.00021905087060430182,
      "loss": 0.1046,
      "step": 1326
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.35865357518196106,
      "learning_rate": 0.00021891430522362582,
      "loss": 0.1151,
      "step": 1327
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.3307590186595917,
      "learning_rate": 0.0002187777398429498,
      "loss": 0.0949,
      "step": 1328
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.33310988545417786,
      "learning_rate": 0.00021864117446227383,
      "loss": 0.1082,
      "step": 1329
    },
    {
      "epoch": 4.54,
      "grad_norm": 0.35183531045913696,
      "learning_rate": 0.00021850460908159783,
      "loss": 0.0997,
      "step": 1330
    },
    {
      "epoch": 4.54,
      "grad_norm": 0.4016630947589874,
      "learning_rate": 0.00021836804370092182,
      "loss": 0.1151,
      "step": 1331
    },
    {
      "epoch": 4.54,
      "grad_norm": 0.3568877875804901,
      "learning_rate": 0.00021823147832024584,
      "loss": 0.0951,
      "step": 1332
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.39961811900138855,
      "learning_rate": 0.00021809491293956984,
      "loss": 0.1059,
      "step": 1333
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.37139371037483215,
      "learning_rate": 0.0002179583475588938,
      "loss": 0.0945,
      "step": 1334
    },
    {
      "epoch": 4.55,
      "grad_norm": 0.423658162355423,
      "learning_rate": 0.00021782178217821785,
      "loss": 0.1274,
      "step": 1335
    },
    {
      "epoch": 4.56,
      "grad_norm": 0.41190263628959656,
      "learning_rate": 0.00021768521679754185,
      "loss": 0.1183,
      "step": 1336
    },
    {
      "epoch": 4.56,
      "grad_norm": 0.34843534231185913,
      "learning_rate": 0.00021754865141686581,
      "loss": 0.0998,
      "step": 1337
    },
    {
      "epoch": 4.56,
      "grad_norm": 0.3485611379146576,
      "learning_rate": 0.00021741208603618986,
      "loss": 0.1054,
      "step": 1338
    },
    {
      "epoch": 4.57,
      "grad_norm": 0.34962090849876404,
      "learning_rate": 0.00021727552065551383,
      "loss": 0.1105,
      "step": 1339
    },
    {
      "epoch": 4.57,
      "grad_norm": 0.33388465642929077,
      "learning_rate": 0.00021713895527483782,
      "loss": 0.1052,
      "step": 1340
    },
    {
      "epoch": 4.57,
      "grad_norm": 0.34331101179122925,
      "learning_rate": 0.00021700238989416187,
      "loss": 0.1013,
      "step": 1341
    },
    {
      "epoch": 4.58,
      "grad_norm": 0.3282906115055084,
      "learning_rate": 0.00021686582451348584,
      "loss": 0.0987,
      "step": 1342
    },
    {
      "epoch": 4.58,
      "grad_norm": 0.32471388578414917,
      "learning_rate": 0.00021672925913280983,
      "loss": 0.0984,
      "step": 1343
    },
    {
      "epoch": 4.58,
      "grad_norm": 0.3188919126987457,
      "learning_rate": 0.00021659269375213383,
      "loss": 0.098,
      "step": 1344
    },
    {
      "epoch": 4.59,
      "grad_norm": 0.35936611890792847,
      "learning_rate": 0.00021645612837145785,
      "loss": 0.1057,
      "step": 1345
    },
    {
      "epoch": 4.59,
      "grad_norm": 0.34890660643577576,
      "learning_rate": 0.00021631956299078184,
      "loss": 0.0982,
      "step": 1346
    },
    {
      "epoch": 4.59,
      "grad_norm": 0.39104512333869934,
      "learning_rate": 0.00021618299761010584,
      "loss": 0.1058,
      "step": 1347
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.3592919111251831,
      "learning_rate": 0.00021604643222942986,
      "loss": 0.0929,
      "step": 1348
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.4171750247478485,
      "learning_rate": 0.00021590986684875385,
      "loss": 0.1154,
      "step": 1349
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.3850025236606598,
      "learning_rate": 0.00021577330146807785,
      "loss": 0.1037,
      "step": 1350
    },
    {
      "epoch": 4.61,
      "grad_norm": 0.34974533319473267,
      "learning_rate": 0.00021563673608740187,
      "loss": 0.101,
      "step": 1351
    },
    {
      "epoch": 4.61,
      "grad_norm": 0.3167378008365631,
      "learning_rate": 0.00021550017070672586,
      "loss": 0.0839,
      "step": 1352
    },
    {
      "epoch": 4.61,
      "grad_norm": 0.3652569055557251,
      "learning_rate": 0.00021536360532604986,
      "loss": 0.1089,
      "step": 1353
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.3274801969528198,
      "learning_rate": 0.00021522703994537388,
      "loss": 0.0837,
      "step": 1354
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.4172804057598114,
      "learning_rate": 0.00021509047456469787,
      "loss": 0.1085,
      "step": 1355
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.4070846736431122,
      "learning_rate": 0.00021495390918402184,
      "loss": 0.1124,
      "step": 1356
    },
    {
      "epoch": 4.63,
      "grad_norm": 0.3613613545894623,
      "learning_rate": 0.00021481734380334589,
      "loss": 0.1142,
      "step": 1357
    },
    {
      "epoch": 4.63,
      "grad_norm": 0.3055890202522278,
      "learning_rate": 0.00021468077842266988,
      "loss": 0.0856,
      "step": 1358
    },
    {
      "epoch": 4.63,
      "grad_norm": 0.4015965163707733,
      "learning_rate": 0.00021454421304199385,
      "loss": 0.1039,
      "step": 1359
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.3460541367530823,
      "learning_rate": 0.00021440764766131784,
      "loss": 0.1058,
      "step": 1360
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.39704811573028564,
      "learning_rate": 0.0002142710822806419,
      "loss": 0.1117,
      "step": 1361
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.3258242607116699,
      "learning_rate": 0.00021413451689996586,
      "loss": 0.0958,
      "step": 1362
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.34833312034606934,
      "learning_rate": 0.00021399795151928985,
      "loss": 0.1006,
      "step": 1363
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.413007915019989,
      "learning_rate": 0.00021386138613861387,
      "loss": 0.1139,
      "step": 1364
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.3444485366344452,
      "learning_rate": 0.00021372482075793787,
      "loss": 0.1031,
      "step": 1365
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.33075910806655884,
      "learning_rate": 0.00021358825537726186,
      "loss": 0.0924,
      "step": 1366
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.3276139199733734,
      "learning_rate": 0.00021345168999658588,
      "loss": 0.0993,
      "step": 1367
    },
    {
      "epoch": 4.66,
      "grad_norm": 0.4269423484802246,
      "learning_rate": 0.00021331512461590988,
      "loss": 0.1297,
      "step": 1368
    },
    {
      "epoch": 4.67,
      "grad_norm": 0.29836565256118774,
      "learning_rate": 0.00021317855923523387,
      "loss": 0.0955,
      "step": 1369
    },
    {
      "epoch": 4.67,
      "grad_norm": 0.3374583423137665,
      "learning_rate": 0.0002130419938545579,
      "loss": 0.105,
      "step": 1370
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.34384721517562866,
      "learning_rate": 0.00021290542847388189,
      "loss": 0.0993,
      "step": 1371
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.3567535877227783,
      "learning_rate": 0.00021276886309320588,
      "loss": 0.101,
      "step": 1372
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.3731863498687744,
      "learning_rate": 0.0002126322977125299,
      "loss": 0.0999,
      "step": 1373
    },
    {
      "epoch": 4.69,
      "grad_norm": 0.37757256627082825,
      "learning_rate": 0.0002124957323318539,
      "loss": 0.1077,
      "step": 1374
    },
    {
      "epoch": 4.69,
      "grad_norm": 0.3090389668941498,
      "learning_rate": 0.0002123591669511779,
      "loss": 0.0886,
      "step": 1375
    },
    {
      "epoch": 4.69,
      "grad_norm": 0.38508227467536926,
      "learning_rate": 0.00021222260157050186,
      "loss": 0.1064,
      "step": 1376
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.3645094037055969,
      "learning_rate": 0.0002120860361898259,
      "loss": 0.1127,
      "step": 1377
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.3439214527606964,
      "learning_rate": 0.0002119494708091499,
      "loss": 0.1093,
      "step": 1378
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.39182204008102417,
      "learning_rate": 0.00021181290542847387,
      "loss": 0.1162,
      "step": 1379
    },
    {
      "epoch": 4.71,
      "grad_norm": 0.30677205324172974,
      "learning_rate": 0.00021167634004779791,
      "loss": 0.0894,
      "step": 1380
    },
    {
      "epoch": 4.71,
      "grad_norm": 0.33671268820762634,
      "learning_rate": 0.00021153977466712188,
      "loss": 0.0986,
      "step": 1381
    },
    {
      "epoch": 4.71,
      "grad_norm": 0.3388548195362091,
      "learning_rate": 0.00021140320928644588,
      "loss": 0.1047,
      "step": 1382
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.3186938166618347,
      "learning_rate": 0.00021126664390576992,
      "loss": 0.0956,
      "step": 1383
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.4082128703594208,
      "learning_rate": 0.0002111300785250939,
      "loss": 0.1195,
      "step": 1384
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.34671810269355774,
      "learning_rate": 0.00021099351314441788,
      "loss": 0.0959,
      "step": 1385
    },
    {
      "epoch": 4.73,
      "grad_norm": 0.41033658385276794,
      "learning_rate": 0.0002108569477637419,
      "loss": 0.1262,
      "step": 1386
    },
    {
      "epoch": 4.73,
      "grad_norm": 0.3798959255218506,
      "learning_rate": 0.0002107203823830659,
      "loss": 0.1058,
      "step": 1387
    },
    {
      "epoch": 4.73,
      "grad_norm": 0.36302489042282104,
      "learning_rate": 0.0002105838170023899,
      "loss": 0.1062,
      "step": 1388
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.33936160802841187,
      "learning_rate": 0.00021044725162171392,
      "loss": 0.0991,
      "step": 1389
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.3423795700073242,
      "learning_rate": 0.0002103106862410379,
      "loss": 0.0965,
      "step": 1390
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.37137851119041443,
      "learning_rate": 0.0002101741208603619,
      "loss": 0.0983,
      "step": 1391
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.34403157234191895,
      "learning_rate": 0.0002100375554796859,
      "loss": 0.1057,
      "step": 1392
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.339282751083374,
      "learning_rate": 0.00020990099009900992,
      "loss": 0.0941,
      "step": 1393
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.3709377646446228,
      "learning_rate": 0.0002097644247183339,
      "loss": 0.0952,
      "step": 1394
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.4023854434490204,
      "learning_rate": 0.0002096278593376579,
      "loss": 0.1112,
      "step": 1395
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.42894166707992554,
      "learning_rate": 0.00020949129395698193,
      "loss": 0.1169,
      "step": 1396
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.30156126618385315,
      "learning_rate": 0.00020935472857630592,
      "loss": 0.0849,
      "step": 1397
    },
    {
      "epoch": 4.77,
      "grad_norm": 0.39492663741111755,
      "learning_rate": 0.0002092181631956299,
      "loss": 0.1006,
      "step": 1398
    },
    {
      "epoch": 4.77,
      "grad_norm": 0.4103110730648041,
      "learning_rate": 0.00020908159781495394,
      "loss": 0.1037,
      "step": 1399
    },
    {
      "epoch": 4.77,
      "grad_norm": 0.3178209364414215,
      "learning_rate": 0.00020894503243427793,
      "loss": 0.0941,
      "step": 1400
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.3348737359046936,
      "learning_rate": 0.0002088084670536019,
      "loss": 0.0918,
      "step": 1401
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.35469484329223633,
      "learning_rate": 0.00020867190167292595,
      "loss": 0.0928,
      "step": 1402
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.41404619812965393,
      "learning_rate": 0.00020853533629224991,
      "loss": 0.1131,
      "step": 1403
    },
    {
      "epoch": 4.79,
      "grad_norm": 0.3924034535884857,
      "learning_rate": 0.0002083987709115739,
      "loss": 0.1136,
      "step": 1404
    },
    {
      "epoch": 4.79,
      "grad_norm": 0.36585646867752075,
      "learning_rate": 0.00020826220553089796,
      "loss": 0.0976,
      "step": 1405
    },
    {
      "epoch": 4.79,
      "grad_norm": 0.3471987545490265,
      "learning_rate": 0.00020812564015022192,
      "loss": 0.0878,
      "step": 1406
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.39948633313179016,
      "learning_rate": 0.00020798907476954592,
      "loss": 0.1134,
      "step": 1407
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.36210429668426514,
      "learning_rate": 0.0002078525093888699,
      "loss": 0.0982,
      "step": 1408
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.4277440011501312,
      "learning_rate": 0.00020771594400819393,
      "loss": 0.1133,
      "step": 1409
    },
    {
      "epoch": 4.81,
      "grad_norm": 0.34105992317199707,
      "learning_rate": 0.00020757937862751793,
      "loss": 0.0927,
      "step": 1410
    },
    {
      "epoch": 4.81,
      "grad_norm": 0.4279976189136505,
      "learning_rate": 0.00020744281324684192,
      "loss": 0.1135,
      "step": 1411
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.3737383782863617,
      "learning_rate": 0.00020730624786616594,
      "loss": 0.0971,
      "step": 1412
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.39430245757102966,
      "learning_rate": 0.00020716968248548994,
      "loss": 0.1028,
      "step": 1413
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.4153781831264496,
      "learning_rate": 0.00020703311710481393,
      "loss": 0.1117,
      "step": 1414
    },
    {
      "epoch": 4.83,
      "grad_norm": 0.34884050488471985,
      "learning_rate": 0.00020689655172413795,
      "loss": 0.0934,
      "step": 1415
    },
    {
      "epoch": 4.83,
      "grad_norm": 0.3900842070579529,
      "learning_rate": 0.00020675998634346195,
      "loss": 0.1107,
      "step": 1416
    },
    {
      "epoch": 4.83,
      "grad_norm": 0.3464319109916687,
      "learning_rate": 0.00020662342096278594,
      "loss": 0.1093,
      "step": 1417
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.31381621956825256,
      "learning_rate": 0.00020648685558210996,
      "loss": 0.0939,
      "step": 1418
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.352895051240921,
      "learning_rate": 0.00020635029020143396,
      "loss": 0.0993,
      "step": 1419
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.35588905215263367,
      "learning_rate": 0.00020621372482075792,
      "loss": 0.0989,
      "step": 1420
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.3703453242778778,
      "learning_rate": 0.00020607715944008197,
      "loss": 0.1088,
      "step": 1421
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.3723497986793518,
      "learning_rate": 0.00020594059405940597,
      "loss": 0.0992,
      "step": 1422
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.3534556031227112,
      "learning_rate": 0.00020580402867872993,
      "loss": 0.0874,
      "step": 1423
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.38822612166404724,
      "learning_rate": 0.00020566746329805398,
      "loss": 0.0936,
      "step": 1424
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.3419961929321289,
      "learning_rate": 0.00020553089791737798,
      "loss": 0.0915,
      "step": 1425
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.3969825208187103,
      "learning_rate": 0.00020539433253670194,
      "loss": 0.1007,
      "step": 1426
    },
    {
      "epoch": 4.87,
      "grad_norm": 0.37186047434806824,
      "learning_rate": 0.00020525776715602594,
      "loss": 0.0949,
      "step": 1427
    },
    {
      "epoch": 4.87,
      "grad_norm": 0.39771780371665955,
      "learning_rate": 0.00020512120177534996,
      "loss": 0.103,
      "step": 1428
    },
    {
      "epoch": 4.87,
      "grad_norm": 0.357074499130249,
      "learning_rate": 0.00020498463639467395,
      "loss": 0.0968,
      "step": 1429
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.31244194507598877,
      "learning_rate": 0.00020484807101399795,
      "loss": 0.0937,
      "step": 1430
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.3574528396129608,
      "learning_rate": 0.00020471150563332197,
      "loss": 0.1026,
      "step": 1431
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.38496336340904236,
      "learning_rate": 0.00020457494025264596,
      "loss": 0.1196,
      "step": 1432
    },
    {
      "epoch": 4.89,
      "grad_norm": 0.31550201773643494,
      "learning_rate": 0.00020443837487196996,
      "loss": 0.0913,
      "step": 1433
    },
    {
      "epoch": 4.89,
      "grad_norm": 0.35577768087387085,
      "learning_rate": 0.00020430180949129398,
      "loss": 0.1085,
      "step": 1434
    },
    {
      "epoch": 4.89,
      "grad_norm": 0.3733772039413452,
      "learning_rate": 0.00020416524411061797,
      "loss": 0.1131,
      "step": 1435
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.32958054542541504,
      "learning_rate": 0.00020402867872994197,
      "loss": 0.1033,
      "step": 1436
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.3226839601993561,
      "learning_rate": 0.000203892113349266,
      "loss": 0.0926,
      "step": 1437
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.3614698350429535,
      "learning_rate": 0.00020375554796858998,
      "loss": 0.0929,
      "step": 1438
    },
    {
      "epoch": 4.91,
      "grad_norm": 0.3063931465148926,
      "learning_rate": 0.00020361898258791398,
      "loss": 0.0895,
      "step": 1439
    },
    {
      "epoch": 4.91,
      "grad_norm": 0.3821222484111786,
      "learning_rate": 0.000203482417207238,
      "loss": 0.1019,
      "step": 1440
    },
    {
      "epoch": 4.91,
      "grad_norm": 0.30656468868255615,
      "learning_rate": 0.000203345851826562,
      "loss": 0.0851,
      "step": 1441
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.45297518372535706,
      "learning_rate": 0.00020320928644588598,
      "loss": 0.1152,
      "step": 1442
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.3533563017845154,
      "learning_rate": 0.00020307272106520995,
      "loss": 0.0937,
      "step": 1443
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.3634732663631439,
      "learning_rate": 0.000202936155684534,
      "loss": 0.1032,
      "step": 1444
    },
    {
      "epoch": 4.93,
      "grad_norm": 0.33958640694618225,
      "learning_rate": 0.00020279959030385797,
      "loss": 0.0898,
      "step": 1445
    },
    {
      "epoch": 4.93,
      "grad_norm": 0.3652137219905853,
      "learning_rate": 0.00020266302492318196,
      "loss": 0.1039,
      "step": 1446
    },
    {
      "epoch": 4.93,
      "grad_norm": 0.3321746587753296,
      "learning_rate": 0.000202526459542506,
      "loss": 0.0971,
      "step": 1447
    },
    {
      "epoch": 4.94,
      "grad_norm": 0.3940568268299103,
      "learning_rate": 0.00020238989416182998,
      "loss": 0.0951,
      "step": 1448
    },
    {
      "epoch": 4.94,
      "grad_norm": 0.37579044699668884,
      "learning_rate": 0.00020225332878115397,
      "loss": 0.1047,
      "step": 1449
    },
    {
      "epoch": 4.94,
      "grad_norm": 0.34887969493865967,
      "learning_rate": 0.000202116763400478,
      "loss": 0.0957,
      "step": 1450
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.3190223276615143,
      "learning_rate": 0.00020198019801980199,
      "loss": 0.0942,
      "step": 1451
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.3603910505771637,
      "learning_rate": 0.00020184363263912598,
      "loss": 0.1157,
      "step": 1452
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.31495431065559387,
      "learning_rate": 0.00020170706725845,
      "loss": 0.0996,
      "step": 1453
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.35225602984428406,
      "learning_rate": 0.000201570501877774,
      "loss": 0.1005,
      "step": 1454
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.32632988691329956,
      "learning_rate": 0.000201433936497098,
      "loss": 0.0882,
      "step": 1455
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.3330793082714081,
      "learning_rate": 0.000201297371116422,
      "loss": 0.0976,
      "step": 1456
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.400644987821579,
      "learning_rate": 0.000201160805735746,
      "loss": 0.116,
      "step": 1457
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.32311660051345825,
      "learning_rate": 0.00020102424035507,
      "loss": 0.0931,
      "step": 1458
    },
    {
      "epoch": 4.98,
      "grad_norm": 0.38004013895988464,
      "learning_rate": 0.000200887674974394,
      "loss": 0.1143,
      "step": 1459
    },
    {
      "epoch": 4.98,
      "grad_norm": 0.3652631640434265,
      "learning_rate": 0.00020075110959371801,
      "loss": 0.0924,
      "step": 1460
    },
    {
      "epoch": 4.98,
      "grad_norm": 0.333185076713562,
      "learning_rate": 0.000200614544213042,
      "loss": 0.0929,
      "step": 1461
    },
    {
      "epoch": 4.99,
      "grad_norm": 0.3731049597263336,
      "learning_rate": 0.00020047797883236598,
      "loss": 0.0897,
      "step": 1462
    },
    {
      "epoch": 4.99,
      "grad_norm": 0.36191412806510925,
      "learning_rate": 0.00020034141345169002,
      "loss": 0.1034,
      "step": 1463
    },
    {
      "epoch": 4.99,
      "grad_norm": 0.3334520757198334,
      "learning_rate": 0.00020020484807101402,
      "loss": 0.0881,
      "step": 1464
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.34671032428741455,
      "learning_rate": 0.00020006828269033799,
      "loss": 0.0921,
      "step": 1465
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.3132627606391907,
      "learning_rate": 0.000199931717309662,
      "loss": 0.0838,
      "step": 1466
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2908782362937927,
      "learning_rate": 0.000199795151928986,
      "loss": 0.0675,
      "step": 1467
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.275020033121109,
      "learning_rate": 0.00019965858654831002,
      "loss": 0.0623,
      "step": 1468
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.36246514320373535,
      "learning_rate": 0.00019952202116763402,
      "loss": 0.0891,
      "step": 1469
    },
    {
      "epoch": 5.01,
      "grad_norm": 0.27465325593948364,
      "learning_rate": 0.000199385455786958,
      "loss": 0.0711,
      "step": 1470
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.3624454736709595,
      "learning_rate": 0.000199248890406282,
      "loss": 0.0697,
      "step": 1471
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.368582159280777,
      "learning_rate": 0.00019911232502560603,
      "loss": 0.0706,
      "step": 1472
    },
    {
      "epoch": 5.02,
      "grad_norm": 0.36119285225868225,
      "learning_rate": 0.00019897575964493002,
      "loss": 0.0652,
      "step": 1473
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.37981656193733215,
      "learning_rate": 0.00019883919426425401,
      "loss": 0.0679,
      "step": 1474
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.3875839412212372,
      "learning_rate": 0.00019870262888357804,
      "loss": 0.0647,
      "step": 1475
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.3976998031139374,
      "learning_rate": 0.00019856606350290203,
      "loss": 0.063,
      "step": 1476
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.3391408324241638,
      "learning_rate": 0.00019842949812222602,
      "loss": 0.0623,
      "step": 1477
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.37747564911842346,
      "learning_rate": 0.00019829293274155002,
      "loss": 0.0734,
      "step": 1478
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.3456377387046814,
      "learning_rate": 0.000198156367360874,
      "loss": 0.0704,
      "step": 1479
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.30833911895751953,
      "learning_rate": 0.00019801980198019803,
      "loss": 0.0747,
      "step": 1480
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.38156217336654663,
      "learning_rate": 0.00019788323659952203,
      "loss": 0.0868,
      "step": 1481
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.3607122302055359,
      "learning_rate": 0.00019774667121884602,
      "loss": 0.0845,
      "step": 1482
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.30260169506073,
      "learning_rate": 0.00019761010583817004,
      "loss": 0.0652,
      "step": 1483
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.3728996217250824,
      "learning_rate": 0.00019747354045749404,
      "loss": 0.0904,
      "step": 1484
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.32316353917121887,
      "learning_rate": 0.00019733697507681803,
      "loss": 0.0726,
      "step": 1485
    },
    {
      "epoch": 5.07,
      "grad_norm": 0.298284113407135,
      "learning_rate": 0.00019720040969614205,
      "loss": 0.0635,
      "step": 1486
    },
    {
      "epoch": 5.07,
      "grad_norm": 0.3410676121711731,
      "learning_rate": 0.00019706384431546602,
      "loss": 0.0653,
      "step": 1487
    },
    {
      "epoch": 5.07,
      "grad_norm": 0.2831306457519531,
      "learning_rate": 0.00019692727893479004,
      "loss": 0.0566,
      "step": 1488
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.33146071434020996,
      "learning_rate": 0.00019679071355411403,
      "loss": 0.0719,
      "step": 1489
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.3424219489097595,
      "learning_rate": 0.00019665414817343803,
      "loss": 0.0701,
      "step": 1490
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.29372870922088623,
      "learning_rate": 0.00019651758279276205,
      "loss": 0.0511,
      "step": 1491
    },
    {
      "epoch": 5.09,
      "grad_norm": 0.3172338902950287,
      "learning_rate": 0.00019638101741208604,
      "loss": 0.061,
      "step": 1492
    },
    {
      "epoch": 5.09,
      "grad_norm": 0.3563513457775116,
      "learning_rate": 0.00019624445203141004,
      "loss": 0.0714,
      "step": 1493
    },
    {
      "epoch": 5.09,
      "grad_norm": 0.29251518845558167,
      "learning_rate": 0.00019610788665073406,
      "loss": 0.0621,
      "step": 1494
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.32943934202194214,
      "learning_rate": 0.00019597132127005803,
      "loss": 0.0682,
      "step": 1495
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.3235938847064972,
      "learning_rate": 0.00019583475588938205,
      "loss": 0.0613,
      "step": 1496
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.3784848153591156,
      "learning_rate": 0.00019569819050870607,
      "loss": 0.08,
      "step": 1497
    },
    {
      "epoch": 5.11,
      "grad_norm": 0.30846771597862244,
      "learning_rate": 0.00019556162512803004,
      "loss": 0.0629,
      "step": 1498
    },
    {
      "epoch": 5.11,
      "grad_norm": 0.34299734234809875,
      "learning_rate": 0.00019542505974735406,
      "loss": 0.0678,
      "step": 1499
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.3535394072532654,
      "learning_rate": 0.00019528849436667808,
      "loss": 0.077,
      "step": 1500
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.3542109727859497,
      "learning_rate": 0.00019515192898600205,
      "loss": 0.077,
      "step": 1501
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.3183377981185913,
      "learning_rate": 0.00019501536360532607,
      "loss": 0.0649,
      "step": 1502
    },
    {
      "epoch": 5.13,
      "grad_norm": 0.29554179310798645,
      "learning_rate": 0.00019487879822465006,
      "loss": 0.059,
      "step": 1503
    },
    {
      "epoch": 5.13,
      "grad_norm": 0.3576511740684509,
      "learning_rate": 0.00019474223284397406,
      "loss": 0.0695,
      "step": 1504
    },
    {
      "epoch": 5.13,
      "grad_norm": 0.3539257347583771,
      "learning_rate": 0.00019460566746329808,
      "loss": 0.0707,
      "step": 1505
    },
    {
      "epoch": 5.14,
      "grad_norm": 0.32694998383522034,
      "learning_rate": 0.00019446910208262204,
      "loss": 0.0645,
      "step": 1506
    },
    {
      "epoch": 5.14,
      "grad_norm": 0.403602659702301,
      "learning_rate": 0.00019433253670194606,
      "loss": 0.078,
      "step": 1507
    },
    {
      "epoch": 5.14,
      "grad_norm": 0.3172549307346344,
      "learning_rate": 0.00019419597132127009,
      "loss": 0.0662,
      "step": 1508
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.32690101861953735,
      "learning_rate": 0.00019405940594059405,
      "loss": 0.0618,
      "step": 1509
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.3398485481739044,
      "learning_rate": 0.00019392284055991807,
      "loss": 0.0688,
      "step": 1510
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.34701472520828247,
      "learning_rate": 0.00019378627517924207,
      "loss": 0.0626,
      "step": 1511
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.34342867136001587,
      "learning_rate": 0.00019364970979856606,
      "loss": 0.0713,
      "step": 1512
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.3835356831550598,
      "learning_rate": 0.00019351314441789008,
      "loss": 0.0761,
      "step": 1513
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.32108479738235474,
      "learning_rate": 0.00019337657903721408,
      "loss": 0.073,
      "step": 1514
    },
    {
      "epoch": 5.17,
      "grad_norm": 0.31288865208625793,
      "learning_rate": 0.00019324001365653807,
      "loss": 0.0667,
      "step": 1515
    },
    {
      "epoch": 5.17,
      "grad_norm": 0.35712960362434387,
      "learning_rate": 0.0001931034482758621,
      "loss": 0.0717,
      "step": 1516
    },
    {
      "epoch": 5.17,
      "grad_norm": 0.3023334741592407,
      "learning_rate": 0.0001929668828951861,
      "loss": 0.057,
      "step": 1517
    },
    {
      "epoch": 5.18,
      "grad_norm": 0.3248802125453949,
      "learning_rate": 0.00019283031751451008,
      "loss": 0.0646,
      "step": 1518
    },
    {
      "epoch": 5.18,
      "grad_norm": 0.4016325771808624,
      "learning_rate": 0.00019269375213383408,
      "loss": 0.0696,
      "step": 1519
    },
    {
      "epoch": 5.18,
      "grad_norm": 0.33792006969451904,
      "learning_rate": 0.00019255718675315807,
      "loss": 0.064,
      "step": 1520
    },
    {
      "epoch": 5.19,
      "grad_norm": 0.3924632966518402,
      "learning_rate": 0.0001924206213724821,
      "loss": 0.0666,
      "step": 1521
    },
    {
      "epoch": 5.19,
      "grad_norm": 0.3000447750091553,
      "learning_rate": 0.00019228405599180609,
      "loss": 0.0737,
      "step": 1522
    },
    {
      "epoch": 5.19,
      "grad_norm": 0.30632859468460083,
      "learning_rate": 0.00019214749061113008,
      "loss": 0.0658,
      "step": 1523
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.34517765045166016,
      "learning_rate": 0.0001920109252304541,
      "loss": 0.0651,
      "step": 1524
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.3567304015159607,
      "learning_rate": 0.0001918743598497781,
      "loss": 0.0673,
      "step": 1525
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.34267234802246094,
      "learning_rate": 0.0001917377944691021,
      "loss": 0.0686,
      "step": 1526
    },
    {
      "epoch": 5.21,
      "grad_norm": 0.35095569491386414,
      "learning_rate": 0.0001916012290884261,
      "loss": 0.0706,
      "step": 1527
    },
    {
      "epoch": 5.21,
      "grad_norm": 0.3195610046386719,
      "learning_rate": 0.0001914646637077501,
      "loss": 0.0646,
      "step": 1528
    },
    {
      "epoch": 5.21,
      "grad_norm": 0.32430464029312134,
      "learning_rate": 0.0001913280983270741,
      "loss": 0.0737,
      "step": 1529
    },
    {
      "epoch": 5.22,
      "grad_norm": 0.3427524268627167,
      "learning_rate": 0.0001911915329463981,
      "loss": 0.0664,
      "step": 1530
    },
    {
      "epoch": 5.22,
      "grad_norm": 0.3497605621814728,
      "learning_rate": 0.0001910549675657221,
      "loss": 0.0741,
      "step": 1531
    },
    {
      "epoch": 5.22,
      "grad_norm": 0.33988383412361145,
      "learning_rate": 0.0001909184021850461,
      "loss": 0.0703,
      "step": 1532
    },
    {
      "epoch": 5.23,
      "grad_norm": 0.3197706341743469,
      "learning_rate": 0.0001907818368043701,
      "loss": 0.072,
      "step": 1533
    },
    {
      "epoch": 5.23,
      "grad_norm": 0.3244132995605469,
      "learning_rate": 0.0001906452714236941,
      "loss": 0.0609,
      "step": 1534
    },
    {
      "epoch": 5.23,
      "grad_norm": 0.4079059064388275,
      "learning_rate": 0.00019050870604301812,
      "loss": 0.0725,
      "step": 1535
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.31910791993141174,
      "learning_rate": 0.0001903721406623421,
      "loss": 0.0687,
      "step": 1536
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.41336309909820557,
      "learning_rate": 0.0001902355752816661,
      "loss": 0.0811,
      "step": 1537
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.33013829588890076,
      "learning_rate": 0.0001900990099009901,
      "loss": 0.0664,
      "step": 1538
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.3664257228374481,
      "learning_rate": 0.00018996244452031412,
      "loss": 0.0672,
      "step": 1539
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.36986616253852844,
      "learning_rate": 0.00018982587913963812,
      "loss": 0.0658,
      "step": 1540
    },
    {
      "epoch": 5.25,
      "grad_norm": 0.355871319770813,
      "learning_rate": 0.0001896893137589621,
      "loss": 0.0728,
      "step": 1541
    },
    {
      "epoch": 5.26,
      "grad_norm": 0.3417467474937439,
      "learning_rate": 0.0001895527483782861,
      "loss": 0.0651,
      "step": 1542
    },
    {
      "epoch": 5.26,
      "grad_norm": 0.35177117586135864,
      "learning_rate": 0.00018941618299761012,
      "loss": 0.0777,
      "step": 1543
    },
    {
      "epoch": 5.27,
      "grad_norm": 0.3506298065185547,
      "learning_rate": 0.00018927961761693412,
      "loss": 0.0764,
      "step": 1544
    },
    {
      "epoch": 5.27,
      "grad_norm": 0.3829716742038727,
      "learning_rate": 0.0001891430522362581,
      "loss": 0.0812,
      "step": 1545
    },
    {
      "epoch": 5.27,
      "grad_norm": 0.33997243642807007,
      "learning_rate": 0.0001890064868555821,
      "loss": 0.069,
      "step": 1546
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.32711243629455566,
      "learning_rate": 0.00018886992147490613,
      "loss": 0.0639,
      "step": 1547
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.2937215566635132,
      "learning_rate": 0.00018873335609423012,
      "loss": 0.0742,
      "step": 1548
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.3664388060569763,
      "learning_rate": 0.00018859679071355412,
      "loss": 0.0769,
      "step": 1549
    },
    {
      "epoch": 5.29,
      "grad_norm": 0.32952481508255005,
      "learning_rate": 0.00018846022533287814,
      "loss": 0.0657,
      "step": 1550
    },
    {
      "epoch": 5.29,
      "grad_norm": 0.3964177668094635,
      "learning_rate": 0.00018832365995220213,
      "loss": 0.0798,
      "step": 1551
    },
    {
      "epoch": 5.29,
      "grad_norm": 0.33290964365005493,
      "learning_rate": 0.00018818709457152613,
      "loss": 0.0741,
      "step": 1552
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.31504353880882263,
      "learning_rate": 0.00018805052919085012,
      "loss": 0.0764,
      "step": 1553
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.3228926360607147,
      "learning_rate": 0.00018791396381017411,
      "loss": 0.0721,
      "step": 1554
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.3532179892063141,
      "learning_rate": 0.00018777739842949814,
      "loss": 0.0759,
      "step": 1555
    },
    {
      "epoch": 5.31,
      "grad_norm": 0.3606696128845215,
      "learning_rate": 0.00018764083304882213,
      "loss": 0.0583,
      "step": 1556
    },
    {
      "epoch": 5.31,
      "grad_norm": 0.4106493592262268,
      "learning_rate": 0.00018750426766814612,
      "loss": 0.0875,
      "step": 1557
    },
    {
      "epoch": 5.31,
      "grad_norm": 0.34150904417037964,
      "learning_rate": 0.00018736770228747015,
      "loss": 0.074,
      "step": 1558
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.3467136323451996,
      "learning_rate": 0.00018723113690679414,
      "loss": 0.0708,
      "step": 1559
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.28427475690841675,
      "learning_rate": 0.00018709457152611813,
      "loss": 0.0572,
      "step": 1560
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.34894511103630066,
      "learning_rate": 0.00018695800614544215,
      "loss": 0.066,
      "step": 1561
    },
    {
      "epoch": 5.33,
      "grad_norm": 0.32096943259239197,
      "learning_rate": 0.00018682144076476612,
      "loss": 0.0652,
      "step": 1562
    },
    {
      "epoch": 5.33,
      "grad_norm": 0.3073258697986603,
      "learning_rate": 0.00018668487538409014,
      "loss": 0.066,
      "step": 1563
    },
    {
      "epoch": 5.33,
      "grad_norm": 0.3097512423992157,
      "learning_rate": 0.00018654831000341414,
      "loss": 0.056,
      "step": 1564
    },
    {
      "epoch": 5.34,
      "grad_norm": 0.3816448152065277,
      "learning_rate": 0.00018641174462273813,
      "loss": 0.0699,
      "step": 1565
    },
    {
      "epoch": 5.34,
      "grad_norm": 0.29534485936164856,
      "learning_rate": 0.00018627517924206215,
      "loss": 0.0628,
      "step": 1566
    },
    {
      "epoch": 5.34,
      "grad_norm": 0.3512754440307617,
      "learning_rate": 0.00018613861386138615,
      "loss": 0.0693,
      "step": 1567
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.34783557057380676,
      "learning_rate": 0.00018600204848071014,
      "loss": 0.0666,
      "step": 1568
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.33007100224494934,
      "learning_rate": 0.00018586548310003416,
      "loss": 0.0702,
      "step": 1569
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.36544427275657654,
      "learning_rate": 0.00018572891771935813,
      "loss": 0.0716,
      "step": 1570
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.34248584508895874,
      "learning_rate": 0.00018559235233868215,
      "loss": 0.0676,
      "step": 1571
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.3516068458557129,
      "learning_rate": 0.00018545578695800617,
      "loss": 0.0657,
      "step": 1572
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.33073437213897705,
      "learning_rate": 0.00018531922157733014,
      "loss": 0.0717,
      "step": 1573
    },
    {
      "epoch": 5.37,
      "grad_norm": 0.3822007179260254,
      "learning_rate": 0.00018518265619665416,
      "loss": 0.0723,
      "step": 1574
    },
    {
      "epoch": 5.37,
      "grad_norm": 0.4278223216533661,
      "learning_rate": 0.00018504609081597818,
      "loss": 0.0823,
      "step": 1575
    },
    {
      "epoch": 5.37,
      "grad_norm": 0.3589874505996704,
      "learning_rate": 0.00018490952543530215,
      "loss": 0.0735,
      "step": 1576
    },
    {
      "epoch": 5.38,
      "grad_norm": 0.31271955370903015,
      "learning_rate": 0.00018477296005462617,
      "loss": 0.0654,
      "step": 1577
    },
    {
      "epoch": 5.38,
      "grad_norm": 0.35223937034606934,
      "learning_rate": 0.00018463639467395016,
      "loss": 0.0732,
      "step": 1578
    },
    {
      "epoch": 5.38,
      "grad_norm": 0.3407895863056183,
      "learning_rate": 0.00018449982929327416,
      "loss": 0.0755,
      "step": 1579
    },
    {
      "epoch": 5.39,
      "grad_norm": 0.3751716613769531,
      "learning_rate": 0.00018436326391259818,
      "loss": 0.0722,
      "step": 1580
    },
    {
      "epoch": 5.39,
      "grad_norm": 0.31074362993240356,
      "learning_rate": 0.00018422669853192215,
      "loss": 0.0695,
      "step": 1581
    },
    {
      "epoch": 5.39,
      "grad_norm": 0.3561902940273285,
      "learning_rate": 0.00018409013315124617,
      "loss": 0.0717,
      "step": 1582
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.34651196002960205,
      "learning_rate": 0.0001839535677705702,
      "loss": 0.0699,
      "step": 1583
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.310001015663147,
      "learning_rate": 0.00018381700238989416,
      "loss": 0.0637,
      "step": 1584
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.3490409553050995,
      "learning_rate": 0.00018368043700921818,
      "loss": 0.0706,
      "step": 1585
    },
    {
      "epoch": 5.41,
      "grad_norm": 0.35389629006385803,
      "learning_rate": 0.00018354387162854217,
      "loss": 0.0787,
      "step": 1586
    },
    {
      "epoch": 5.41,
      "grad_norm": 0.33963412046432495,
      "learning_rate": 0.00018340730624786617,
      "loss": 0.0656,
      "step": 1587
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.32629188895225525,
      "learning_rate": 0.00018327074086719019,
      "loss": 0.0726,
      "step": 1588
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.3920169174671173,
      "learning_rate": 0.00018313417548651418,
      "loss": 0.0723,
      "step": 1589
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.3320388197898865,
      "learning_rate": 0.00018299761010583817,
      "loss": 0.0642,
      "step": 1590
    },
    {
      "epoch": 5.43,
      "grad_norm": 0.33136409521102905,
      "learning_rate": 0.0001828610447251622,
      "loss": 0.0636,
      "step": 1591
    },
    {
      "epoch": 5.43,
      "grad_norm": 0.3083954453468323,
      "learning_rate": 0.0001827244793444862,
      "loss": 0.0634,
      "step": 1592
    },
    {
      "epoch": 5.43,
      "grad_norm": 0.35582852363586426,
      "learning_rate": 0.00018258791396381018,
      "loss": 0.0756,
      "step": 1593
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.3406873643398285,
      "learning_rate": 0.00018245134858313418,
      "loss": 0.0638,
      "step": 1594
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.3493720591068268,
      "learning_rate": 0.00018231478320245817,
      "loss": 0.0655,
      "step": 1595
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.3432040512561798,
      "learning_rate": 0.0001821782178217822,
      "loss": 0.0683,
      "step": 1596
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.3890399932861328,
      "learning_rate": 0.0001820416524411062,
      "loss": 0.0794,
      "step": 1597
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.3379170596599579,
      "learning_rate": 0.00018190508706043018,
      "loss": 0.0783,
      "step": 1598
    },
    {
      "epoch": 5.45,
      "grad_norm": 0.32529279589653015,
      "learning_rate": 0.0001817685216797542,
      "loss": 0.0675,
      "step": 1599
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.3628244996070862,
      "learning_rate": 0.0001816319562990782,
      "loss": 0.0813,
      "step": 1600
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.32885250449180603,
      "learning_rate": 0.0001814953909184022,
      "loss": 0.0696,
      "step": 1601
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.30822983384132385,
      "learning_rate": 0.00018135882553772619,
      "loss": 0.0643,
      "step": 1602
    },
    {
      "epoch": 5.47,
      "grad_norm": 0.31839653849601746,
      "learning_rate": 0.0001812222601570502,
      "loss": 0.0661,
      "step": 1603
    },
    {
      "epoch": 5.47,
      "grad_norm": 0.3489604890346527,
      "learning_rate": 0.0001810856947763742,
      "loss": 0.0739,
      "step": 1604
    },
    {
      "epoch": 5.47,
      "grad_norm": 0.3464997708797455,
      "learning_rate": 0.0001809491293956982,
      "loss": 0.0618,
      "step": 1605
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.38572052121162415,
      "learning_rate": 0.0001808125640150222,
      "loss": 0.0775,
      "step": 1606
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.34444284439086914,
      "learning_rate": 0.0001806759986343462,
      "loss": 0.0748,
      "step": 1607
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.32591724395751953,
      "learning_rate": 0.0001805394332536702,
      "loss": 0.0656,
      "step": 1608
    },
    {
      "epoch": 5.49,
      "grad_norm": 0.33943411707878113,
      "learning_rate": 0.0001804028678729942,
      "loss": 0.0694,
      "step": 1609
    },
    {
      "epoch": 5.49,
      "grad_norm": 0.3733276128768921,
      "learning_rate": 0.0001802663024923182,
      "loss": 0.0748,
      "step": 1610
    },
    {
      "epoch": 5.49,
      "grad_norm": 0.34659209847450256,
      "learning_rate": 0.00018012973711164221,
      "loss": 0.0754,
      "step": 1611
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.3433821499347687,
      "learning_rate": 0.0001799931717309662,
      "loss": 0.0716,
      "step": 1612
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.30931270122528076,
      "learning_rate": 0.0001798566063502902,
      "loss": 0.0617,
      "step": 1613
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.34607037901878357,
      "learning_rate": 0.00017972004096961422,
      "loss": 0.0725,
      "step": 1614
    },
    {
      "epoch": 5.51,
      "grad_norm": 0.36173173785209656,
      "learning_rate": 0.00017958347558893822,
      "loss": 0.0738,
      "step": 1615
    },
    {
      "epoch": 5.51,
      "grad_norm": 0.31279388070106506,
      "learning_rate": 0.0001794469102082622,
      "loss": 0.0727,
      "step": 1616
    },
    {
      "epoch": 5.51,
      "grad_norm": 0.3127437233924866,
      "learning_rate": 0.0001793103448275862,
      "loss": 0.0606,
      "step": 1617
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.4009944200515747,
      "learning_rate": 0.0001791737794469102,
      "loss": 0.0752,
      "step": 1618
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.38957273960113525,
      "learning_rate": 0.00017903721406623422,
      "loss": 0.0779,
      "step": 1619
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.36151185631752014,
      "learning_rate": 0.00017890064868555822,
      "loss": 0.085,
      "step": 1620
    },
    {
      "epoch": 5.53,
      "grad_norm": 0.29465794563293457,
      "learning_rate": 0.0001787640833048822,
      "loss": 0.0585,
      "step": 1621
    },
    {
      "epoch": 5.53,
      "grad_norm": 0.3526611626148224,
      "learning_rate": 0.00017862751792420623,
      "loss": 0.0774,
      "step": 1622
    },
    {
      "epoch": 5.53,
      "grad_norm": 0.3774256408214569,
      "learning_rate": 0.00017849095254353023,
      "loss": 0.0819,
      "step": 1623
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.3555929362773895,
      "learning_rate": 0.00017835438716285422,
      "loss": 0.0636,
      "step": 1624
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.3215370178222656,
      "learning_rate": 0.00017821782178217824,
      "loss": 0.0702,
      "step": 1625
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.29388880729675293,
      "learning_rate": 0.0001780812564015022,
      "loss": 0.0647,
      "step": 1626
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.27704301476478577,
      "learning_rate": 0.00017794469102082623,
      "loss": 0.0628,
      "step": 1627
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.34346985816955566,
      "learning_rate": 0.00017780812564015022,
      "loss": 0.0787,
      "step": 1628
    },
    {
      "epoch": 5.55,
      "grad_norm": 0.33279886841773987,
      "learning_rate": 0.00017767156025947422,
      "loss": 0.0693,
      "step": 1629
    },
    {
      "epoch": 5.56,
      "grad_norm": 0.349695086479187,
      "learning_rate": 0.00017753499487879824,
      "loss": 0.0685,
      "step": 1630
    },
    {
      "epoch": 5.56,
      "grad_norm": 0.3158538341522217,
      "learning_rate": 0.00017739842949812223,
      "loss": 0.0571,
      "step": 1631
    },
    {
      "epoch": 5.57,
      "grad_norm": 0.3882369101047516,
      "learning_rate": 0.00017726186411744623,
      "loss": 0.072,
      "step": 1632
    },
    {
      "epoch": 5.57,
      "grad_norm": 0.35186469554901123,
      "learning_rate": 0.00017712529873677025,
      "loss": 0.0711,
      "step": 1633
    },
    {
      "epoch": 5.57,
      "grad_norm": 0.360072523355484,
      "learning_rate": 0.00017698873335609424,
      "loss": 0.0711,
      "step": 1634
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.3913479149341583,
      "learning_rate": 0.00017685216797541824,
      "loss": 0.0748,
      "step": 1635
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.29921117424964905,
      "learning_rate": 0.00017671560259474226,
      "loss": 0.0559,
      "step": 1636
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.33582741022109985,
      "learning_rate": 0.00017657903721406622,
      "loss": 0.0717,
      "step": 1637
    },
    {
      "epoch": 5.59,
      "grad_norm": 0.3426766097545624,
      "learning_rate": 0.00017644247183339025,
      "loss": 0.0655,
      "step": 1638
    },
    {
      "epoch": 5.59,
      "grad_norm": 0.307269811630249,
      "learning_rate": 0.00017630590645271427,
      "loss": 0.0616,
      "step": 1639
    },
    {
      "epoch": 5.59,
      "grad_norm": 0.3315980136394501,
      "learning_rate": 0.00017616934107203823,
      "loss": 0.0661,
      "step": 1640
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.3688851594924927,
      "learning_rate": 0.00017603277569136226,
      "loss": 0.0761,
      "step": 1641
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.31265443563461304,
      "learning_rate": 0.00017589621031068625,
      "loss": 0.0667,
      "step": 1642
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.3640306293964386,
      "learning_rate": 0.00017575964493001024,
      "loss": 0.0651,
      "step": 1643
    },
    {
      "epoch": 5.61,
      "grad_norm": 0.3720439672470093,
      "learning_rate": 0.00017562307954933426,
      "loss": 0.0804,
      "step": 1644
    },
    {
      "epoch": 5.61,
      "grad_norm": 0.3713473379611969,
      "learning_rate": 0.00017548651416865823,
      "loss": 0.0713,
      "step": 1645
    },
    {
      "epoch": 5.61,
      "grad_norm": 1.5305079221725464,
      "learning_rate": 0.00017534994878798225,
      "loss": 0.0642,
      "step": 1646
    },
    {
      "epoch": 5.62,
      "grad_norm": 0.2676602602005005,
      "learning_rate": 0.00017521338340730627,
      "loss": 0.0534,
      "step": 1647
    },
    {
      "epoch": 5.62,
      "grad_norm": 0.3354998528957367,
      "learning_rate": 0.00017507681802663024,
      "loss": 0.0708,
      "step": 1648
    },
    {
      "epoch": 5.62,
      "grad_norm": 0.3390306532382965,
      "learning_rate": 0.00017494025264595426,
      "loss": 0.0743,
      "step": 1649
    },
    {
      "epoch": 5.63,
      "grad_norm": 0.3113814890384674,
      "learning_rate": 0.00017480368726527828,
      "loss": 0.0733,
      "step": 1650
    },
    {
      "epoch": 5.63,
      "grad_norm": 0.37810593843460083,
      "learning_rate": 0.00017466712188460225,
      "loss": 0.0831,
      "step": 1651
    },
    {
      "epoch": 5.63,
      "grad_norm": 0.33792048692703247,
      "learning_rate": 0.00017453055650392627,
      "loss": 0.0715,
      "step": 1652
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.3481842279434204,
      "learning_rate": 0.00017439399112325027,
      "loss": 0.0751,
      "step": 1653
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.3404812812805176,
      "learning_rate": 0.00017425742574257426,
      "loss": 0.0695,
      "step": 1654
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.31662479043006897,
      "learning_rate": 0.00017412086036189828,
      "loss": 0.0676,
      "step": 1655
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.353133887052536,
      "learning_rate": 0.00017398429498122225,
      "loss": 0.0625,
      "step": 1656
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.34623149037361145,
      "learning_rate": 0.00017384772960054627,
      "loss": 0.0698,
      "step": 1657
    },
    {
      "epoch": 5.65,
      "grad_norm": 0.3883180320262909,
      "learning_rate": 0.0001737111642198703,
      "loss": 0.0887,
      "step": 1658
    },
    {
      "epoch": 5.66,
      "grad_norm": 0.37482866644859314,
      "learning_rate": 0.00017357459883919426,
      "loss": 0.0746,
      "step": 1659
    },
    {
      "epoch": 5.66,
      "grad_norm": 0.31609025597572327,
      "learning_rate": 0.00017343803345851828,
      "loss": 0.0614,
      "step": 1660
    },
    {
      "epoch": 5.66,
      "grad_norm": 0.35787707567214966,
      "learning_rate": 0.00017330146807784227,
      "loss": 0.0729,
      "step": 1661
    },
    {
      "epoch": 5.67,
      "grad_norm": 0.3222653269767761,
      "learning_rate": 0.00017316490269716627,
      "loss": 0.0627,
      "step": 1662
    },
    {
      "epoch": 5.67,
      "grad_norm": 0.3390509784221649,
      "learning_rate": 0.0001730283373164903,
      "loss": 0.0759,
      "step": 1663
    },
    {
      "epoch": 5.67,
      "grad_norm": 0.3520734906196594,
      "learning_rate": 0.00017289177193581428,
      "loss": 0.0684,
      "step": 1664
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.3724004328250885,
      "learning_rate": 0.00017275520655513828,
      "loss": 0.0819,
      "step": 1665
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.3544366657733917,
      "learning_rate": 0.0001726186411744623,
      "loss": 0.0671,
      "step": 1666
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.34365180134773254,
      "learning_rate": 0.0001724820757937863,
      "loss": 0.0707,
      "step": 1667
    },
    {
      "epoch": 5.69,
      "grad_norm": 0.40785151720046997,
      "learning_rate": 0.0001723455104131103,
      "loss": 0.0844,
      "step": 1668
    },
    {
      "epoch": 5.69,
      "grad_norm": 0.3612571954727173,
      "learning_rate": 0.00017220894503243428,
      "loss": 0.065,
      "step": 1669
    },
    {
      "epoch": 5.69,
      "grad_norm": 0.3600432276725769,
      "learning_rate": 0.00017207237965175828,
      "loss": 0.0791,
      "step": 1670
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.3508896827697754,
      "learning_rate": 0.0001719358142710823,
      "loss": 0.0671,
      "step": 1671
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.35256052017211914,
      "learning_rate": 0.0001717992488904063,
      "loss": 0.0685,
      "step": 1672
    },
    {
      "epoch": 5.71,
      "grad_norm": 0.3937649130821228,
      "learning_rate": 0.00017166268350973028,
      "loss": 0.0787,
      "step": 1673
    },
    {
      "epoch": 5.71,
      "grad_norm": 0.3146854639053345,
      "learning_rate": 0.0001715261181290543,
      "loss": 0.0646,
      "step": 1674
    },
    {
      "epoch": 5.71,
      "grad_norm": 0.3129865527153015,
      "learning_rate": 0.0001713895527483783,
      "loss": 0.0667,
      "step": 1675
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.3160679340362549,
      "learning_rate": 0.0001712529873677023,
      "loss": 0.0687,
      "step": 1676
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.3586801290512085,
      "learning_rate": 0.0001711164219870263,
      "loss": 0.0625,
      "step": 1677
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.3611689507961273,
      "learning_rate": 0.0001709798566063503,
      "loss": 0.071,
      "step": 1678
    },
    {
      "epoch": 5.73,
      "grad_norm": 0.32646921277046204,
      "learning_rate": 0.0001708432912256743,
      "loss": 0.0724,
      "step": 1679
    },
    {
      "epoch": 5.73,
      "grad_norm": 0.3438551723957062,
      "learning_rate": 0.0001707067258449983,
      "loss": 0.0734,
      "step": 1680
    },
    {
      "epoch": 5.73,
      "grad_norm": 0.3439573347568512,
      "learning_rate": 0.0001705701604643223,
      "loss": 0.0671,
      "step": 1681
    },
    {
      "epoch": 5.74,
      "grad_norm": 0.3441942632198334,
      "learning_rate": 0.0001704335950836463,
      "loss": 0.0641,
      "step": 1682
    },
    {
      "epoch": 5.74,
      "grad_norm": 0.35302695631980896,
      "learning_rate": 0.0001702970297029703,
      "loss": 0.0606,
      "step": 1683
    },
    {
      "epoch": 5.74,
      "grad_norm": 0.34783971309661865,
      "learning_rate": 0.0001701604643222943,
      "loss": 0.0721,
      "step": 1684
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.3457019329071045,
      "learning_rate": 0.0001700238989416183,
      "loss": 0.074,
      "step": 1685
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.3112567961215973,
      "learning_rate": 0.00016988733356094232,
      "loss": 0.0687,
      "step": 1686
    },
    {
      "epoch": 5.75,
      "grad_norm": 0.3122674226760864,
      "learning_rate": 0.0001697507681802663,
      "loss": 0.0658,
      "step": 1687
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.3454590439796448,
      "learning_rate": 0.0001696142027995903,
      "loss": 0.0773,
      "step": 1688
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.30267852544784546,
      "learning_rate": 0.00016947763741891433,
      "loss": 0.0634,
      "step": 1689
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.25762200355529785,
      "learning_rate": 0.00016934107203823832,
      "loss": 0.0597,
      "step": 1690
    },
    {
      "epoch": 5.77,
      "grad_norm": 0.32357263565063477,
      "learning_rate": 0.00016920450665756231,
      "loss": 0.0717,
      "step": 1691
    },
    {
      "epoch": 5.77,
      "grad_norm": 0.37627384066581726,
      "learning_rate": 0.0001690679412768863,
      "loss": 0.0789,
      "step": 1692
    },
    {
      "epoch": 5.77,
      "grad_norm": 0.348939448595047,
      "learning_rate": 0.0001689313758962103,
      "loss": 0.0724,
      "step": 1693
    },
    {
      "epoch": 5.78,
      "grad_norm": 0.355587899684906,
      "learning_rate": 0.00016879481051553432,
      "loss": 0.072,
      "step": 1694
    },
    {
      "epoch": 5.78,
      "grad_norm": 0.3096280097961426,
      "learning_rate": 0.00016865824513485832,
      "loss": 0.062,
      "step": 1695
    },
    {
      "epoch": 5.78,
      "grad_norm": 0.33475735783576965,
      "learning_rate": 0.0001685216797541823,
      "loss": 0.0677,
      "step": 1696
    },
    {
      "epoch": 5.79,
      "grad_norm": 0.4205711781978607,
      "learning_rate": 0.00016838511437350633,
      "loss": 0.0708,
      "step": 1697
    },
    {
      "epoch": 5.79,
      "grad_norm": 0.3334733247756958,
      "learning_rate": 0.00016824854899283033,
      "loss": 0.0702,
      "step": 1698
    },
    {
      "epoch": 5.79,
      "grad_norm": 0.29289719462394714,
      "learning_rate": 0.00016811198361215432,
      "loss": 0.0596,
      "step": 1699
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.3059764504432678,
      "learning_rate": 0.00016797541823147834,
      "loss": 0.0643,
      "step": 1700
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.2892500162124634,
      "learning_rate": 0.0001678388528508023,
      "loss": 0.0569,
      "step": 1701
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.33708661794662476,
      "learning_rate": 0.00016770228747012633,
      "loss": 0.0709,
      "step": 1702
    },
    {
      "epoch": 5.81,
      "grad_norm": 0.3264619708061218,
      "learning_rate": 0.00016756572208945033,
      "loss": 0.067,
      "step": 1703
    },
    {
      "epoch": 5.81,
      "grad_norm": 0.37959522008895874,
      "learning_rate": 0.00016742915670877432,
      "loss": 0.0733,
      "step": 1704
    },
    {
      "epoch": 5.81,
      "grad_norm": 0.33454447984695435,
      "learning_rate": 0.00016729259132809834,
      "loss": 0.0625,
      "step": 1705
    },
    {
      "epoch": 5.82,
      "grad_norm": 0.2910950183868408,
      "learning_rate": 0.00016715602594742234,
      "loss": 0.0561,
      "step": 1706
    },
    {
      "epoch": 5.82,
      "grad_norm": 0.2915467619895935,
      "learning_rate": 0.00016701946056674633,
      "loss": 0.0615,
      "step": 1707
    },
    {
      "epoch": 5.82,
      "grad_norm": 0.3309738039970398,
      "learning_rate": 0.00016688289518607035,
      "loss": 0.063,
      "step": 1708
    },
    {
      "epoch": 5.83,
      "grad_norm": 0.34512269496917725,
      "learning_rate": 0.00016674632980539432,
      "loss": 0.0714,
      "step": 1709
    },
    {
      "epoch": 5.83,
      "grad_norm": 0.33787062764167786,
      "learning_rate": 0.00016660976442471834,
      "loss": 0.0649,
      "step": 1710
    },
    {
      "epoch": 5.83,
      "grad_norm": 0.31520965695381165,
      "learning_rate": 0.00016647319904404236,
      "loss": 0.0614,
      "step": 1711
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.35259997844696045,
      "learning_rate": 0.00016633663366336633,
      "loss": 0.0574,
      "step": 1712
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.30822810530662537,
      "learning_rate": 0.00016620006828269035,
      "loss": 0.0567,
      "step": 1713
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.351807177066803,
      "learning_rate": 0.00016606350290201437,
      "loss": 0.0687,
      "step": 1714
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.33687692880630493,
      "learning_rate": 0.00016592693752133834,
      "loss": 0.0652,
      "step": 1715
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.3030819594860077,
      "learning_rate": 0.00016579037214066236,
      "loss": 0.0612,
      "step": 1716
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.338060200214386,
      "learning_rate": 0.00016565380675998635,
      "loss": 0.0696,
      "step": 1717
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.4051430821418762,
      "learning_rate": 0.00016551724137931035,
      "loss": 0.0805,
      "step": 1718
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.3190195858478546,
      "learning_rate": 0.00016538067599863437,
      "loss": 0.0608,
      "step": 1719
    },
    {
      "epoch": 5.87,
      "grad_norm": 0.35475409030914307,
      "learning_rate": 0.00016524411061795833,
      "loss": 0.0746,
      "step": 1720
    },
    {
      "epoch": 5.87,
      "grad_norm": 0.3157251179218292,
      "learning_rate": 0.00016510754523728236,
      "loss": 0.0679,
      "step": 1721
    },
    {
      "epoch": 5.87,
      "grad_norm": 0.30528098344802856,
      "learning_rate": 0.00016497097985660638,
      "loss": 0.0649,
      "step": 1722
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.33273202180862427,
      "learning_rate": 0.00016483441447593034,
      "loss": 0.0655,
      "step": 1723
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.3653239905834198,
      "learning_rate": 0.00016469784909525437,
      "loss": 0.0776,
      "step": 1724
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.3535367548465729,
      "learning_rate": 0.00016456128371457836,
      "loss": 0.073,
      "step": 1725
    },
    {
      "epoch": 5.89,
      "grad_norm": 0.335769385099411,
      "learning_rate": 0.00016442471833390235,
      "loss": 0.0622,
      "step": 1726
    },
    {
      "epoch": 5.89,
      "grad_norm": 0.30276283621788025,
      "learning_rate": 0.00016428815295322637,
      "loss": 0.064,
      "step": 1727
    },
    {
      "epoch": 5.89,
      "grad_norm": 0.35170578956604004,
      "learning_rate": 0.00016415158757255037,
      "loss": 0.075,
      "step": 1728
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.33023756742477417,
      "learning_rate": 0.00016401502219187436,
      "loss": 0.0687,
      "step": 1729
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.38983458280563354,
      "learning_rate": 0.00016387845681119838,
      "loss": 0.0714,
      "step": 1730
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.350766122341156,
      "learning_rate": 0.00016374189143052238,
      "loss": 0.0699,
      "step": 1731
    },
    {
      "epoch": 5.91,
      "grad_norm": 0.36954185366630554,
      "learning_rate": 0.00016360532604984637,
      "loss": 0.0749,
      "step": 1732
    },
    {
      "epoch": 5.91,
      "grad_norm": 0.3187588155269623,
      "learning_rate": 0.00016346876066917037,
      "loss": 0.0598,
      "step": 1733
    },
    {
      "epoch": 5.91,
      "grad_norm": 0.31767237186431885,
      "learning_rate": 0.00016333219528849436,
      "loss": 0.0614,
      "step": 1734
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.29891642928123474,
      "learning_rate": 0.00016319562990781838,
      "loss": 0.0624,
      "step": 1735
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.3215799033641815,
      "learning_rate": 0.00016305906452714238,
      "loss": 0.0615,
      "step": 1736
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.3284009099006653,
      "learning_rate": 0.00016292249914646637,
      "loss": 0.0663,
      "step": 1737
    },
    {
      "epoch": 5.93,
      "grad_norm": 0.3144752085208893,
      "learning_rate": 0.0001627859337657904,
      "loss": 0.0569,
      "step": 1738
    },
    {
      "epoch": 5.93,
      "grad_norm": 0.3231860101222992,
      "learning_rate": 0.00016264936838511439,
      "loss": 0.0677,
      "step": 1739
    },
    {
      "epoch": 5.93,
      "grad_norm": 0.2895374298095703,
      "learning_rate": 0.00016251280300443838,
      "loss": 0.06,
      "step": 1740
    },
    {
      "epoch": 5.94,
      "grad_norm": 0.3636800944805145,
      "learning_rate": 0.0001623762376237624,
      "loss": 0.0799,
      "step": 1741
    },
    {
      "epoch": 5.94,
      "grad_norm": 0.3278675675392151,
      "learning_rate": 0.0001622396722430864,
      "loss": 0.069,
      "step": 1742
    },
    {
      "epoch": 5.94,
      "grad_norm": 0.3785158097743988,
      "learning_rate": 0.0001621031068624104,
      "loss": 0.0789,
      "step": 1743
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.3288118541240692,
      "learning_rate": 0.00016196654148173438,
      "loss": 0.0608,
      "step": 1744
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.2989487648010254,
      "learning_rate": 0.00016182997610105838,
      "loss": 0.0587,
      "step": 1745
    },
    {
      "epoch": 5.95,
      "grad_norm": 0.3349917232990265,
      "learning_rate": 0.0001616934107203824,
      "loss": 0.0736,
      "step": 1746
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.3836369812488556,
      "learning_rate": 0.0001615568453397064,
      "loss": 0.0744,
      "step": 1747
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.313242644071579,
      "learning_rate": 0.0001614202799590304,
      "loss": 0.062,
      "step": 1748
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.317844957113266,
      "learning_rate": 0.0001612837145783544,
      "loss": 0.0687,
      "step": 1749
    },
    {
      "epoch": 5.97,
      "grad_norm": 0.29437562823295593,
      "learning_rate": 0.0001611471491976784,
      "loss": 0.0621,
      "step": 1750
    },
    {
      "epoch": 5.97,
      "grad_norm": 0.3292478024959564,
      "learning_rate": 0.0001610105838170024,
      "loss": 0.0727,
      "step": 1751
    },
    {
      "epoch": 5.97,
      "grad_norm": 0.27738338708877563,
      "learning_rate": 0.0001608740184363264,
      "loss": 0.0612,
      "step": 1752
    },
    {
      "epoch": 5.98,
      "grad_norm": 0.32084816694259644,
      "learning_rate": 0.0001607374530556504,
      "loss": 0.0669,
      "step": 1753
    },
    {
      "epoch": 5.98,
      "grad_norm": 0.32851576805114746,
      "learning_rate": 0.0001606008876749744,
      "loss": 0.0664,
      "step": 1754
    },
    {
      "epoch": 5.98,
      "grad_norm": 0.3387250602245331,
      "learning_rate": 0.0001604643222942984,
      "loss": 0.0619,
      "step": 1755
    },
    {
      "epoch": 5.99,
      "grad_norm": 0.36410871148109436,
      "learning_rate": 0.0001603277569136224,
      "loss": 0.0692,
      "step": 1756
    },
    {
      "epoch": 5.99,
      "grad_norm": 0.31704026460647583,
      "learning_rate": 0.00016019119153294642,
      "loss": 0.0591,
      "step": 1757
    },
    {
      "epoch": 5.99,
      "grad_norm": 0.32279786467552185,
      "learning_rate": 0.0001600546261522704,
      "loss": 0.0634,
      "step": 1758
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2750723361968994,
      "learning_rate": 0.0001599180607715944,
      "loss": 0.057,
      "step": 1759
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.32976701855659485,
      "learning_rate": 0.0001597814953909184,
      "loss": 0.0637,
      "step": 1760
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.22905269265174866,
      "learning_rate": 0.00015964493001024242,
      "loss": 0.0448,
      "step": 1761
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.2613821029663086,
      "learning_rate": 0.00015950836462956641,
      "loss": 0.0455,
      "step": 1762
    },
    {
      "epoch": 6.01,
      "grad_norm": 0.24872489273548126,
      "learning_rate": 0.0001593717992488904,
      "loss": 0.0365,
      "step": 1763
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.26074182987213135,
      "learning_rate": 0.00015923523386821443,
      "loss": 0.0426,
      "step": 1764
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.3057127296924591,
      "learning_rate": 0.00015909866848753842,
      "loss": 0.0483,
      "step": 1765
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.303374707698822,
      "learning_rate": 0.00015896210310686242,
      "loss": 0.0389,
      "step": 1766
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.2755545973777771,
      "learning_rate": 0.0001588255377261864,
      "loss": 0.0361,
      "step": 1767
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.41784998774528503,
      "learning_rate": 0.0001586889723455104,
      "loss": 0.0488,
      "step": 1768
    },
    {
      "epoch": 6.03,
      "grad_norm": 0.3623383045196533,
      "learning_rate": 0.00015855240696483443,
      "loss": 0.044,
      "step": 1769
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.302849680185318,
      "learning_rate": 0.00015841584158415842,
      "loss": 0.0382,
      "step": 1770
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.3422788679599762,
      "learning_rate": 0.00015827927620348242,
      "loss": 0.0369,
      "step": 1771
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.334575355052948,
      "learning_rate": 0.00015814271082280644,
      "loss": 0.0429,
      "step": 1772
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.33621644973754883,
      "learning_rate": 0.00015800614544213043,
      "loss": 0.0459,
      "step": 1773
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.32231226563453674,
      "learning_rate": 0.00015786958006145442,
      "loss": 0.0413,
      "step": 1774
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.3492160141468048,
      "learning_rate": 0.00015773301468077845,
      "loss": 0.0492,
      "step": 1775
    },
    {
      "epoch": 6.06,
      "grad_norm": 0.2782396376132965,
      "learning_rate": 0.0001575964493001024,
      "loss": 0.0388,
      "step": 1776
    },
    {
      "epoch": 6.06,
      "grad_norm": 0.2971923053264618,
      "learning_rate": 0.00015745988391942643,
      "loss": 0.0432,
      "step": 1777
    },
    {
      "epoch": 6.06,
      "grad_norm": 0.29518139362335205,
      "learning_rate": 0.00015732331853875043,
      "loss": 0.0448,
      "step": 1778
    },
    {
      "epoch": 6.07,
      "grad_norm": 0.30050745606422424,
      "learning_rate": 0.00015718675315807442,
      "loss": 0.0458,
      "step": 1779
    },
    {
      "epoch": 6.07,
      "grad_norm": 0.318877249956131,
      "learning_rate": 0.00015705018777739844,
      "loss": 0.0526,
      "step": 1780
    },
    {
      "epoch": 6.07,
      "grad_norm": 0.27623477578163147,
      "learning_rate": 0.00015691362239672244,
      "loss": 0.0417,
      "step": 1781
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.33222314715385437,
      "learning_rate": 0.00015677705701604643,
      "loss": 0.0491,
      "step": 1782
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.29032647609710693,
      "learning_rate": 0.00015664049163537045,
      "loss": 0.0407,
      "step": 1783
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.2787192463874817,
      "learning_rate": 0.00015650392625469442,
      "loss": 0.0406,
      "step": 1784
    },
    {
      "epoch": 6.09,
      "grad_norm": 0.35046669840812683,
      "learning_rate": 0.00015636736087401844,
      "loss": 0.0481,
      "step": 1785
    },
    {
      "epoch": 6.09,
      "grad_norm": 0.2999608814716339,
      "learning_rate": 0.00015623079549334246,
      "loss": 0.0445,
      "step": 1786
    },
    {
      "epoch": 6.09,
      "grad_norm": 0.32988592982292175,
      "learning_rate": 0.00015609423011266643,
      "loss": 0.05,
      "step": 1787
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.2782198190689087,
      "learning_rate": 0.00015595766473199045,
      "loss": 0.0395,
      "step": 1788
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.3349972665309906,
      "learning_rate": 0.00015582109935131447,
      "loss": 0.0495,
      "step": 1789
    },
    {
      "epoch": 6.1,
      "grad_norm": 0.2745943069458008,
      "learning_rate": 0.00015568453397063844,
      "loss": 0.0401,
      "step": 1790
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.3719400465488434,
      "learning_rate": 0.00015554796858996246,
      "loss": 0.0525,
      "step": 1791
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.2968427836894989,
      "learning_rate": 0.00015541140320928645,
      "loss": 0.0417,
      "step": 1792
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.3413950204849243,
      "learning_rate": 0.00015527483782861045,
      "loss": 0.0533,
      "step": 1793
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.3121582865715027,
      "learning_rate": 0.00015513827244793447,
      "loss": 0.0442,
      "step": 1794
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.3141803443431854,
      "learning_rate": 0.00015500170706725844,
      "loss": 0.0446,
      "step": 1795
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.3651014566421509,
      "learning_rate": 0.00015486514168658246,
      "loss": 0.0518,
      "step": 1796
    },
    {
      "epoch": 6.13,
      "grad_norm": 0.30956360697746277,
      "learning_rate": 0.00015472857630590648,
      "loss": 0.0443,
      "step": 1797
    },
    {
      "epoch": 6.13,
      "grad_norm": 0.2819195091724396,
      "learning_rate": 0.00015459201092523045,
      "loss": 0.0414,
      "step": 1798
    },
    {
      "epoch": 6.13,
      "grad_norm": 0.33730530738830566,
      "learning_rate": 0.00015445544554455447,
      "loss": 0.0489,
      "step": 1799
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.2910168468952179,
      "learning_rate": 0.00015431888016387846,
      "loss": 0.0416,
      "step": 1800
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.2705249786376953,
      "learning_rate": 0.00015418231478320246,
      "loss": 0.0432,
      "step": 1801
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.2878706157207489,
      "learning_rate": 0.00015404574940252648,
      "loss": 0.0414,
      "step": 1802
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.3129920959472656,
      "learning_rate": 0.00015390918402185047,
      "loss": 0.0413,
      "step": 1803
    },
    {
      "epoch": 6.15,
      "grad_norm": 0.2639618217945099,
      "learning_rate": 0.00015377261864117447,
      "loss": 0.0449,
      "step": 1804
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.30115577578544617,
      "learning_rate": 0.0001536360532604985,
      "loss": 0.0479,
      "step": 1805
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.30348876118659973,
      "learning_rate": 0.00015349948787982248,
      "loss": 0.0499,
      "step": 1806
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.3442979156970978,
      "learning_rate": 0.00015336292249914648,
      "loss": 0.0469,
      "step": 1807
    },
    {
      "epoch": 6.17,
      "grad_norm": 0.34679895639419556,
      "learning_rate": 0.00015322635711847047,
      "loss": 0.0467,
      "step": 1808
    },
    {
      "epoch": 6.17,
      "grad_norm": 0.30340343713760376,
      "learning_rate": 0.00015308979173779446,
      "loss": 0.043,
      "step": 1809
    },
    {
      "epoch": 6.17,
      "grad_norm": 0.3174162805080414,
      "learning_rate": 0.00015295322635711848,
      "loss": 0.0396,
      "step": 1810
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.3161090016365051,
      "learning_rate": 0.00015281666097644248,
      "loss": 0.0421,
      "step": 1811
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.31212562322616577,
      "learning_rate": 0.00015268009559576647,
      "loss": 0.044,
      "step": 1812
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.3294938802719116,
      "learning_rate": 0.0001525435302150905,
      "loss": 0.0431,
      "step": 1813
    },
    {
      "epoch": 6.19,
      "grad_norm": 0.29684245586395264,
      "learning_rate": 0.0001524069648344145,
      "loss": 0.0409,
      "step": 1814
    },
    {
      "epoch": 6.19,
      "grad_norm": 0.3954585790634155,
      "learning_rate": 0.00015227039945373848,
      "loss": 0.0472,
      "step": 1815
    },
    {
      "epoch": 6.19,
      "grad_norm": 0.33930057287216187,
      "learning_rate": 0.00015213383407306248,
      "loss": 0.0495,
      "step": 1816
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.32951024174690247,
      "learning_rate": 0.0001519972686923865,
      "loss": 0.0498,
      "step": 1817
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.2567121982574463,
      "learning_rate": 0.0001518607033117105,
      "loss": 0.0366,
      "step": 1818
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.3449903428554535,
      "learning_rate": 0.00015172413793103449,
      "loss": 0.0462,
      "step": 1819
    },
    {
      "epoch": 6.21,
      "grad_norm": 0.31108495593070984,
      "learning_rate": 0.00015158757255035848,
      "loss": 0.041,
      "step": 1820
    },
    {
      "epoch": 6.21,
      "grad_norm": 0.30412065982818604,
      "learning_rate": 0.0001514510071696825,
      "loss": 0.047,
      "step": 1821
    },
    {
      "epoch": 6.21,
      "grad_norm": 0.3152598738670349,
      "learning_rate": 0.0001513144417890065,
      "loss": 0.0435,
      "step": 1822
    },
    {
      "epoch": 6.22,
      "grad_norm": 0.3156518340110779,
      "learning_rate": 0.0001511778764083305,
      "loss": 0.0454,
      "step": 1823
    },
    {
      "epoch": 6.22,
      "grad_norm": 0.34372320771217346,
      "learning_rate": 0.00015104131102765448,
      "loss": 0.0441,
      "step": 1824
    },
    {
      "epoch": 6.22,
      "grad_norm": 0.3437564969062805,
      "learning_rate": 0.0001509047456469785,
      "loss": 0.0519,
      "step": 1825
    },
    {
      "epoch": 6.23,
      "grad_norm": 0.2609958052635193,
      "learning_rate": 0.0001507681802663025,
      "loss": 0.0419,
      "step": 1826
    },
    {
      "epoch": 6.23,
      "grad_norm": 0.32485881447792053,
      "learning_rate": 0.0001506316148856265,
      "loss": 0.0516,
      "step": 1827
    },
    {
      "epoch": 6.23,
      "grad_norm": 0.31679767370224,
      "learning_rate": 0.00015049504950495051,
      "loss": 0.0457,
      "step": 1828
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.41784000396728516,
      "learning_rate": 0.0001503584841242745,
      "loss": 0.0413,
      "step": 1829
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.2466733157634735,
      "learning_rate": 0.0001502219187435985,
      "loss": 0.0385,
      "step": 1830
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.2995202839374542,
      "learning_rate": 0.0001500853533629225,
      "loss": 0.042,
      "step": 1831
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.29041776061058044,
      "learning_rate": 0.0001499487879822465,
      "loss": 0.0414,
      "step": 1832
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.3372683823108673,
      "learning_rate": 0.0001498122226015705,
      "loss": 0.045,
      "step": 1833
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.29618918895721436,
      "learning_rate": 0.0001496756572208945,
      "loss": 0.0428,
      "step": 1834
    },
    {
      "epoch": 6.26,
      "grad_norm": 0.3914436399936676,
      "learning_rate": 0.0001495390918402185,
      "loss": 0.0595,
      "step": 1835
    },
    {
      "epoch": 6.26,
      "grad_norm": 0.3098396956920624,
      "learning_rate": 0.00014940252645954252,
      "loss": 0.0429,
      "step": 1836
    },
    {
      "epoch": 6.26,
      "grad_norm": 0.33541813492774963,
      "learning_rate": 0.00014926596107886652,
      "loss": 0.0458,
      "step": 1837
    },
    {
      "epoch": 6.27,
      "grad_norm": 0.339534193277359,
      "learning_rate": 0.0001491293956981905,
      "loss": 0.0475,
      "step": 1838
    },
    {
      "epoch": 6.27,
      "grad_norm": 0.3137018382549286,
      "learning_rate": 0.00014899283031751453,
      "loss": 0.052,
      "step": 1839
    },
    {
      "epoch": 6.27,
      "grad_norm": 0.31584855914115906,
      "learning_rate": 0.0001488562649368385,
      "loss": 0.0501,
      "step": 1840
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.27807509899139404,
      "learning_rate": 0.00014871969955616252,
      "loss": 0.0385,
      "step": 1841
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.2938554584980011,
      "learning_rate": 0.00014858313417548651,
      "loss": 0.0427,
      "step": 1842
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.2667103111743927,
      "learning_rate": 0.0001484465687948105,
      "loss": 0.0374,
      "step": 1843
    },
    {
      "epoch": 6.29,
      "grad_norm": 0.297451913356781,
      "learning_rate": 0.00014831000341413453,
      "loss": 0.0457,
      "step": 1844
    },
    {
      "epoch": 6.29,
      "grad_norm": 0.326172798871994,
      "learning_rate": 0.00014817343803345852,
      "loss": 0.0537,
      "step": 1845
    },
    {
      "epoch": 6.29,
      "grad_norm": 0.29315611720085144,
      "learning_rate": 0.00014803687265278252,
      "loss": 0.0486,
      "step": 1846
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.3096560537815094,
      "learning_rate": 0.00014790030727210654,
      "loss": 0.0425,
      "step": 1847
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.3186192512512207,
      "learning_rate": 0.00014776374189143053,
      "loss": 0.0463,
      "step": 1848
    },
    {
      "epoch": 6.31,
      "grad_norm": 0.27718478441238403,
      "learning_rate": 0.00014762717651075453,
      "loss": 0.0431,
      "step": 1849
    },
    {
      "epoch": 6.31,
      "grad_norm": 0.3455556333065033,
      "learning_rate": 0.00014749061113007855,
      "loss": 0.0465,
      "step": 1850
    },
    {
      "epoch": 6.31,
      "grad_norm": 0.32290413975715637,
      "learning_rate": 0.00014735404574940252,
      "loss": 0.0516,
      "step": 1851
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.2971360683441162,
      "learning_rate": 0.00014721748036872654,
      "loss": 0.0434,
      "step": 1852
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.31546756625175476,
      "learning_rate": 0.00014708091498805053,
      "loss": 0.0414,
      "step": 1853
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.32264095544815063,
      "learning_rate": 0.00014694434960737453,
      "loss": 0.0412,
      "step": 1854
    },
    {
      "epoch": 6.33,
      "grad_norm": 0.31952884793281555,
      "learning_rate": 0.00014680778422669855,
      "loss": 0.0406,
      "step": 1855
    },
    {
      "epoch": 6.33,
      "grad_norm": 0.3116503357887268,
      "learning_rate": 0.00014667121884602254,
      "loss": 0.044,
      "step": 1856
    },
    {
      "epoch": 6.33,
      "grad_norm": 0.31419074535369873,
      "learning_rate": 0.00014653465346534653,
      "loss": 0.0457,
      "step": 1857
    },
    {
      "epoch": 6.34,
      "grad_norm": 0.3131401240825653,
      "learning_rate": 0.00014639808808467056,
      "loss": 0.0483,
      "step": 1858
    },
    {
      "epoch": 6.34,
      "grad_norm": 0.2854275107383728,
      "learning_rate": 0.00014626152270399452,
      "loss": 0.0406,
      "step": 1859
    },
    {
      "epoch": 6.34,
      "grad_norm": 0.2815302908420563,
      "learning_rate": 0.00014612495732331854,
      "loss": 0.04,
      "step": 1860
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.3396608531475067,
      "learning_rate": 0.00014598839194264257,
      "loss": 0.0458,
      "step": 1861
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.2924013137817383,
      "learning_rate": 0.00014585182656196653,
      "loss": 0.0419,
      "step": 1862
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.27109894156455994,
      "learning_rate": 0.00014571526118129055,
      "loss": 0.0356,
      "step": 1863
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.30489251017570496,
      "learning_rate": 0.00014557869580061458,
      "loss": 0.0414,
      "step": 1864
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.2726000249385834,
      "learning_rate": 0.00014544213041993854,
      "loss": 0.0421,
      "step": 1865
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.31250205636024475,
      "learning_rate": 0.00014530556503926256,
      "loss": 0.0419,
      "step": 1866
    },
    {
      "epoch": 6.37,
      "grad_norm": 0.3336576819419861,
      "learning_rate": 0.00014516899965858656,
      "loss": 0.0472,
      "step": 1867
    },
    {
      "epoch": 6.37,
      "grad_norm": 0.3374710977077484,
      "learning_rate": 0.00014503243427791055,
      "loss": 0.0468,
      "step": 1868
    },
    {
      "epoch": 6.37,
      "grad_norm": 0.32718947529792786,
      "learning_rate": 0.00014489586889723457,
      "loss": 0.0447,
      "step": 1869
    },
    {
      "epoch": 6.38,
      "grad_norm": 0.3031948506832123,
      "learning_rate": 0.00014475930351655854,
      "loss": 0.0434,
      "step": 1870
    },
    {
      "epoch": 6.38,
      "grad_norm": 0.3276292681694031,
      "learning_rate": 0.00014462273813588256,
      "loss": 0.0471,
      "step": 1871
    },
    {
      "epoch": 6.38,
      "grad_norm": 0.35202839970588684,
      "learning_rate": 0.00014448617275520658,
      "loss": 0.0467,
      "step": 1872
    },
    {
      "epoch": 6.39,
      "grad_norm": 0.3363291323184967,
      "learning_rate": 0.00014434960737453055,
      "loss": 0.0559,
      "step": 1873
    },
    {
      "epoch": 6.39,
      "grad_norm": 0.2581416368484497,
      "learning_rate": 0.00014421304199385457,
      "loss": 0.0346,
      "step": 1874
    },
    {
      "epoch": 6.39,
      "grad_norm": 0.2725876569747925,
      "learning_rate": 0.00014407647661317856,
      "loss": 0.0418,
      "step": 1875
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.28246980905532837,
      "learning_rate": 0.00014393991123250256,
      "loss": 0.0446,
      "step": 1876
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.29372459650039673,
      "learning_rate": 0.00014380334585182658,
      "loss": 0.0463,
      "step": 1877
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.3902915418148041,
      "learning_rate": 0.00014366678047115057,
      "loss": 0.0604,
      "step": 1878
    },
    {
      "epoch": 6.41,
      "grad_norm": 0.2832409143447876,
      "learning_rate": 0.00014353021509047457,
      "loss": 0.0497,
      "step": 1879
    },
    {
      "epoch": 6.41,
      "grad_norm": 0.27999401092529297,
      "learning_rate": 0.0001433936497097986,
      "loss": 0.043,
      "step": 1880
    },
    {
      "epoch": 6.41,
      "grad_norm": 0.2886159420013428,
      "learning_rate": 0.00014325708432912258,
      "loss": 0.0421,
      "step": 1881
    },
    {
      "epoch": 6.42,
      "grad_norm": 0.3430490791797638,
      "learning_rate": 0.00014312051894844658,
      "loss": 0.0487,
      "step": 1882
    },
    {
      "epoch": 6.42,
      "grad_norm": 0.30334821343421936,
      "learning_rate": 0.00014298395356777057,
      "loss": 0.0464,
      "step": 1883
    },
    {
      "epoch": 6.42,
      "grad_norm": 0.2971780598163605,
      "learning_rate": 0.00014284738818709457,
      "loss": 0.0463,
      "step": 1884
    },
    {
      "epoch": 6.43,
      "grad_norm": 0.31187182664871216,
      "learning_rate": 0.0001427108228064186,
      "loss": 0.0447,
      "step": 1885
    },
    {
      "epoch": 6.43,
      "grad_norm": 0.3401166796684265,
      "learning_rate": 0.00014257425742574258,
      "loss": 0.0468,
      "step": 1886
    },
    {
      "epoch": 6.43,
      "grad_norm": 0.36595281958580017,
      "learning_rate": 0.00014243769204506658,
      "loss": 0.0469,
      "step": 1887
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.3006207346916199,
      "learning_rate": 0.0001423011266643906,
      "loss": 0.0452,
      "step": 1888
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.33181479573249817,
      "learning_rate": 0.0001421645612837146,
      "loss": 0.046,
      "step": 1889
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.3417797386646271,
      "learning_rate": 0.00014202799590303859,
      "loss": 0.0461,
      "step": 1890
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.3281199038028717,
      "learning_rate": 0.00014189143052236258,
      "loss": 0.0459,
      "step": 1891
    },
    {
      "epoch": 6.45,
      "grad_norm": 0.3684510886669159,
      "learning_rate": 0.0001417548651416866,
      "loss": 0.0488,
      "step": 1892
    },
    {
      "epoch": 6.46,
      "grad_norm": 0.32720980048179626,
      "learning_rate": 0.0001416182997610106,
      "loss": 0.0407,
      "step": 1893
    },
    {
      "epoch": 6.46,
      "grad_norm": 0.3416285514831543,
      "learning_rate": 0.0001414817343803346,
      "loss": 0.0545,
      "step": 1894
    },
    {
      "epoch": 6.46,
      "grad_norm": 0.320828914642334,
      "learning_rate": 0.00014134516899965858,
      "loss": 0.0461,
      "step": 1895
    },
    {
      "epoch": 6.47,
      "grad_norm": 0.3120727837085724,
      "learning_rate": 0.0001412086036189826,
      "loss": 0.0478,
      "step": 1896
    },
    {
      "epoch": 6.47,
      "grad_norm": 0.32273152470588684,
      "learning_rate": 0.0001410720382383066,
      "loss": 0.0499,
      "step": 1897
    },
    {
      "epoch": 6.47,
      "grad_norm": 0.3307949900627136,
      "learning_rate": 0.0001409354728576306,
      "loss": 0.0449,
      "step": 1898
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.38578927516937256,
      "learning_rate": 0.0001407989074769546,
      "loss": 0.0534,
      "step": 1899
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.27688753604888916,
      "learning_rate": 0.0001406623420962786,
      "loss": 0.0431,
      "step": 1900
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.2823440134525299,
      "learning_rate": 0.0001405257767156026,
      "loss": 0.039,
      "step": 1901
    },
    {
      "epoch": 6.49,
      "grad_norm": 0.30463355779647827,
      "learning_rate": 0.0001403892113349266,
      "loss": 0.0476,
      "step": 1902
    },
    {
      "epoch": 6.49,
      "grad_norm": 0.33477267622947693,
      "learning_rate": 0.00014025264595425062,
      "loss": 0.0523,
      "step": 1903
    },
    {
      "epoch": 6.49,
      "grad_norm": 0.3157355785369873,
      "learning_rate": 0.0001401160805735746,
      "loss": 0.0443,
      "step": 1904
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.3019934594631195,
      "learning_rate": 0.0001399795151928986,
      "loss": 0.0477,
      "step": 1905
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.3186829388141632,
      "learning_rate": 0.0001398429498122226,
      "loss": 0.0486,
      "step": 1906
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.3115313649177551,
      "learning_rate": 0.0001397063844315466,
      "loss": 0.0523,
      "step": 1907
    },
    {
      "epoch": 6.51,
      "grad_norm": 0.3228011429309845,
      "learning_rate": 0.00013956981905087062,
      "loss": 0.0467,
      "step": 1908
    },
    {
      "epoch": 6.51,
      "grad_norm": 0.3089749813079834,
      "learning_rate": 0.0001394332536701946,
      "loss": 0.0416,
      "step": 1909
    },
    {
      "epoch": 6.51,
      "grad_norm": 0.27466505765914917,
      "learning_rate": 0.0001392966882895186,
      "loss": 0.0413,
      "step": 1910
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.3266758918762207,
      "learning_rate": 0.00013916012290884262,
      "loss": 0.0496,
      "step": 1911
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.3156699240207672,
      "learning_rate": 0.00013902355752816662,
      "loss": 0.043,
      "step": 1912
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.2913324534893036,
      "learning_rate": 0.0001388869921474906,
      "loss": 0.0434,
      "step": 1913
    },
    {
      "epoch": 6.53,
      "grad_norm": 0.29040929675102234,
      "learning_rate": 0.00013875042676681463,
      "loss": 0.0398,
      "step": 1914
    },
    {
      "epoch": 6.53,
      "grad_norm": 0.338202565908432,
      "learning_rate": 0.0001386138613861386,
      "loss": 0.0479,
      "step": 1915
    },
    {
      "epoch": 6.53,
      "grad_norm": 0.29437193274497986,
      "learning_rate": 0.00013847729600546262,
      "loss": 0.0466,
      "step": 1916
    },
    {
      "epoch": 6.54,
      "grad_norm": 0.2797069847583771,
      "learning_rate": 0.00013834073062478662,
      "loss": 0.0418,
      "step": 1917
    },
    {
      "epoch": 6.54,
      "grad_norm": 0.30982881784439087,
      "learning_rate": 0.0001382041652441106,
      "loss": 0.0446,
      "step": 1918
    },
    {
      "epoch": 6.54,
      "grad_norm": 0.28555068373680115,
      "learning_rate": 0.00013806759986343463,
      "loss": 0.0441,
      "step": 1919
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.31579115986824036,
      "learning_rate": 0.00013793103448275863,
      "loss": 0.0487,
      "step": 1920
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.27942895889282227,
      "learning_rate": 0.00013779446910208262,
      "loss": 0.0465,
      "step": 1921
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.29388609528541565,
      "learning_rate": 0.00013765790372140664,
      "loss": 0.0523,
      "step": 1922
    },
    {
      "epoch": 6.56,
      "grad_norm": 0.30960527062416077,
      "learning_rate": 0.0001375213383407306,
      "loss": 0.0457,
      "step": 1923
    },
    {
      "epoch": 6.56,
      "grad_norm": 0.3199256658554077,
      "learning_rate": 0.00013738477296005463,
      "loss": 0.0428,
      "step": 1924
    },
    {
      "epoch": 6.56,
      "grad_norm": 0.2813293933868408,
      "learning_rate": 0.00013724820757937865,
      "loss": 0.041,
      "step": 1925
    },
    {
      "epoch": 6.57,
      "grad_norm": 0.26239320635795593,
      "learning_rate": 0.00013711164219870262,
      "loss": 0.0418,
      "step": 1926
    },
    {
      "epoch": 6.57,
      "grad_norm": 0.35643282532691956,
      "learning_rate": 0.00013697507681802664,
      "loss": 0.047,
      "step": 1927
    },
    {
      "epoch": 6.57,
      "grad_norm": 0.37874746322631836,
      "learning_rate": 0.00013683851143735063,
      "loss": 0.0603,
      "step": 1928
    },
    {
      "epoch": 6.58,
      "grad_norm": 0.33242666721343994,
      "learning_rate": 0.00013670194605667463,
      "loss": 0.0451,
      "step": 1929
    },
    {
      "epoch": 6.58,
      "grad_norm": 0.27843177318573,
      "learning_rate": 0.00013656538067599865,
      "loss": 0.0362,
      "step": 1930
    },
    {
      "epoch": 6.58,
      "grad_norm": 0.34340643882751465,
      "learning_rate": 0.00013642881529532264,
      "loss": 0.0421,
      "step": 1931
    },
    {
      "epoch": 6.59,
      "grad_norm": 0.35159555077552795,
      "learning_rate": 0.00013629224991464664,
      "loss": 0.0523,
      "step": 1932
    },
    {
      "epoch": 6.59,
      "grad_norm": 0.3277459740638733,
      "learning_rate": 0.00013615568453397066,
      "loss": 0.0478,
      "step": 1933
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.32810407876968384,
      "learning_rate": 0.00013601911915329463,
      "loss": 0.0414,
      "step": 1934
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.30364662408828735,
      "learning_rate": 0.00013588255377261865,
      "loss": 0.0471,
      "step": 1935
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.29360532760620117,
      "learning_rate": 0.00013574598839194267,
      "loss": 0.0435,
      "step": 1936
    },
    {
      "epoch": 6.61,
      "grad_norm": 0.3416955769062042,
      "learning_rate": 0.00013560942301126664,
      "loss": 0.0512,
      "step": 1937
    },
    {
      "epoch": 6.61,
      "grad_norm": 0.28380757570266724,
      "learning_rate": 0.00013547285763059066,
      "loss": 0.0435,
      "step": 1938
    },
    {
      "epoch": 6.61,
      "grad_norm": 0.30630016326904297,
      "learning_rate": 0.00013533629224991465,
      "loss": 0.0429,
      "step": 1939
    },
    {
      "epoch": 6.62,
      "grad_norm": 0.2765847444534302,
      "learning_rate": 0.00013519972686923864,
      "loss": 0.0376,
      "step": 1940
    },
    {
      "epoch": 6.62,
      "grad_norm": 0.31570765376091003,
      "learning_rate": 0.00013506316148856267,
      "loss": 0.0517,
      "step": 1941
    },
    {
      "epoch": 6.62,
      "grad_norm": 0.3139350712299347,
      "learning_rate": 0.00013492659610788666,
      "loss": 0.0465,
      "step": 1942
    },
    {
      "epoch": 6.63,
      "grad_norm": 0.28108251094818115,
      "learning_rate": 0.00013479003072721065,
      "loss": 0.0414,
      "step": 1943
    },
    {
      "epoch": 6.63,
      "grad_norm": 0.3033149838447571,
      "learning_rate": 0.00013465346534653468,
      "loss": 0.0475,
      "step": 1944
    },
    {
      "epoch": 6.63,
      "grad_norm": 0.31081804633140564,
      "learning_rate": 0.00013451689996585864,
      "loss": 0.04,
      "step": 1945
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.2982846200466156,
      "learning_rate": 0.00013438033458518266,
      "loss": 0.0463,
      "step": 1946
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.3343614935874939,
      "learning_rate": 0.00013424376920450666,
      "loss": 0.0416,
      "step": 1947
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.2714769244194031,
      "learning_rate": 0.00013410720382383065,
      "loss": 0.0393,
      "step": 1948
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.29564034938812256,
      "learning_rate": 0.00013397063844315467,
      "loss": 0.0453,
      "step": 1949
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.32685279846191406,
      "learning_rate": 0.00013383407306247867,
      "loss": 0.044,
      "step": 1950
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.32142576575279236,
      "learning_rate": 0.00013369750768180266,
      "loss": 0.0415,
      "step": 1951
    },
    {
      "epoch": 6.66,
      "grad_norm": 0.3126049339771271,
      "learning_rate": 0.00013356094230112668,
      "loss": 0.0433,
      "step": 1952
    },
    {
      "epoch": 6.66,
      "grad_norm": 0.2828398644924164,
      "learning_rate": 0.00013342437692045068,
      "loss": 0.0391,
      "step": 1953
    },
    {
      "epoch": 6.66,
      "grad_norm": 0.3816729485988617,
      "learning_rate": 0.00013328781153977467,
      "loss": 0.0481,
      "step": 1954
    },
    {
      "epoch": 6.67,
      "grad_norm": 0.33048924803733826,
      "learning_rate": 0.0001331512461590987,
      "loss": 0.0371,
      "step": 1955
    },
    {
      "epoch": 6.67,
      "grad_norm": 0.34672126173973083,
      "learning_rate": 0.0001330146807784227,
      "loss": 0.0524,
      "step": 1956
    },
    {
      "epoch": 6.67,
      "grad_norm": 0.3128804862499237,
      "learning_rate": 0.00013287811539774668,
      "loss": 0.0423,
      "step": 1957
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.2774321436882019,
      "learning_rate": 0.00013274155001707067,
      "loss": 0.044,
      "step": 1958
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.3017050325870514,
      "learning_rate": 0.00013260498463639467,
      "loss": 0.0412,
      "step": 1959
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.3110371530056,
      "learning_rate": 0.0001324684192557187,
      "loss": 0.0445,
      "step": 1960
    },
    {
      "epoch": 6.69,
      "grad_norm": 0.2891545593738556,
      "learning_rate": 0.00013233185387504268,
      "loss": 0.0454,
      "step": 1961
    },
    {
      "epoch": 6.69,
      "grad_norm": 0.28654244542121887,
      "learning_rate": 0.00013219528849436668,
      "loss": 0.0494,
      "step": 1962
    },
    {
      "epoch": 6.69,
      "grad_norm": 0.30981913208961487,
      "learning_rate": 0.0001320587231136907,
      "loss": 0.0475,
      "step": 1963
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.2897730767726898,
      "learning_rate": 0.0001319221577330147,
      "loss": 0.0475,
      "step": 1964
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.3189067244529724,
      "learning_rate": 0.0001317855923523387,
      "loss": 0.0483,
      "step": 1965
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.34344053268432617,
      "learning_rate": 0.00013164902697166268,
      "loss": 0.0492,
      "step": 1966
    },
    {
      "epoch": 6.71,
      "grad_norm": 0.29607072472572327,
      "learning_rate": 0.0001315124615909867,
      "loss": 0.0435,
      "step": 1967
    },
    {
      "epoch": 6.71,
      "grad_norm": 0.274970680475235,
      "learning_rate": 0.0001313758962103107,
      "loss": 0.0436,
      "step": 1968
    },
    {
      "epoch": 6.71,
      "grad_norm": 0.2723548710346222,
      "learning_rate": 0.0001312393308296347,
      "loss": 0.0396,
      "step": 1969
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.29681500792503357,
      "learning_rate": 0.00013110276544895869,
      "loss": 0.0498,
      "step": 1970
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.3062795400619507,
      "learning_rate": 0.0001309662000682827,
      "loss": 0.0416,
      "step": 1971
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.3122633397579193,
      "learning_rate": 0.0001308296346876067,
      "loss": 0.0427,
      "step": 1972
    },
    {
      "epoch": 6.73,
      "grad_norm": 0.3158898651599884,
      "learning_rate": 0.0001306930693069307,
      "loss": 0.0464,
      "step": 1973
    },
    {
      "epoch": 6.73,
      "grad_norm": 0.3021998703479767,
      "learning_rate": 0.0001305565039262547,
      "loss": 0.0414,
      "step": 1974
    },
    {
      "epoch": 6.73,
      "grad_norm": 0.37606167793273926,
      "learning_rate": 0.0001304199385455787,
      "loss": 0.0578,
      "step": 1975
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.30156970024108887,
      "learning_rate": 0.0001302833731649027,
      "loss": 0.0436,
      "step": 1976
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.34075334668159485,
      "learning_rate": 0.0001301468077842267,
      "loss": 0.0441,
      "step": 1977
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.313290536403656,
      "learning_rate": 0.00013001024240355072,
      "loss": 0.0382,
      "step": 1978
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.31989267468452454,
      "learning_rate": 0.00012987367702287471,
      "loss": 0.0475,
      "step": 1979
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.3555223345756531,
      "learning_rate": 0.0001297371116421987,
      "loss": 0.0496,
      "step": 1980
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.29077592492103577,
      "learning_rate": 0.0001296005462615227,
      "loss": 0.0427,
      "step": 1981
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.2783481776714325,
      "learning_rate": 0.0001294639808808467,
      "loss": 0.0432,
      "step": 1982
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.33302274346351624,
      "learning_rate": 0.00012932741550017072,
      "loss": 0.0464,
      "step": 1983
    },
    {
      "epoch": 6.77,
      "grad_norm": 0.2830049395561218,
      "learning_rate": 0.0001291908501194947,
      "loss": 0.0473,
      "step": 1984
    },
    {
      "epoch": 6.77,
      "grad_norm": 0.3406882584095001,
      "learning_rate": 0.0001290542847388187,
      "loss": 0.0546,
      "step": 1985
    },
    {
      "epoch": 6.77,
      "grad_norm": 0.27920404076576233,
      "learning_rate": 0.00012891771935814273,
      "loss": 0.0408,
      "step": 1986
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.24956835806369781,
      "learning_rate": 0.00012878115397746672,
      "loss": 0.0409,
      "step": 1987
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.29371583461761475,
      "learning_rate": 0.00012864458859679072,
      "loss": 0.0413,
      "step": 1988
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.3094078004360199,
      "learning_rate": 0.00012850802321611474,
      "loss": 0.046,
      "step": 1989
    },
    {
      "epoch": 6.79,
      "grad_norm": 0.3709909915924072,
      "learning_rate": 0.0001283714578354387,
      "loss": 0.0442,
      "step": 1990
    },
    {
      "epoch": 6.79,
      "grad_norm": 0.27748700976371765,
      "learning_rate": 0.00012823489245476273,
      "loss": 0.042,
      "step": 1991
    },
    {
      "epoch": 6.79,
      "grad_norm": 0.3055112063884735,
      "learning_rate": 0.00012809832707408672,
      "loss": 0.0481,
      "step": 1992
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.3238344192504883,
      "learning_rate": 0.00012796176169341071,
      "loss": 0.0515,
      "step": 1993
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.32570651173591614,
      "learning_rate": 0.00012782519631273473,
      "loss": 0.0533,
      "step": 1994
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.35145434737205505,
      "learning_rate": 0.00012768863093205873,
      "loss": 0.0575,
      "step": 1995
    },
    {
      "epoch": 6.81,
      "grad_norm": 0.3259075880050659,
      "learning_rate": 0.00012755206555138272,
      "loss": 0.0484,
      "step": 1996
    },
    {
      "epoch": 6.81,
      "grad_norm": 0.27172595262527466,
      "learning_rate": 0.00012741550017070674,
      "loss": 0.0466,
      "step": 1997
    },
    {
      "epoch": 6.81,
      "grad_norm": 0.31529501080513,
      "learning_rate": 0.0001272789347900307,
      "loss": 0.0446,
      "step": 1998
    },
    {
      "epoch": 6.82,
      "grad_norm": 0.2755546569824219,
      "learning_rate": 0.00012714236940935473,
      "loss": 0.0452,
      "step": 1999
    },
    {
      "epoch": 6.82,
      "grad_norm": 0.3393344581127167,
      "learning_rate": 0.00012700580402867875,
      "loss": 0.0486,
      "step": 2000
    }
  ],
  "logging_steps": 1,
  "max_steps": 2930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 2.8467265037368934e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
