{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.4100596760443307,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.11932601034641266,
      "learning_rate": 0.0004,
      "loss": 0.8959,
      "step": 1
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.12995079159736633,
      "learning_rate": 0.000399863434619324,
      "loss": 0.9509,
      "step": 2
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1028643399477005,
      "learning_rate": 0.00039972686923864806,
      "loss": 0.8057,
      "step": 3
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.11891897022724152,
      "learning_rate": 0.000399590303857972,
      "loss": 0.781,
      "step": 4
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11693283915519714,
      "learning_rate": 0.000399453738477296,
      "loss": 0.7576,
      "step": 5
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11341890692710876,
      "learning_rate": 0.00039931717309662004,
      "loss": 0.798,
      "step": 6
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.122858926653862,
      "learning_rate": 0.00039918060771594404,
      "loss": 0.7117,
      "step": 7
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12956611812114716,
      "learning_rate": 0.00039904404233526803,
      "loss": 0.6596,
      "step": 8
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.21965965628623962,
      "learning_rate": 0.000398907476954592,
      "loss": 0.6033,
      "step": 9
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1176835373044014,
      "learning_rate": 0.000398770911573916,
      "loss": 0.5973,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11746004223823547,
      "learning_rate": 0.00039863434619324,
      "loss": 0.6031,
      "step": 11
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10500402748584747,
      "learning_rate": 0.000398497780812564,
      "loss": 0.5548,
      "step": 12
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.13920103013515472,
      "learning_rate": 0.00039836121543188806,
      "loss": 0.6046,
      "step": 13
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13967584073543549,
      "learning_rate": 0.00039822465005121205,
      "loss": 0.5541,
      "step": 14
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13367138803005219,
      "learning_rate": 0.00039808808467053605,
      "loss": 0.5453,
      "step": 15
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1382903754711151,
      "learning_rate": 0.00039795151928986004,
      "loss": 0.5255,
      "step": 16
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.16521431505680084,
      "learning_rate": 0.00039781495390918403,
      "loss": 0.5806,
      "step": 17
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.14018790423870087,
      "learning_rate": 0.00039767838852850803,
      "loss": 0.5837,
      "step": 18
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.20510762929916382,
      "learning_rate": 0.0003975418231478321,
      "loss": 0.5877,
      "step": 19
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15951736271381378,
      "learning_rate": 0.00039740525776715607,
      "loss": 0.5098,
      "step": 20
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.18222330510616302,
      "learning_rate": 0.00039726869238648,
      "loss": 0.5985,
      "step": 21
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.12442512810230255,
      "learning_rate": 0.00039713212700580406,
      "loss": 0.5194,
      "step": 22
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1894417256116867,
      "learning_rate": 0.00039699556162512805,
      "loss": 0.5462,
      "step": 23
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.12953850626945496,
      "learning_rate": 0.00039685899624445205,
      "loss": 0.4865,
      "step": 24
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.19135719537734985,
      "learning_rate": 0.0003967224308637761,
      "loss": 0.4825,
      "step": 25
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1669173687696457,
      "learning_rate": 0.00039658586548310004,
      "loss": 0.5047,
      "step": 26
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1852615624666214,
      "learning_rate": 0.00039644930010242403,
      "loss": 0.4946,
      "step": 27
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19344154000282288,
      "learning_rate": 0.000396312734721748,
      "loss": 0.5015,
      "step": 28
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.14693255722522736,
      "learning_rate": 0.00039617616934107207,
      "loss": 0.5102,
      "step": 29
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.15513701736927032,
      "learning_rate": 0.00039603960396039607,
      "loss": 0.5022,
      "step": 30
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.16791105270385742,
      "learning_rate": 0.00039590303857972006,
      "loss": 0.5442,
      "step": 31
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.17000769078731537,
      "learning_rate": 0.00039576647319904405,
      "loss": 0.4718,
      "step": 32
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.15345706045627594,
      "learning_rate": 0.00039562990781836805,
      "loss": 0.4348,
      "step": 33
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.19199515879154205,
      "learning_rate": 0.00039549334243769204,
      "loss": 0.4994,
      "step": 34
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.19298982620239258,
      "learning_rate": 0.0003953567770570161,
      "loss": 0.5367,
      "step": 35
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.18228675425052643,
      "learning_rate": 0.0003952202116763401,
      "loss": 0.4753,
      "step": 36
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.22715966403484344,
      "learning_rate": 0.0003950836462956641,
      "loss": 0.4911,
      "step": 37
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.17330849170684814,
      "learning_rate": 0.0003949470809149881,
      "loss": 0.4644,
      "step": 38
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3439425230026245,
      "learning_rate": 0.00039481051553431207,
      "loss": 0.5084,
      "step": 39
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2567111551761627,
      "learning_rate": 0.00039467395015363606,
      "loss": 0.5116,
      "step": 40
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.20711593329906464,
      "learning_rate": 0.0003945373847729601,
      "loss": 0.4745,
      "step": 41
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.18716032803058624,
      "learning_rate": 0.0003944008193922841,
      "loss": 0.4883,
      "step": 42
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.20658157765865326,
      "learning_rate": 0.00039426425401160804,
      "loss": 0.4738,
      "step": 43
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.19123712182044983,
      "learning_rate": 0.00039412768863093204,
      "loss": 0.4835,
      "step": 44
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.1860593855381012,
      "learning_rate": 0.0003939911232502561,
      "loss": 0.4783,
      "step": 45
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.16982242465019226,
      "learning_rate": 0.0003938545578695801,
      "loss": 0.4701,
      "step": 46
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.19591237604618073,
      "learning_rate": 0.0003937179924889041,
      "loss": 0.4279,
      "step": 47
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2108498215675354,
      "learning_rate": 0.00039358142710822807,
      "loss": 0.4391,
      "step": 48
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.1974157989025116,
      "learning_rate": 0.00039344486172755206,
      "loss": 0.501,
      "step": 49
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.1864587962627411,
      "learning_rate": 0.00039330829634687606,
      "loss": 0.4348,
      "step": 50
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.18650147318840027,
      "learning_rate": 0.0003931717309662001,
      "loss": 0.481,
      "step": 51
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.16282854974269867,
      "learning_rate": 0.0003930351655855241,
      "loss": 0.4605,
      "step": 52
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.18192808330059052,
      "learning_rate": 0.0003928986002048481,
      "loss": 0.4911,
      "step": 53
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.14408214390277863,
      "learning_rate": 0.0003927620348241721,
      "loss": 0.4521,
      "step": 54
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.16893240809440613,
      "learning_rate": 0.0003926254694434961,
      "loss": 0.4622,
      "step": 55
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.20898085832595825,
      "learning_rate": 0.0003924889040628201,
      "loss": 0.4969,
      "step": 56
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.19083088636398315,
      "learning_rate": 0.0003923523386821441,
      "loss": 0.5239,
      "step": 57
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1833944469690323,
      "learning_rate": 0.0003922157733014681,
      "loss": 0.5189,
      "step": 58
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.17402781546115875,
      "learning_rate": 0.0003920792079207921,
      "loss": 0.4416,
      "step": 59
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1983473300933838,
      "learning_rate": 0.00039194264254011605,
      "loss": 0.4058,
      "step": 60
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.198753222823143,
      "learning_rate": 0.0003918060771594401,
      "loss": 0.4304,
      "step": 61
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.19336481392383575,
      "learning_rate": 0.0003916695117787641,
      "loss": 0.4343,
      "step": 62
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.16549089550971985,
      "learning_rate": 0.0003915329463980881,
      "loss": 0.4663,
      "step": 63
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.18489280343055725,
      "learning_rate": 0.00039139638101741214,
      "loss": 0.4779,
      "step": 64
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.17566567659378052,
      "learning_rate": 0.0003912598156367361,
      "loss": 0.4406,
      "step": 65
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1636786162853241,
      "learning_rate": 0.00039112325025606007,
      "loss": 0.432,
      "step": 66
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1571778953075409,
      "learning_rate": 0.0003909866848753841,
      "loss": 0.4013,
      "step": 67
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1813317984342575,
      "learning_rate": 0.0003908501194947081,
      "loss": 0.453,
      "step": 68
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.15979111194610596,
      "learning_rate": 0.0003907135541140321,
      "loss": 0.4955,
      "step": 69
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.18714825809001923,
      "learning_rate": 0.00039057698873335616,
      "loss": 0.3917,
      "step": 70
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.16007860004901886,
      "learning_rate": 0.0003904404233526801,
      "loss": 0.4404,
      "step": 71
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18033036589622498,
      "learning_rate": 0.0003903038579720041,
      "loss": 0.4495,
      "step": 72
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18039646744728088,
      "learning_rate": 0.00039016729259132814,
      "loss": 0.4508,
      "step": 73
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18390505015850067,
      "learning_rate": 0.00039003072721065213,
      "loss": 0.4633,
      "step": 74
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.21328343451023102,
      "learning_rate": 0.00038989416182997613,
      "loss": 0.4402,
      "step": 75
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.20199717581272125,
      "learning_rate": 0.0003897575964493001,
      "loss": 0.4346,
      "step": 76
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.21577580273151398,
      "learning_rate": 0.0003896210310686241,
      "loss": 0.4383,
      "step": 77
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.17391496896743774,
      "learning_rate": 0.0003894844656879481,
      "loss": 0.4184,
      "step": 78
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.17531253397464752,
      "learning_rate": 0.0003893479003072721,
      "loss": 0.5059,
      "step": 79
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.25591975450515747,
      "learning_rate": 0.00038921133492659615,
      "loss": 0.4707,
      "step": 80
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.16724248230457306,
      "learning_rate": 0.00038907476954592015,
      "loss": 0.4205,
      "step": 81
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.18535126745700836,
      "learning_rate": 0.0003889382041652441,
      "loss": 0.4157,
      "step": 82
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1879180371761322,
      "learning_rate": 0.00038880163878456814,
      "loss": 0.4128,
      "step": 83
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.22169995307922363,
      "learning_rate": 0.00038866507340389213,
      "loss": 0.4654,
      "step": 84
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.22645032405853271,
      "learning_rate": 0.0003885285080232161,
      "loss": 0.4889,
      "step": 85
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.17365556955337524,
      "learning_rate": 0.00038839194264254017,
      "loss": 0.467,
      "step": 86
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.21194802224636078,
      "learning_rate": 0.00038825537726186417,
      "loss": 0.3815,
      "step": 87
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.21270978450775146,
      "learning_rate": 0.0003881188118811881,
      "loss": 0.4285,
      "step": 88
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.2029954493045807,
      "learning_rate": 0.00038798224650051215,
      "loss": 0.3947,
      "step": 89
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.17495183646678925,
      "learning_rate": 0.00038784568111983615,
      "loss": 0.3947,
      "step": 90
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.21961523592472076,
      "learning_rate": 0.00038770911573916014,
      "loss": 0.4331,
      "step": 91
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.17954495549201965,
      "learning_rate": 0.00038757255035848414,
      "loss": 0.4189,
      "step": 92
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.18917836248874664,
      "learning_rate": 0.00038743598497780813,
      "loss": 0.4617,
      "step": 93
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1711726039648056,
      "learning_rate": 0.0003872994195971321,
      "loss": 0.3694,
      "step": 94
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.18672242760658264,
      "learning_rate": 0.0003871628542164561,
      "loss": 0.3997,
      "step": 95
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1815706193447113,
      "learning_rate": 0.00038702628883578017,
      "loss": 0.4099,
      "step": 96
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.21121686697006226,
      "learning_rate": 0.00038688972345510416,
      "loss": 0.4231,
      "step": 97
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.24120746552944183,
      "learning_rate": 0.00038675315807442816,
      "loss": 0.4756,
      "step": 98
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.18905414640903473,
      "learning_rate": 0.00038661659269375215,
      "loss": 0.4366,
      "step": 99
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.2789367735385895,
      "learning_rate": 0.00038648002731307614,
      "loss": 0.4429,
      "step": 100
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.17393247783184052,
      "learning_rate": 0.00038634346193240014,
      "loss": 0.4259,
      "step": 101
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1679239571094513,
      "learning_rate": 0.0003862068965517242,
      "loss": 0.3994,
      "step": 102
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.19263914227485657,
      "learning_rate": 0.0003860703311710482,
      "loss": 0.4222,
      "step": 103
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1893499195575714,
      "learning_rate": 0.0003859337657903722,
      "loss": 0.4206,
      "step": 104
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.283657431602478,
      "learning_rate": 0.00038579720040969617,
      "loss": 0.4698,
      "step": 105
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.17698688805103302,
      "learning_rate": 0.00038566063502902016,
      "loss": 0.4357,
      "step": 106
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.20826728641986847,
      "learning_rate": 0.00038552406964834416,
      "loss": 0.3977,
      "step": 107
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1877846121788025,
      "learning_rate": 0.00038538750426766815,
      "loss": 0.4299,
      "step": 108
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.19921369850635529,
      "learning_rate": 0.0003852509388869922,
      "loss": 0.411,
      "step": 109
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.25177013874053955,
      "learning_rate": 0.00038511437350631614,
      "loss": 0.4259,
      "step": 110
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.23400160670280457,
      "learning_rate": 0.00038497780812564013,
      "loss": 0.3981,
      "step": 111
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.20995192229747772,
      "learning_rate": 0.0003848412427449642,
      "loss": 0.3497,
      "step": 112
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.18908075988292694,
      "learning_rate": 0.0003847046773642882,
      "loss": 0.3957,
      "step": 113
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.20198990404605865,
      "learning_rate": 0.00038456811198361217,
      "loss": 0.4369,
      "step": 114
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1864842027425766,
      "learning_rate": 0.00038443154660293616,
      "loss": 0.4417,
      "step": 115
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.20353202521800995,
      "learning_rate": 0.00038429498122226016,
      "loss": 0.4059,
      "step": 116
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.20620527863502502,
      "learning_rate": 0.00038415841584158415,
      "loss": 0.4505,
      "step": 117
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.17421503365039825,
      "learning_rate": 0.0003840218504609082,
      "loss": 0.4064,
      "step": 118
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.2056753933429718,
      "learning_rate": 0.0003838852850802322,
      "loss": 0.4032,
      "step": 119
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.189042329788208,
      "learning_rate": 0.0003837487196995562,
      "loss": 0.4334,
      "step": 120
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.19650782644748688,
      "learning_rate": 0.0003836121543188802,
      "loss": 0.3631,
      "step": 121
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.18814721703529358,
      "learning_rate": 0.0003834755889382042,
      "loss": 0.3932,
      "step": 122
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.17587293684482574,
      "learning_rate": 0.00038333902355752817,
      "loss": 0.4532,
      "step": 123
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.16995179653167725,
      "learning_rate": 0.0003832024581768522,
      "loss": 0.4116,
      "step": 124
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1828056275844574,
      "learning_rate": 0.0003830658927961762,
      "loss": 0.395,
      "step": 125
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.18312714993953705,
      "learning_rate": 0.0003829293274155002,
      "loss": 0.4075,
      "step": 126
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.17621472477912903,
      "learning_rate": 0.00038279276203482415,
      "loss": 0.4385,
      "step": 127
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1863430142402649,
      "learning_rate": 0.0003826561966541482,
      "loss": 0.3993,
      "step": 128
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.19096267223358154,
      "learning_rate": 0.0003825196312734722,
      "loss": 0.3839,
      "step": 129
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.21727265417575836,
      "learning_rate": 0.0003823830658927962,
      "loss": 0.4004,
      "step": 130
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.19263474643230438,
      "learning_rate": 0.00038224650051212023,
      "loss": 0.3918,
      "step": 131
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1866053193807602,
      "learning_rate": 0.0003821099351314442,
      "loss": 0.3859,
      "step": 132
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.18332050740718842,
      "learning_rate": 0.00038197336975076817,
      "loss": 0.4111,
      "step": 133
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.22084063291549683,
      "learning_rate": 0.0003818368043700922,
      "loss": 0.3605,
      "step": 134
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.21410885453224182,
      "learning_rate": 0.0003817002389894162,
      "loss": 0.4081,
      "step": 135
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.2135201394557953,
      "learning_rate": 0.0003815636736087402,
      "loss": 0.4057,
      "step": 136
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.2088382989168167,
      "learning_rate": 0.0003814271082280642,
      "loss": 0.3873,
      "step": 137
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.20540077984333038,
      "learning_rate": 0.0003812905428473882,
      "loss": 0.4035,
      "step": 138
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.20161038637161255,
      "learning_rate": 0.0003811539774667122,
      "loss": 0.4043,
      "step": 139
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.17132288217544556,
      "learning_rate": 0.00038101741208603623,
      "loss": 0.3702,
      "step": 140
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1865415871143341,
      "learning_rate": 0.00038088084670536023,
      "loss": 0.4161,
      "step": 141
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.19205421209335327,
      "learning_rate": 0.0003807442813246842,
      "loss": 0.3748,
      "step": 142
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.17669232189655304,
      "learning_rate": 0.0003806077159440082,
      "loss": 0.395,
      "step": 143
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.2023332417011261,
      "learning_rate": 0.0003804711505633322,
      "loss": 0.37,
      "step": 144
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.18515044450759888,
      "learning_rate": 0.0003803345851826562,
      "loss": 0.3901,
      "step": 145
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2399897426366806,
      "learning_rate": 0.0003801980198019802,
      "loss": 0.4218,
      "step": 146
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.2420056313276291,
      "learning_rate": 0.00038006145442130425,
      "loss": 0.412,
      "step": 147
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.23440030217170715,
      "learning_rate": 0.00037992488904062824,
      "loss": 0.364,
      "step": 148
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.20118071138858795,
      "learning_rate": 0.0003797883236599522,
      "loss": 0.4022,
      "step": 149
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1706302911043167,
      "learning_rate": 0.00037965175827927623,
      "loss": 0.3944,
      "step": 150
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.19102372229099274,
      "learning_rate": 0.0003795151928986002,
      "loss": 0.3301,
      "step": 151
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.18222784996032715,
      "learning_rate": 0.0003793786275179242,
      "loss": 0.3984,
      "step": 152
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.17706440389156342,
      "learning_rate": 0.00037924206213724827,
      "loss": 0.4145,
      "step": 153
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.19225913286209106,
      "learning_rate": 0.0003791054967565722,
      "loss": 0.3456,
      "step": 154
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.19951173663139343,
      "learning_rate": 0.0003789689313758962,
      "loss": 0.3633,
      "step": 155
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.21073518693447113,
      "learning_rate": 0.00037883236599522025,
      "loss": 0.3773,
      "step": 156
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.17023064196109772,
      "learning_rate": 0.00037869580061454424,
      "loss": 0.3456,
      "step": 157
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.20859971642494202,
      "learning_rate": 0.00037855923523386824,
      "loss": 0.3543,
      "step": 158
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.23133733868598938,
      "learning_rate": 0.00037842266985319223,
      "loss": 0.3414,
      "step": 159
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1911781132221222,
      "learning_rate": 0.0003782861044725162,
      "loss": 0.3705,
      "step": 160
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.21870696544647217,
      "learning_rate": 0.0003781495390918402,
      "loss": 0.3987,
      "step": 161
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.16268710792064667,
      "learning_rate": 0.0003780129737111642,
      "loss": 0.364,
      "step": 162
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.21182574331760406,
      "learning_rate": 0.00037787640833048826,
      "loss": 0.3685,
      "step": 163
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.19948598742485046,
      "learning_rate": 0.00037773984294981226,
      "loss": 0.3888,
      "step": 164
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.16624271869659424,
      "learning_rate": 0.00037760327756913625,
      "loss": 0.3684,
      "step": 165
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.168888121843338,
      "learning_rate": 0.00037746671218846025,
      "loss": 0.4106,
      "step": 166
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1666525900363922,
      "learning_rate": 0.00037733014680778424,
      "loss": 0.4125,
      "step": 167
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1948082447052002,
      "learning_rate": 0.00037719358142710823,
      "loss": 0.3576,
      "step": 168
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.19242322444915771,
      "learning_rate": 0.0003770570160464323,
      "loss": 0.369,
      "step": 169
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1987505406141281,
      "learning_rate": 0.0003769204506657563,
      "loss": 0.4216,
      "step": 170
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.2443125993013382,
      "learning_rate": 0.0003767838852850802,
      "loss": 0.4162,
      "step": 171
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1850782334804535,
      "learning_rate": 0.00037664731990440426,
      "loss": 0.3304,
      "step": 172
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1918804794549942,
      "learning_rate": 0.00037651075452372826,
      "loss": 0.3673,
      "step": 173
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.22750459611415863,
      "learning_rate": 0.00037637418914305225,
      "loss": 0.4014,
      "step": 174
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.17416325211524963,
      "learning_rate": 0.00037623762376237625,
      "loss": 0.3891,
      "step": 175
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.16330155730247498,
      "learning_rate": 0.00037610105838170024,
      "loss": 0.3864,
      "step": 176
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.18479983508586884,
      "learning_rate": 0.00037596449300102423,
      "loss": 0.3783,
      "step": 177
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.19715462625026703,
      "learning_rate": 0.00037582792762034823,
      "loss": 0.3807,
      "step": 178
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1924590915441513,
      "learning_rate": 0.0003756913622396723,
      "loss": 0.3633,
      "step": 179
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.20747852325439453,
      "learning_rate": 0.00037555479685899627,
      "loss": 0.3715,
      "step": 180
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.2685392200946808,
      "learning_rate": 0.00037541823147832027,
      "loss": 0.4609,
      "step": 181
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.20092441141605377,
      "learning_rate": 0.00037528166609764426,
      "loss": 0.4046,
      "step": 182
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.19370871782302856,
      "learning_rate": 0.00037514510071696825,
      "loss": 0.4211,
      "step": 183
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.17117629945278168,
      "learning_rate": 0.00037500853533629225,
      "loss": 0.3857,
      "step": 184
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1688281148672104,
      "learning_rate": 0.0003748719699556163,
      "loss": 0.3542,
      "step": 185
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.18875424563884735,
      "learning_rate": 0.0003747354045749403,
      "loss": 0.4098,
      "step": 186
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.18127739429473877,
      "learning_rate": 0.0003745988391942643,
      "loss": 0.3278,
      "step": 187
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.17721326649188995,
      "learning_rate": 0.0003744622738135883,
      "loss": 0.3473,
      "step": 188
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1865159273147583,
      "learning_rate": 0.0003743257084329123,
      "loss": 0.3639,
      "step": 189
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.17829829454421997,
      "learning_rate": 0.00037418914305223627,
      "loss": 0.3781,
      "step": 190
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.18134117126464844,
      "learning_rate": 0.00037405257767156026,
      "loss": 0.3628,
      "step": 191
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.19378823041915894,
      "learning_rate": 0.0003739160122908843,
      "loss": 0.4108,
      "step": 192
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.18632633984088898,
      "learning_rate": 0.00037377944691020825,
      "loss": 0.4174,
      "step": 193
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.22484908998012543,
      "learning_rate": 0.00037364288152953224,
      "loss": 0.3919,
      "step": 194
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.17331703007221222,
      "learning_rate": 0.0003735063161488563,
      "loss": 0.3811,
      "step": 195
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16882792115211487,
      "learning_rate": 0.0003733697507681803,
      "loss": 0.382,
      "step": 196
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16708339750766754,
      "learning_rate": 0.0003732331853875043,
      "loss": 0.392,
      "step": 197
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.17704758048057556,
      "learning_rate": 0.0003730966200068283,
      "loss": 0.3711,
      "step": 198
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.16114240884780884,
      "learning_rate": 0.00037296005462615227,
      "loss": 0.3362,
      "step": 199
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.20022638142108917,
      "learning_rate": 0.00037282348924547626,
      "loss": 0.3806,
      "step": 200
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.18744675815105438,
      "learning_rate": 0.0003726869238648003,
      "loss": 0.3319,
      "step": 201
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.21558323502540588,
      "learning_rate": 0.0003725503584841243,
      "loss": 0.3529,
      "step": 202
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.21583403646945953,
      "learning_rate": 0.0003724137931034483,
      "loss": 0.39,
      "step": 203
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.19908298552036285,
      "learning_rate": 0.0003722772277227723,
      "loss": 0.351,
      "step": 204
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1802712231874466,
      "learning_rate": 0.0003721406623420963,
      "loss": 0.4298,
      "step": 205
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.19505298137664795,
      "learning_rate": 0.0003720040969614203,
      "loss": 0.3494,
      "step": 206
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.16028131544589996,
      "learning_rate": 0.0003718675315807443,
      "loss": 0.3365,
      "step": 207
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.17946474254131317,
      "learning_rate": 0.0003717309662000683,
      "loss": 0.3766,
      "step": 208
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.1911803036928177,
      "learning_rate": 0.0003715944008193923,
      "loss": 0.3829,
      "step": 209
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.19979660212993622,
      "learning_rate": 0.00037145783543871626,
      "loss": 0.3937,
      "step": 210
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.17798380553722382,
      "learning_rate": 0.0003713212700580403,
      "loss": 0.3842,
      "step": 211
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.19575877487659454,
      "learning_rate": 0.0003711847046773643,
      "loss": 0.375,
      "step": 212
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.19981318712234497,
      "learning_rate": 0.0003710481392966883,
      "loss": 0.3749,
      "step": 213
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.1978575438261032,
      "learning_rate": 0.00037091157391601234,
      "loss": 0.343,
      "step": 214
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.16956236958503723,
      "learning_rate": 0.0003707750085353363,
      "loss": 0.3663,
      "step": 215
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.19567793607711792,
      "learning_rate": 0.0003706384431546603,
      "loss": 0.3659,
      "step": 216
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.18070311844348907,
      "learning_rate": 0.0003705018777739843,
      "loss": 0.3589,
      "step": 217
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.17055091261863708,
      "learning_rate": 0.0003703653123933083,
      "loss": 0.3523,
      "step": 218
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.18255577981472015,
      "learning_rate": 0.0003702287470126323,
      "loss": 0.3442,
      "step": 219
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.2007906138896942,
      "learning_rate": 0.00037009218163195636,
      "loss": 0.3675,
      "step": 220
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.2507295608520508,
      "learning_rate": 0.0003699556162512803,
      "loss": 0.3583,
      "step": 221
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18266668915748596,
      "learning_rate": 0.0003698190508706043,
      "loss": 0.3814,
      "step": 222
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18681594729423523,
      "learning_rate": 0.00036968248548992834,
      "loss": 0.3498,
      "step": 223
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.18366739153862,
      "learning_rate": 0.00036954592010925234,
      "loss": 0.3385,
      "step": 224
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.17412066459655762,
      "learning_rate": 0.00036940935472857633,
      "loss": 0.3846,
      "step": 225
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1903606355190277,
      "learning_rate": 0.00036927278934790033,
      "loss": 0.376,
      "step": 226
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.1933138221502304,
      "learning_rate": 0.0003691362239672243,
      "loss": 0.3759,
      "step": 227
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.22036446630954742,
      "learning_rate": 0.0003689996585865483,
      "loss": 0.4055,
      "step": 228
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.2663576900959015,
      "learning_rate": 0.0003688630932058723,
      "loss": 0.409,
      "step": 229
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.21347099542617798,
      "learning_rate": 0.00036872652782519636,
      "loss": 0.3664,
      "step": 230
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1852015256881714,
      "learning_rate": 0.00036858996244452035,
      "loss": 0.3758,
      "step": 231
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.19410254061222076,
      "learning_rate": 0.0003684533970638443,
      "loss": 0.3577,
      "step": 232
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.1948726326227188,
      "learning_rate": 0.00036831683168316834,
      "loss": 0.3637,
      "step": 233
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.17496037483215332,
      "learning_rate": 0.00036818026630249233,
      "loss": 0.35,
      "step": 234
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.18115025758743286,
      "learning_rate": 0.00036804370092181633,
      "loss": 0.3865,
      "step": 235
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.20185108482837677,
      "learning_rate": 0.0003679071355411404,
      "loss": 0.364,
      "step": 236
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.1938481330871582,
      "learning_rate": 0.00036777057016046437,
      "loss": 0.3618,
      "step": 237
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.20931850373744965,
      "learning_rate": 0.0003676340047797883,
      "loss": 0.3573,
      "step": 238
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.18935449421405792,
      "learning_rate": 0.00036749743939911236,
      "loss": 0.4016,
      "step": 239
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.2249639332294464,
      "learning_rate": 0.00036736087401843635,
      "loss": 0.398,
      "step": 240
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.1690995693206787,
      "learning_rate": 0.00036722430863776035,
      "loss": 0.3921,
      "step": 241
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.19712598621845245,
      "learning_rate": 0.00036708774325708434,
      "loss": 0.3927,
      "step": 242
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.19995993375778198,
      "learning_rate": 0.00036695117787640834,
      "loss": 0.3432,
      "step": 243
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.20136070251464844,
      "learning_rate": 0.00036681461249573233,
      "loss": 0.3823,
      "step": 244
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.1755421757698059,
      "learning_rate": 0.0003666780471150563,
      "loss": 0.351,
      "step": 245
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.23074768483638763,
      "learning_rate": 0.00036654148173438037,
      "loss": 0.4405,
      "step": 246
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.17130251228809357,
      "learning_rate": 0.00036640491635370437,
      "loss": 0.3548,
      "step": 247
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.20049941539764404,
      "learning_rate": 0.00036626835097302836,
      "loss": 0.395,
      "step": 248
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.17307546734809875,
      "learning_rate": 0.00036613178559235236,
      "loss": 0.351,
      "step": 249
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.18956033885478973,
      "learning_rate": 0.00036599522021167635,
      "loss": 0.3732,
      "step": 250
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.19508998095989227,
      "learning_rate": 0.00036585865483100034,
      "loss": 0.37,
      "step": 251
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.1894523650407791,
      "learning_rate": 0.0003657220894503244,
      "loss": 0.3617,
      "step": 252
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.18485723435878754,
      "learning_rate": 0.0003655855240696484,
      "loss": 0.3227,
      "step": 253
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.19283626973628998,
      "learning_rate": 0.0003654489586889724,
      "loss": 0.3582,
      "step": 254
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.18002986907958984,
      "learning_rate": 0.0003653123933082964,
      "loss": 0.3563,
      "step": 255
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.1734979748725891,
      "learning_rate": 0.00036517582792762037,
      "loss": 0.3242,
      "step": 256
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.19178953766822815,
      "learning_rate": 0.00036503926254694436,
      "loss": 0.3241,
      "step": 257
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.20438987016677856,
      "learning_rate": 0.00036490269716626836,
      "loss": 0.3719,
      "step": 258
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.2484029084444046,
      "learning_rate": 0.0003647661317855924,
      "loss": 0.3667,
      "step": 259
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.18747936189174652,
      "learning_rate": 0.00036462956640491634,
      "loss": 0.3318,
      "step": 260
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.19476965069770813,
      "learning_rate": 0.00036449300102424034,
      "loss": 0.3915,
      "step": 261
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.22352959215641022,
      "learning_rate": 0.0003643564356435644,
      "loss": 0.3976,
      "step": 262
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.16797375679016113,
      "learning_rate": 0.0003642198702628884,
      "loss": 0.293,
      "step": 263
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.1924566775560379,
      "learning_rate": 0.0003640833048822124,
      "loss": 0.3432,
      "step": 264
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.19407260417938232,
      "learning_rate": 0.00036394673950153637,
      "loss": 0.352,
      "step": 265
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.18697986006736755,
      "learning_rate": 0.00036381017412086036,
      "loss": 0.3711,
      "step": 266
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.19984957575798035,
      "learning_rate": 0.00036367360874018436,
      "loss": 0.3941,
      "step": 267
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.25614839792251587,
      "learning_rate": 0.0003635370433595084,
      "loss": 0.397,
      "step": 268
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.17615966498851776,
      "learning_rate": 0.0003634004779788324,
      "loss": 0.3398,
      "step": 269
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.16232623159885406,
      "learning_rate": 0.0003632639125981564,
      "loss": 0.3268,
      "step": 270
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.17790842056274414,
      "learning_rate": 0.0003631273472174804,
      "loss": 0.3425,
      "step": 271
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.1584029346704483,
      "learning_rate": 0.0003629907818368044,
      "loss": 0.332,
      "step": 272
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.20034293830394745,
      "learning_rate": 0.0003628542164561284,
      "loss": 0.3941,
      "step": 273
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.20284485816955566,
      "learning_rate": 0.00036271765107545237,
      "loss": 0.3626,
      "step": 274
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.18261189758777618,
      "learning_rate": 0.0003625810856947764,
      "loss": 0.3115,
      "step": 275
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.2061653584241867,
      "learning_rate": 0.0003624445203141004,
      "loss": 0.3353,
      "step": 276
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.16379022598266602,
      "learning_rate": 0.00036230795493342435,
      "loss": 0.3147,
      "step": 277
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.18098846077919006,
      "learning_rate": 0.0003621713895527484,
      "loss": 0.3326,
      "step": 278
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.17694753408432007,
      "learning_rate": 0.0003620348241720724,
      "loss": 0.3147,
      "step": 279
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.21474365890026093,
      "learning_rate": 0.0003618982587913964,
      "loss": 0.3502,
      "step": 280
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1938004344701767,
      "learning_rate": 0.00036176169341072044,
      "loss": 0.3297,
      "step": 281
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1779995560646057,
      "learning_rate": 0.0003616251280300444,
      "loss": 0.36,
      "step": 282
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.2481638640165329,
      "learning_rate": 0.00036148856264936837,
      "loss": 0.357,
      "step": 283
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.19048528373241425,
      "learning_rate": 0.0003613519972686924,
      "loss": 0.3478,
      "step": 284
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.2661489248275757,
      "learning_rate": 0.0003612154318880164,
      "loss": 0.3242,
      "step": 285
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.18586614727973938,
      "learning_rate": 0.0003610788665073404,
      "loss": 0.3272,
      "step": 286
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.252966046333313,
      "learning_rate": 0.0003609423011266644,
      "loss": 0.3109,
      "step": 287
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.25187063217163086,
      "learning_rate": 0.0003608057357459884,
      "loss": 0.4313,
      "step": 288
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.2117471545934677,
      "learning_rate": 0.0003606691703653124,
      "loss": 0.3286,
      "step": 289
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.22412477433681488,
      "learning_rate": 0.0003605326049846364,
      "loss": 0.3466,
      "step": 290
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.16692133247852325,
      "learning_rate": 0.00036039603960396043,
      "loss": 0.3204,
      "step": 291
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.18807296454906464,
      "learning_rate": 0.00036025947422328443,
      "loss": 0.36,
      "step": 292
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.21419252455234528,
      "learning_rate": 0.0003601229088426084,
      "loss": 0.4177,
      "step": 293
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1749790906906128,
      "learning_rate": 0.0003599863434619324,
      "loss": 0.3243,
      "step": 294
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.18493682146072388,
      "learning_rate": 0.0003598497780812564,
      "loss": 0.3404,
      "step": 295
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.21522802114486694,
      "learning_rate": 0.0003597132127005804,
      "loss": 0.3183,
      "step": 296
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.24882280826568604,
      "learning_rate": 0.00035957664731990445,
      "loss": 0.3477,
      "step": 297
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.21226254105567932,
      "learning_rate": 0.00035944008193922845,
      "loss": 0.3123,
      "step": 298
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.23622505366802216,
      "learning_rate": 0.0003593035165585524,
      "loss": 0.3092,
      "step": 299
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.24488712847232819,
      "learning_rate": 0.00035916695117787644,
      "loss": 0.3609,
      "step": 300
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.22958829998970032,
      "learning_rate": 0.00035903038579720043,
      "loss": 0.3381,
      "step": 301
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.19518715143203735,
      "learning_rate": 0.0003588938204165244,
      "loss": 0.3533,
      "step": 302
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.19504888355731964,
      "learning_rate": 0.00035875725503584847,
      "loss": 0.3366,
      "step": 303
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.197079136967659,
      "learning_rate": 0.0003586206896551724,
      "loss": 0.3084,
      "step": 304
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1875862032175064,
      "learning_rate": 0.0003584841242744964,
      "loss": 0.3312,
      "step": 305
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.17808176577091217,
      "learning_rate": 0.0003583475588938204,
      "loss": 0.3024,
      "step": 306
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.2030431032180786,
      "learning_rate": 0.00035821099351314445,
      "loss": 0.3211,
      "step": 307
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.21580669283866882,
      "learning_rate": 0.00035807442813246844,
      "loss": 0.3362,
      "step": 308
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.22665748000144958,
      "learning_rate": 0.00035793786275179244,
      "loss": 0.3744,
      "step": 309
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.26513639092445374,
      "learning_rate": 0.00035780129737111643,
      "loss": 0.3431,
      "step": 310
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.2653314769268036,
      "learning_rate": 0.0003576647319904404,
      "loss": 0.3648,
      "step": 311
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.2110290825366974,
      "learning_rate": 0.0003575281666097644,
      "loss": 0.3355,
      "step": 312
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.21307623386383057,
      "learning_rate": 0.00035739160122908847,
      "loss": 0.3231,
      "step": 313
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.1949010044336319,
      "learning_rate": 0.00035725503584841246,
      "loss": 0.3216,
      "step": 314
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.18773755431175232,
      "learning_rate": 0.00035711847046773646,
      "loss": 0.3268,
      "step": 315
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.21050895750522614,
      "learning_rate": 0.00035698190508706045,
      "loss": 0.3092,
      "step": 316
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.20176264643669128,
      "learning_rate": 0.00035684533970638444,
      "loss": 0.3042,
      "step": 317
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.22255906462669373,
      "learning_rate": 0.00035670877432570844,
      "loss": 0.3286,
      "step": 318
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.24059513211250305,
      "learning_rate": 0.0003565722089450325,
      "loss": 0.3196,
      "step": 319
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.21301156282424927,
      "learning_rate": 0.0003564356435643565,
      "loss": 0.3136,
      "step": 320
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.29737719893455505,
      "learning_rate": 0.0003562990781836804,
      "loss": 0.3965,
      "step": 321
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.2317172735929489,
      "learning_rate": 0.0003561625128030044,
      "loss": 0.3584,
      "step": 322
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.23438389599323273,
      "learning_rate": 0.00035602594742232846,
      "loss": 0.3545,
      "step": 323
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.20273594558238983,
      "learning_rate": 0.00035588938204165246,
      "loss": 0.3382,
      "step": 324
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.24612386524677277,
      "learning_rate": 0.00035575281666097645,
      "loss": 0.3547,
      "step": 325
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.21637634932994843,
      "learning_rate": 0.00035561625128030045,
      "loss": 0.365,
      "step": 326
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.19678835570812225,
      "learning_rate": 0.00035547968589962444,
      "loss": 0.3382,
      "step": 327
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.24516811966896057,
      "learning_rate": 0.00035534312051894843,
      "loss": 0.3723,
      "step": 328
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.18380539119243622,
      "learning_rate": 0.0003552065551382725,
      "loss": 0.3422,
      "step": 329
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.19929836690425873,
      "learning_rate": 0.0003550699897575965,
      "loss": 0.3239,
      "step": 330
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.18697336316108704,
      "learning_rate": 0.00035493342437692047,
      "loss": 0.2937,
      "step": 331
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.17347358167171478,
      "learning_rate": 0.00035479685899624447,
      "loss": 0.3093,
      "step": 332
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.19448332488536835,
      "learning_rate": 0.00035466029361556846,
      "loss": 0.3532,
      "step": 333
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.19622744619846344,
      "learning_rate": 0.00035452372823489245,
      "loss": 0.3364,
      "step": 334
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.20212899148464203,
      "learning_rate": 0.0003543871628542165,
      "loss": 0.332,
      "step": 335
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.17936906218528748,
      "learning_rate": 0.0003542505974735405,
      "loss": 0.278,
      "step": 336
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.23737987875938416,
      "learning_rate": 0.0003541140320928645,
      "loss": 0.3577,
      "step": 337
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.24131621420383453,
      "learning_rate": 0.0003539774667121885,
      "loss": 0.3918,
      "step": 338
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1995277851819992,
      "learning_rate": 0.0003538409013315125,
      "loss": 0.3512,
      "step": 339
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.1794193983078003,
      "learning_rate": 0.00035370433595083647,
      "loss": 0.2991,
      "step": 340
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.19475747644901276,
      "learning_rate": 0.00035356777057016047,
      "loss": 0.319,
      "step": 341
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.20989356935024261,
      "learning_rate": 0.0003534312051894845,
      "loss": 0.3302,
      "step": 342
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.23322360217571259,
      "learning_rate": 0.00035329463980880845,
      "loss": 0.334,
      "step": 343
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.22068044543266296,
      "learning_rate": 0.00035315807442813245,
      "loss": 0.3185,
      "step": 344
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.23216703534126282,
      "learning_rate": 0.0003530215090474565,
      "loss": 0.3536,
      "step": 345
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.2448900192975998,
      "learning_rate": 0.0003528849436667805,
      "loss": 0.4075,
      "step": 346
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.20112290978431702,
      "learning_rate": 0.0003527483782861045,
      "loss": 0.3363,
      "step": 347
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.21474134922027588,
      "learning_rate": 0.00035261181290542853,
      "loss": 0.311,
      "step": 348
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.20913651585578918,
      "learning_rate": 0.0003524752475247525,
      "loss": 0.3653,
      "step": 349
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.19747164845466614,
      "learning_rate": 0.00035233868214407647,
      "loss": 0.2868,
      "step": 350
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.23086903989315033,
      "learning_rate": 0.0003522021167634005,
      "loss": 0.3268,
      "step": 351
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.21606570482254028,
      "learning_rate": 0.0003520655513827245,
      "loss": 0.3174,
      "step": 352
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.20444978773593903,
      "learning_rate": 0.0003519289860020485,
      "loss": 0.3217,
      "step": 353
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.2465686947107315,
      "learning_rate": 0.0003517924206213725,
      "loss": 0.3473,
      "step": 354
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.22836992144584656,
      "learning_rate": 0.0003516558552406965,
      "loss": 0.2873,
      "step": 355
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.2218930572271347,
      "learning_rate": 0.0003515192898600205,
      "loss": 0.3336,
      "step": 356
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.2022252380847931,
      "learning_rate": 0.0003513827244793445,
      "loss": 0.3234,
      "step": 357
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.23240654170513153,
      "learning_rate": 0.00035124615909866853,
      "loss": 0.3148,
      "step": 358
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.22239798307418823,
      "learning_rate": 0.0003511095937179925,
      "loss": 0.3216,
      "step": 359
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.2224113494157791,
      "learning_rate": 0.00035097302833731646,
      "loss": 0.3409,
      "step": 360
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.19898109138011932,
      "learning_rate": 0.0003508364629566405,
      "loss": 0.3137,
      "step": 361
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.20596817135810852,
      "learning_rate": 0.0003506998975759645,
      "loss": 0.334,
      "step": 362
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.18799731135368347,
      "learning_rate": 0.0003505633321952885,
      "loss": 0.3147,
      "step": 363
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.18455596268177032,
      "learning_rate": 0.00035042676681461255,
      "loss": 0.2958,
      "step": 364
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.2187097817659378,
      "learning_rate": 0.00035029020143393654,
      "loss": 0.3683,
      "step": 365
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.2159241884946823,
      "learning_rate": 0.0003501536360532605,
      "loss": 0.3344,
      "step": 366
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.20640219748020172,
      "learning_rate": 0.00035001707067258453,
      "loss": 0.3263,
      "step": 367
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.21508823335170746,
      "learning_rate": 0.0003498805052919085,
      "loss": 0.3229,
      "step": 368
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.24084541201591492,
      "learning_rate": 0.0003497439399112325,
      "loss": 0.3392,
      "step": 369
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.23376256227493286,
      "learning_rate": 0.00034960737453055657,
      "loss": 0.3675,
      "step": 370
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.20889417827129364,
      "learning_rate": 0.0003494708091498805,
      "loss": 0.3022,
      "step": 371
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.1714739352464676,
      "learning_rate": 0.0003493342437692045,
      "loss": 0.31,
      "step": 372
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.19280219078063965,
      "learning_rate": 0.0003491976783885285,
      "loss": 0.3031,
      "step": 373
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.19822730123996735,
      "learning_rate": 0.00034906111300785254,
      "loss": 0.3435,
      "step": 374
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.21925927698612213,
      "learning_rate": 0.00034892454762717654,
      "loss": 0.3515,
      "step": 375
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.21244312822818756,
      "learning_rate": 0.00034878798224650053,
      "loss": 0.3401,
      "step": 376
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.23074650764465332,
      "learning_rate": 0.0003486514168658245,
      "loss": 0.3356,
      "step": 377
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.22382019460201263,
      "learning_rate": 0.0003485148514851485,
      "loss": 0.3319,
      "step": 378
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.21527686715126038,
      "learning_rate": 0.0003483782861044725,
      "loss": 0.3348,
      "step": 379
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.21716850996017456,
      "learning_rate": 0.00034824172072379656,
      "loss": 0.3042,
      "step": 380
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.26965954899787903,
      "learning_rate": 0.00034810515534312056,
      "loss": 0.3617,
      "step": 381
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.2109793722629547,
      "learning_rate": 0.0003479685899624445,
      "loss": 0.3115,
      "step": 382
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.23406080901622772,
      "learning_rate": 0.00034783202458176855,
      "loss": 0.3562,
      "step": 383
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.1885213404893875,
      "learning_rate": 0.00034769545920109254,
      "loss": 0.3125,
      "step": 384
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.20651307702064514,
      "learning_rate": 0.00034755889382041653,
      "loss": 0.3176,
      "step": 385
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.20523285865783691,
      "learning_rate": 0.0003474223284397406,
      "loss": 0.3181,
      "step": 386
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.20894725620746613,
      "learning_rate": 0.0003472857630590646,
      "loss": 0.3556,
      "step": 387
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.18450474739074707,
      "learning_rate": 0.0003471491976783885,
      "loss": 0.3165,
      "step": 388
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.23721225559711456,
      "learning_rate": 0.0003470126322977125,
      "loss": 0.3318,
      "step": 389
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.1889929473400116,
      "learning_rate": 0.00034687606691703656,
      "loss": 0.279,
      "step": 390
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.21711833775043488,
      "learning_rate": 0.00034673950153636055,
      "loss": 0.332,
      "step": 391
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.24192307889461517,
      "learning_rate": 0.00034660293615568455,
      "loss": 0.3613,
      "step": 392
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.26290762424468994,
      "learning_rate": 0.00034646637077500854,
      "loss": 0.3123,
      "step": 393
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.22642219066619873,
      "learning_rate": 0.00034632980539433254,
      "loss": 0.3161,
      "step": 394
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.2525891661643982,
      "learning_rate": 0.00034619324001365653,
      "loss": 0.3138,
      "step": 395
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.21142880618572235,
      "learning_rate": 0.0003460566746329806,
      "loss": 0.3353,
      "step": 396
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.18987533450126648,
      "learning_rate": 0.00034592010925230457,
      "loss": 0.3014,
      "step": 397
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.18728755414485931,
      "learning_rate": 0.00034578354387162857,
      "loss": 0.3026,
      "step": 398
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.21900956332683563,
      "learning_rate": 0.00034564697849095256,
      "loss": 0.3904,
      "step": 399
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.24834366142749786,
      "learning_rate": 0.00034551041311027655,
      "loss": 0.3508,
      "step": 400
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.20587611198425293,
      "learning_rate": 0.00034537384772960055,
      "loss": 0.3082,
      "step": 401
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.23933079838752747,
      "learning_rate": 0.0003452372823489246,
      "loss": 0.3478,
      "step": 402
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.18723377585411072,
      "learning_rate": 0.0003451007169682486,
      "loss": 0.2832,
      "step": 403
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.21344821155071259,
      "learning_rate": 0.0003449641515875726,
      "loss": 0.337,
      "step": 404
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.22146761417388916,
      "learning_rate": 0.0003448275862068965,
      "loss": 0.3173,
      "step": 405
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.21174845099449158,
      "learning_rate": 0.0003446910208262206,
      "loss": 0.3551,
      "step": 406
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.24281994998455048,
      "learning_rate": 0.00034455445544554457,
      "loss": 0.3679,
      "step": 407
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.21000364422798157,
      "learning_rate": 0.00034441789006486856,
      "loss": 0.3787,
      "step": 408
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.18209049105644226,
      "learning_rate": 0.0003442813246841926,
      "loss": 0.3194,
      "step": 409
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.23496213555335999,
      "learning_rate": 0.00034414475930351655,
      "loss": 0.3729,
      "step": 410
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.1980510652065277,
      "learning_rate": 0.00034400819392284054,
      "loss": 0.344,
      "step": 411
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.20585277676582336,
      "learning_rate": 0.0003438716285421646,
      "loss": 0.3242,
      "step": 412
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.2242691069841385,
      "learning_rate": 0.0003437350631614886,
      "loss": 0.3205,
      "step": 413
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.23390519618988037,
      "learning_rate": 0.0003435984977808126,
      "loss": 0.3585,
      "step": 414
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.2117650955915451,
      "learning_rate": 0.0003434619324001366,
      "loss": 0.3268,
      "step": 415
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.21375177800655365,
      "learning_rate": 0.00034332536701946057,
      "loss": 0.3127,
      "step": 416
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.20376719534397125,
      "learning_rate": 0.00034318880163878456,
      "loss": 0.3235,
      "step": 417
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.20974870026111603,
      "learning_rate": 0.0003430522362581086,
      "loss": 0.3004,
      "step": 418
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.20580217242240906,
      "learning_rate": 0.0003429156708774326,
      "loss": 0.3068,
      "step": 419
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.2302500307559967,
      "learning_rate": 0.0003427791054967566,
      "loss": 0.3041,
      "step": 420
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.22961857914924622,
      "learning_rate": 0.0003426425401160806,
      "loss": 0.3224,
      "step": 421
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.2238655835390091,
      "learning_rate": 0.0003425059747354046,
      "loss": 0.2925,
      "step": 422
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.2443244457244873,
      "learning_rate": 0.0003423694093547286,
      "loss": 0.3017,
      "step": 423
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.21487785875797272,
      "learning_rate": 0.0003422328439740526,
      "loss": 0.3128,
      "step": 424
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.2441122829914093,
      "learning_rate": 0.0003420962785933766,
      "loss": 0.3173,
      "step": 425
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.24611538648605347,
      "learning_rate": 0.0003419597132127006,
      "loss": 0.3416,
      "step": 426
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.22902363538742065,
      "learning_rate": 0.00034182314783202456,
      "loss": 0.3812,
      "step": 427
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.23213110864162445,
      "learning_rate": 0.0003416865824513486,
      "loss": 0.312,
      "step": 428
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.20174476504325867,
      "learning_rate": 0.0003415500170706726,
      "loss": 0.2927,
      "step": 429
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.20617976784706116,
      "learning_rate": 0.0003414134516899966,
      "loss": 0.3195,
      "step": 430
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.21369288861751556,
      "learning_rate": 0.00034127688630932064,
      "loss": 0.3053,
      "step": 431
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.19960172474384308,
      "learning_rate": 0.0003411403209286446,
      "loss": 0.3164,
      "step": 432
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.1865237057209015,
      "learning_rate": 0.0003410037555479686,
      "loss": 0.2988,
      "step": 433
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.2161438763141632,
      "learning_rate": 0.0003408671901672926,
      "loss": 0.3183,
      "step": 434
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.20188391208648682,
      "learning_rate": 0.0003407306247866166,
      "loss": 0.2683,
      "step": 435
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.22893966734409332,
      "learning_rate": 0.0003405940594059406,
      "loss": 0.311,
      "step": 436
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.24851582944393158,
      "learning_rate": 0.0003404574940252646,
      "loss": 0.2843,
      "step": 437
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.2697020173072815,
      "learning_rate": 0.0003403209286445886,
      "loss": 0.345,
      "step": 438
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.2721976935863495,
      "learning_rate": 0.0003401843632639126,
      "loss": 0.3698,
      "step": 439
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.23578594624996185,
      "learning_rate": 0.0003400477978832366,
      "loss": 0.3229,
      "step": 440
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.19231589138507843,
      "learning_rate": 0.00033991123250256064,
      "loss": 0.3193,
      "step": 441
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.2158489227294922,
      "learning_rate": 0.00033977466712188463,
      "loss": 0.3128,
      "step": 442
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.2037849724292755,
      "learning_rate": 0.00033963810174120863,
      "loss": 0.3262,
      "step": 443
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.18851549923419952,
      "learning_rate": 0.0003395015363605326,
      "loss": 0.2829,
      "step": 444
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.19197121262550354,
      "learning_rate": 0.0003393649709798566,
      "loss": 0.2819,
      "step": 445
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.26434674859046936,
      "learning_rate": 0.0003392284055991806,
      "loss": 0.3649,
      "step": 446
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.2117290496826172,
      "learning_rate": 0.00033909184021850466,
      "loss": 0.3086,
      "step": 447
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2356727421283722,
      "learning_rate": 0.00033895527483782865,
      "loss": 0.2908,
      "step": 448
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2894708216190338,
      "learning_rate": 0.0003388187094571526,
      "loss": 0.3109,
      "step": 449
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.2802561819553375,
      "learning_rate": 0.00033868214407647664,
      "loss": 0.3419,
      "step": 450
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.21933603286743164,
      "learning_rate": 0.00033854557869580064,
      "loss": 0.2609,
      "step": 451
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.2017894983291626,
      "learning_rate": 0.00033840901331512463,
      "loss": 0.2575,
      "step": 452
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.20970788598060608,
      "learning_rate": 0.0003382724479344487,
      "loss": 0.3213,
      "step": 453
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.22622358798980713,
      "learning_rate": 0.0003381358825537726,
      "loss": 0.3154,
      "step": 454
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.20292894542217255,
      "learning_rate": 0.0003379993171730966,
      "loss": 0.2695,
      "step": 455
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.21411782503128052,
      "learning_rate": 0.0003378627517924206,
      "loss": 0.3132,
      "step": 456
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.2978256344795227,
      "learning_rate": 0.00033772618641174465,
      "loss": 0.3191,
      "step": 457
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.28505149483680725,
      "learning_rate": 0.00033758962103106865,
      "loss": 0.3431,
      "step": 458
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.29751160740852356,
      "learning_rate": 0.00033745305565039264,
      "loss": 0.342,
      "step": 459
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.22977152466773987,
      "learning_rate": 0.00033731649026971664,
      "loss": 0.298,
      "step": 460
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.18935450911521912,
      "learning_rate": 0.00033717992488904063,
      "loss": 0.3123,
      "step": 461
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.23792827129364014,
      "learning_rate": 0.0003370433595083646,
      "loss": 0.2989,
      "step": 462
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.20273086428642273,
      "learning_rate": 0.0003369067941276887,
      "loss": 0.3033,
      "step": 463
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.2046014666557312,
      "learning_rate": 0.00033677022874701267,
      "loss": 0.298,
      "step": 464
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.22221295535564423,
      "learning_rate": 0.00033663366336633666,
      "loss": 0.2824,
      "step": 465
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.23686303198337555,
      "learning_rate": 0.00033649709798566066,
      "loss": 0.3344,
      "step": 466
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.22441580891609192,
      "learning_rate": 0.00033636053260498465,
      "loss": 0.3016,
      "step": 467
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.23785005509853363,
      "learning_rate": 0.00033622396722430864,
      "loss": 0.2959,
      "step": 468
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2760114371776581,
      "learning_rate": 0.0003360874018436327,
      "loss": 0.3011,
      "step": 469
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.2698655426502228,
      "learning_rate": 0.0003359508364629567,
      "loss": 0.3742,
      "step": 470
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.24856457114219666,
      "learning_rate": 0.0003358142710822806,
      "loss": 0.2879,
      "step": 471
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.2138814479112625,
      "learning_rate": 0.0003356777057016046,
      "loss": 0.2859,
      "step": 472
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.21407762169837952,
      "learning_rate": 0.00033554114032092867,
      "loss": 0.3243,
      "step": 473
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.2208736091852188,
      "learning_rate": 0.00033540457494025266,
      "loss": 0.3095,
      "step": 474
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.21401436626911163,
      "learning_rate": 0.00033526800955957666,
      "loss": 0.3483,
      "step": 475
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.21205928921699524,
      "learning_rate": 0.00033513144417890065,
      "loss": 0.3197,
      "step": 476
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.21503736078739166,
      "learning_rate": 0.00033499487879822465,
      "loss": 0.3251,
      "step": 477
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.19942706823349,
      "learning_rate": 0.00033485831341754864,
      "loss": 0.3062,
      "step": 478
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.22622978687286377,
      "learning_rate": 0.0003347217480368727,
      "loss": 0.314,
      "step": 479
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.23547393083572388,
      "learning_rate": 0.0003345851826561967,
      "loss": 0.2996,
      "step": 480
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.2636096179485321,
      "learning_rate": 0.0003344486172755207,
      "loss": 0.3596,
      "step": 481
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.2560253143310547,
      "learning_rate": 0.00033431205189484467,
      "loss": 0.3362,
      "step": 482
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2340826541185379,
      "learning_rate": 0.00033417548651416866,
      "loss": 0.2961,
      "step": 483
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2092929631471634,
      "learning_rate": 0.00033403892113349266,
      "loss": 0.3003,
      "step": 484
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.2335752695798874,
      "learning_rate": 0.0003339023557528167,
      "loss": 0.3416,
      "step": 485
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.24169817566871643,
      "learning_rate": 0.0003337657903721407,
      "loss": 0.3562,
      "step": 486
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.2404930740594864,
      "learning_rate": 0.0003336292249914647,
      "loss": 0.36,
      "step": 487
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.2303403615951538,
      "learning_rate": 0.00033349265961078864,
      "loss": 0.2881,
      "step": 488
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.23361048102378845,
      "learning_rate": 0.0003333560942301127,
      "loss": 0.3023,
      "step": 489
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.23842883110046387,
      "learning_rate": 0.0003332195288494367,
      "loss": 0.3118,
      "step": 490
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.21191640198230743,
      "learning_rate": 0.00033308296346876067,
      "loss": 0.2952,
      "step": 491
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.1997518390417099,
      "learning_rate": 0.0003329463980880847,
      "loss": 0.3121,
      "step": 492
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.22100260853767395,
      "learning_rate": 0.00033280983270740866,
      "loss": 0.2995,
      "step": 493
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.20040227472782135,
      "learning_rate": 0.00033267326732673265,
      "loss": 0.2794,
      "step": 494
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.24342064559459686,
      "learning_rate": 0.0003325367019460567,
      "loss": 0.2881,
      "step": 495
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.24706287682056427,
      "learning_rate": 0.0003324001365653807,
      "loss": 0.3222,
      "step": 496
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.2307801991701126,
      "learning_rate": 0.0003322635711847047,
      "loss": 0.302,
      "step": 497
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.2536643147468567,
      "learning_rate": 0.00033212700580402874,
      "loss": 0.3103,
      "step": 498
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.23330727219581604,
      "learning_rate": 0.0003319904404233527,
      "loss": 0.3139,
      "step": 499
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.25033849477767944,
      "learning_rate": 0.0003318538750426767,
      "loss": 0.3299,
      "step": 500
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.2157747745513916,
      "learning_rate": 0.0003317173096620007,
      "loss": 0.3286,
      "step": 501
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.24722754955291748,
      "learning_rate": 0.0003315807442813247,
      "loss": 0.3528,
      "step": 502
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.2099849134683609,
      "learning_rate": 0.0003314441789006487,
      "loss": 0.2754,
      "step": 503
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.25216421484947205,
      "learning_rate": 0.0003313076135199727,
      "loss": 0.2993,
      "step": 504
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.2387196570634842,
      "learning_rate": 0.0003311710481392967,
      "loss": 0.3358,
      "step": 505
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.2207803875207901,
      "learning_rate": 0.0003310344827586207,
      "loss": 0.3022,
      "step": 506
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.23718354105949402,
      "learning_rate": 0.0003308979173779447,
      "loss": 0.2872,
      "step": 507
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.22435124218463898,
      "learning_rate": 0.00033076135199726873,
      "loss": 0.3053,
      "step": 508
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.22459182143211365,
      "learning_rate": 0.00033062478661659273,
      "loss": 0.2837,
      "step": 509
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.23864047229290009,
      "learning_rate": 0.00033048822123591667,
      "loss": 0.3076,
      "step": 510
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.2538717985153198,
      "learning_rate": 0.0003303516558552407,
      "loss": 0.3137,
      "step": 511
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.21586747467517853,
      "learning_rate": 0.0003302150904745647,
      "loss": 0.2911,
      "step": 512
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.2315429300069809,
      "learning_rate": 0.0003300785250938887,
      "loss": 0.2651,
      "step": 513
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.22632360458374023,
      "learning_rate": 0.00032994195971321275,
      "loss": 0.2836,
      "step": 514
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.2672441601753235,
      "learning_rate": 0.00032980539433253675,
      "loss": 0.3378,
      "step": 515
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.21000726521015167,
      "learning_rate": 0.0003296688289518607,
      "loss": 0.2736,
      "step": 516
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.21258525550365448,
      "learning_rate": 0.00032953226357118474,
      "loss": 0.2708,
      "step": 517
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.21957795321941376,
      "learning_rate": 0.00032939569819050873,
      "loss": 0.2903,
      "step": 518
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.2004522681236267,
      "learning_rate": 0.0003292591328098327,
      "loss": 0.2851,
      "step": 519
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.19407841563224792,
      "learning_rate": 0.0003291225674291567,
      "loss": 0.2544,
      "step": 520
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.22608740627765656,
      "learning_rate": 0.0003289860020484807,
      "loss": 0.3095,
      "step": 521
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.2553013563156128,
      "learning_rate": 0.0003288494366678047,
      "loss": 0.3426,
      "step": 522
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.24679940938949585,
      "learning_rate": 0.0003287128712871287,
      "loss": 0.3162,
      "step": 523
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.21840453147888184,
      "learning_rate": 0.00032857630590645275,
      "loss": 0.2986,
      "step": 524
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.26539304852485657,
      "learning_rate": 0.00032843974052577674,
      "loss": 0.3693,
      "step": 525
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.23466843366622925,
      "learning_rate": 0.00032830317514510074,
      "loss": 0.2956,
      "step": 526
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.2602140009403229,
      "learning_rate": 0.00032816660976442473,
      "loss": 0.3152,
      "step": 527
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.2120136022567749,
      "learning_rate": 0.0003280300443837487,
      "loss": 0.2698,
      "step": 528
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.2200935184955597,
      "learning_rate": 0.0003278934790030727,
      "loss": 0.2849,
      "step": 529
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.24048815667629242,
      "learning_rate": 0.00032775691362239677,
      "loss": 0.2752,
      "step": 530
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.24697589874267578,
      "learning_rate": 0.00032762034824172076,
      "loss": 0.3048,
      "step": 531
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.25353580713272095,
      "learning_rate": 0.00032748378286104476,
      "loss": 0.3104,
      "step": 532
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.22914521396160126,
      "learning_rate": 0.00032734721748036875,
      "loss": 0.2587,
      "step": 533
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.25223249197006226,
      "learning_rate": 0.00032721065209969275,
      "loss": 0.2857,
      "step": 534
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.20144064724445343,
      "learning_rate": 0.00032707408671901674,
      "loss": 0.2587,
      "step": 535
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.2628914415836334,
      "learning_rate": 0.00032693752133834073,
      "loss": 0.3164,
      "step": 536
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.23092570900917053,
      "learning_rate": 0.0003268009559576648,
      "loss": 0.2955,
      "step": 537
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.2483551949262619,
      "learning_rate": 0.0003266643905769887,
      "loss": 0.3197,
      "step": 538
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.24644523859024048,
      "learning_rate": 0.0003265278251963127,
      "loss": 0.2975,
      "step": 539
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.2311246246099472,
      "learning_rate": 0.00032639125981563676,
      "loss": 0.3007,
      "step": 540
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.2329186201095581,
      "learning_rate": 0.00032625469443496076,
      "loss": 0.2746,
      "step": 541
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.253858357667923,
      "learning_rate": 0.00032611812905428475,
      "loss": 0.2713,
      "step": 542
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.24943000078201294,
      "learning_rate": 0.00032598156367360875,
      "loss": 0.2987,
      "step": 543
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.2607397735118866,
      "learning_rate": 0.00032584499829293274,
      "loss": 0.3128,
      "step": 544
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.21323326230049133,
      "learning_rate": 0.00032570843291225673,
      "loss": 0.2911,
      "step": 545
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.22772394120693207,
      "learning_rate": 0.0003255718675315808,
      "loss": 0.2973,
      "step": 546
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.22225059568881989,
      "learning_rate": 0.0003254353021509048,
      "loss": 0.3252,
      "step": 547
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.23616188764572144,
      "learning_rate": 0.00032529873677022877,
      "loss": 0.3225,
      "step": 548
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.226515531539917,
      "learning_rate": 0.00032516217138955277,
      "loss": 0.3006,
      "step": 549
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.2777732014656067,
      "learning_rate": 0.00032502560600887676,
      "loss": 0.3376,
      "step": 550
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.23271530866622925,
      "learning_rate": 0.00032488904062820075,
      "loss": 0.3051,
      "step": 551
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.26344048976898193,
      "learning_rate": 0.0003247524752475248,
      "loss": 0.3008,
      "step": 552
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.20472854375839233,
      "learning_rate": 0.0003246159098668488,
      "loss": 0.2644,
      "step": 553
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.2197595089673996,
      "learning_rate": 0.0003244793444861728,
      "loss": 0.2784,
      "step": 554
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.29249078035354614,
      "learning_rate": 0.00032434277910549673,
      "loss": 0.3303,
      "step": 555
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.27194032073020935,
      "learning_rate": 0.0003242062137248208,
      "loss": 0.3077,
      "step": 556
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.2777726948261261,
      "learning_rate": 0.0003240696483441448,
      "loss": 0.3073,
      "step": 557
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.27145203948020935,
      "learning_rate": 0.00032393308296346877,
      "loss": 0.3358,
      "step": 558
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.22894646227359772,
      "learning_rate": 0.0003237965175827928,
      "loss": 0.274,
      "step": 559
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.2698633372783661,
      "learning_rate": 0.00032365995220211676,
      "loss": 0.3112,
      "step": 560
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.20423170924186707,
      "learning_rate": 0.00032352338682144075,
      "loss": 0.2698,
      "step": 561
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.22150705754756927,
      "learning_rate": 0.0003233868214407648,
      "loss": 0.2845,
      "step": 562
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.2498629093170166,
      "learning_rate": 0.0003232502560600888,
      "loss": 0.2854,
      "step": 563
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.24699947237968445,
      "learning_rate": 0.0003231136906794128,
      "loss": 0.2792,
      "step": 564
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.29410219192504883,
      "learning_rate": 0.0003229771252987368,
      "loss": 0.2915,
      "step": 565
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.24067720770835876,
      "learning_rate": 0.0003228405599180608,
      "loss": 0.2697,
      "step": 566
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.23433727025985718,
      "learning_rate": 0.00032270399453738477,
      "loss": 0.2973,
      "step": 567
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.22253163158893585,
      "learning_rate": 0.0003225674291567088,
      "loss": 0.2654,
      "step": 568
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.260884165763855,
      "learning_rate": 0.0003224308637760328,
      "loss": 0.2877,
      "step": 569
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.26322606205940247,
      "learning_rate": 0.0003222942983953568,
      "loss": 0.2949,
      "step": 570
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.2531607449054718,
      "learning_rate": 0.0003221577330146808,
      "loss": 0.2831,
      "step": 571
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.2755001187324524,
      "learning_rate": 0.0003220211676340048,
      "loss": 0.3091,
      "step": 572
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.25070714950561523,
      "learning_rate": 0.0003218846022533288,
      "loss": 0.3104,
      "step": 573
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.21333590149879456,
      "learning_rate": 0.0003217480368726528,
      "loss": 0.2738,
      "step": 574
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.23027096688747406,
      "learning_rate": 0.00032161147149197683,
      "loss": 0.2718,
      "step": 575
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.24842569231987,
      "learning_rate": 0.0003214749061113008,
      "loss": 0.306,
      "step": 576
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.26059767603874207,
      "learning_rate": 0.00032133834073062476,
      "loss": 0.3247,
      "step": 577
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.24429315328598022,
      "learning_rate": 0.0003212017753499488,
      "loss": 0.2858,
      "step": 578
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.23248037695884705,
      "learning_rate": 0.0003210652099692728,
      "loss": 0.2937,
      "step": 579
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.24480308592319489,
      "learning_rate": 0.0003209286445885968,
      "loss": 0.2705,
      "step": 580
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.2592727243900299,
      "learning_rate": 0.00032079207920792085,
      "loss": 0.2723,
      "step": 581
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.3040045499801636,
      "learning_rate": 0.0003206555138272448,
      "loss": 0.3344,
      "step": 582
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.2486877590417862,
      "learning_rate": 0.0003205189484465688,
      "loss": 0.2937,
      "step": 583
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.291645348072052,
      "learning_rate": 0.00032038238306589283,
      "loss": 0.2812,
      "step": 584
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.22450725734233856,
      "learning_rate": 0.0003202458176852168,
      "loss": 0.2687,
      "step": 585
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.23074780404567719,
      "learning_rate": 0.0003201092523045408,
      "loss": 0.2607,
      "step": 586
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.2545883059501648,
      "learning_rate": 0.0003199726869238648,
      "loss": 0.2747,
      "step": 587
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.23479263484477997,
      "learning_rate": 0.0003198361215431888,
      "loss": 0.2426,
      "step": 588
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.26226720213890076,
      "learning_rate": 0.0003196995561625128,
      "loss": 0.2492,
      "step": 589
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.32191288471221924,
      "learning_rate": 0.0003195629907818368,
      "loss": 0.2697,
      "step": 590
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2786462604999542,
      "learning_rate": 0.00031942642540116084,
      "loss": 0.2388,
      "step": 591
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.32363754510879517,
      "learning_rate": 0.00031928986002048484,
      "loss": 0.2911,
      "step": 592
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.2995135486125946,
      "learning_rate": 0.00031915329463980883,
      "loss": 0.2821,
      "step": 593
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.2548411786556244,
      "learning_rate": 0.00031901672925913283,
      "loss": 0.2705,
      "step": 594
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.2622937262058258,
      "learning_rate": 0.0003188801638784568,
      "loss": 0.2637,
      "step": 595
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.22986482083797455,
      "learning_rate": 0.0003187435984977808,
      "loss": 0.2369,
      "step": 596
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.24805472791194916,
      "learning_rate": 0.00031860703311710486,
      "loss": 0.2636,
      "step": 597
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.24748413264751434,
      "learning_rate": 0.00031847046773642886,
      "loss": 0.2378,
      "step": 598
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.2822194993495941,
      "learning_rate": 0.0003183339023557528,
      "loss": 0.2636,
      "step": 599
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.28365758061408997,
      "learning_rate": 0.00031819733697507685,
      "loss": 0.2585,
      "step": 600
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.31404346227645874,
      "learning_rate": 0.00031806077159440084,
      "loss": 0.2571,
      "step": 601
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.30190208554267883,
      "learning_rate": 0.00031792420621372483,
      "loss": 0.267,
      "step": 602
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.3302168548107147,
      "learning_rate": 0.00031778764083304883,
      "loss": 0.2702,
      "step": 603
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.3031648099422455,
      "learning_rate": 0.0003176510754523728,
      "loss": 0.2824,
      "step": 604
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.30199965834617615,
      "learning_rate": 0.0003175145100716968,
      "loss": 0.2681,
      "step": 605
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.2609722316265106,
      "learning_rate": 0.0003173779446910208,
      "loss": 0.2647,
      "step": 606
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.24228164553642273,
      "learning_rate": 0.00031724137931034486,
      "loss": 0.2591,
      "step": 607
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.23881682753562927,
      "learning_rate": 0.00031710481392966885,
      "loss": 0.2157,
      "step": 608
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.28731048107147217,
      "learning_rate": 0.00031696824854899285,
      "loss": 0.2697,
      "step": 609
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.303299218416214,
      "learning_rate": 0.00031683168316831684,
      "loss": 0.2759,
      "step": 610
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.30895745754241943,
      "learning_rate": 0.00031669511778764084,
      "loss": 0.2786,
      "step": 611
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.27508968114852905,
      "learning_rate": 0.00031655855240696483,
      "loss": 0.2549,
      "step": 612
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.2568661570549011,
      "learning_rate": 0.0003164219870262889,
      "loss": 0.2403,
      "step": 613
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.28074145317077637,
      "learning_rate": 0.00031628542164561287,
      "loss": 0.2315,
      "step": 614
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.24714379012584686,
      "learning_rate": 0.00031614885626493687,
      "loss": 0.2242,
      "step": 615
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.32963407039642334,
      "learning_rate": 0.00031601229088426086,
      "loss": 0.2765,
      "step": 616
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.3279256224632263,
      "learning_rate": 0.00031587572550358486,
      "loss": 0.2933,
      "step": 617
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.28644028306007385,
      "learning_rate": 0.00031573916012290885,
      "loss": 0.2803,
      "step": 618
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.28528892993927,
      "learning_rate": 0.00031560259474223284,
      "loss": 0.2875,
      "step": 619
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.2486429065465927,
      "learning_rate": 0.0003154660293615569,
      "loss": 0.2468,
      "step": 620
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.2676497995853424,
      "learning_rate": 0.00031532946398088083,
      "loss": 0.2454,
      "step": 621
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.2713560461997986,
      "learning_rate": 0.0003151928986002048,
      "loss": 0.2564,
      "step": 622
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.2803455591201782,
      "learning_rate": 0.0003150563332195289,
      "loss": 0.2607,
      "step": 623
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.2626256048679352,
      "learning_rate": 0.00031491976783885287,
      "loss": 0.2485,
      "step": 624
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.3161276876926422,
      "learning_rate": 0.00031478320245817686,
      "loss": 0.2538,
      "step": 625
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.29687508940696716,
      "learning_rate": 0.00031464663707750086,
      "loss": 0.2382,
      "step": 626
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.3442644476890564,
      "learning_rate": 0.00031451007169682485,
      "loss": 0.2692,
      "step": 627
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.3355252742767334,
      "learning_rate": 0.00031437350631614884,
      "loss": 0.2888,
      "step": 628
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.2590068280696869,
      "learning_rate": 0.0003142369409354729,
      "loss": 0.2425,
      "step": 629
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.2568148076534271,
      "learning_rate": 0.0003141003755547969,
      "loss": 0.2341,
      "step": 630
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.2782413959503174,
      "learning_rate": 0.0003139638101741209,
      "loss": 0.2554,
      "step": 631
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.2784276604652405,
      "learning_rate": 0.0003138272447934449,
      "loss": 0.2816,
      "step": 632
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.304522305727005,
      "learning_rate": 0.00031369067941276887,
      "loss": 0.2946,
      "step": 633
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.27047568559646606,
      "learning_rate": 0.00031355411403209286,
      "loss": 0.2604,
      "step": 634
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.26798924803733826,
      "learning_rate": 0.00031341754865141686,
      "loss": 0.2788,
      "step": 635
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.29893046617507935,
      "learning_rate": 0.0003132809832707409,
      "loss": 0.2736,
      "step": 636
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.2836349606513977,
      "learning_rate": 0.0003131444178900649,
      "loss": 0.2585,
      "step": 637
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.3224533796310425,
      "learning_rate": 0.00031300785250938884,
      "loss": 0.2661,
      "step": 638
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.2459944635629654,
      "learning_rate": 0.0003128712871287129,
      "loss": 0.2407,
      "step": 639
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.255055695772171,
      "learning_rate": 0.0003127347217480369,
      "loss": 0.2456,
      "step": 640
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.2923852205276489,
      "learning_rate": 0.0003125981563673609,
      "loss": 0.2471,
      "step": 641
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.28309422731399536,
      "learning_rate": 0.0003124615909866849,
      "loss": 0.2529,
      "step": 642
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.28973591327667236,
      "learning_rate": 0.00031232502560600887,
      "loss": 0.2577,
      "step": 643
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.29402920603752136,
      "learning_rate": 0.00031218846022533286,
      "loss": 0.2638,
      "step": 644
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.27947381138801575,
      "learning_rate": 0.0003120518948446569,
      "loss": 0.2384,
      "step": 645
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.26717349886894226,
      "learning_rate": 0.0003119153294639809,
      "loss": 0.2245,
      "step": 646
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.36581602692604065,
      "learning_rate": 0.0003117787640833049,
      "loss": 0.2745,
      "step": 647
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.3059908151626587,
      "learning_rate": 0.00031164219870262894,
      "loss": 0.2733,
      "step": 648
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.35893580317497253,
      "learning_rate": 0.0003115056333219529,
      "loss": 0.2511,
      "step": 649
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.2775363624095917,
      "learning_rate": 0.0003113690679412769,
      "loss": 0.2584,
      "step": 650
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.295235812664032,
      "learning_rate": 0.00031123250256060087,
      "loss": 0.2459,
      "step": 651
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.3265732228755951,
      "learning_rate": 0.0003110959371799249,
      "loss": 0.2744,
      "step": 652
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.2942526936531067,
      "learning_rate": 0.0003109593717992489,
      "loss": 0.2437,
      "step": 653
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.32908937335014343,
      "learning_rate": 0.0003108228064185729,
      "loss": 0.2634,
      "step": 654
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.36819320917129517,
      "learning_rate": 0.0003106862410378969,
      "loss": 0.3239,
      "step": 655
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.2666073143482208,
      "learning_rate": 0.0003105496756572209,
      "loss": 0.2268,
      "step": 656
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3843906819820404,
      "learning_rate": 0.0003104131102765449,
      "loss": 0.2783,
      "step": 657
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.2553766369819641,
      "learning_rate": 0.00031027654489586894,
      "loss": 0.2411,
      "step": 658
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.3624238669872284,
      "learning_rate": 0.00031013997951519293,
      "loss": 0.2722,
      "step": 659
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.31297534704208374,
      "learning_rate": 0.0003100034141345169,
      "loss": 0.2706,
      "step": 660
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.31684568524360657,
      "learning_rate": 0.0003098668487538409,
      "loss": 0.2538,
      "step": 661
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.3213319778442383,
      "learning_rate": 0.0003097302833731649,
      "loss": 0.2523,
      "step": 662
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.4779462218284607,
      "learning_rate": 0.0003095937179924889,
      "loss": 0.2927,
      "step": 663
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.3026541471481323,
      "learning_rate": 0.00030945715261181296,
      "loss": 0.2551,
      "step": 664
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.3311305642127991,
      "learning_rate": 0.00030932058723113695,
      "loss": 0.2208,
      "step": 665
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.3042091429233551,
      "learning_rate": 0.0003091840218504609,
      "loss": 0.231,
      "step": 666
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.265809565782547,
      "learning_rate": 0.00030904745646978494,
      "loss": 0.2502,
      "step": 667
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.3381834924221039,
      "learning_rate": 0.00030891089108910894,
      "loss": 0.2285,
      "step": 668
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.35733169317245483,
      "learning_rate": 0.00030877432570843293,
      "loss": 0.28,
      "step": 669
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.2805085778236389,
      "learning_rate": 0.0003086377603277569,
      "loss": 0.2507,
      "step": 670
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.3854765295982361,
      "learning_rate": 0.0003085011949470809,
      "loss": 0.2766,
      "step": 671
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.3840591311454773,
      "learning_rate": 0.0003083646295664049,
      "loss": 0.2768,
      "step": 672
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.29096904397010803,
      "learning_rate": 0.0003082280641857289,
      "loss": 0.2436,
      "step": 673
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.30415967106819153,
      "learning_rate": 0.00030809149880505295,
      "loss": 0.2251,
      "step": 674
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.2738903760910034,
      "learning_rate": 0.00030795493342437695,
      "loss": 0.2451,
      "step": 675
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.2681007981300354,
      "learning_rate": 0.00030781836804370094,
      "loss": 0.2268,
      "step": 676
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.30679404735565186,
      "learning_rate": 0.00030768180266302494,
      "loss": 0.2847,
      "step": 677
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.2807861864566803,
      "learning_rate": 0.00030754523728234893,
      "loss": 0.2263,
      "step": 678
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.33048173785209656,
      "learning_rate": 0.0003074086719016729,
      "loss": 0.2678,
      "step": 679
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.2610887885093689,
      "learning_rate": 0.000307272106520997,
      "loss": 0.2201,
      "step": 680
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.27570798993110657,
      "learning_rate": 0.00030713554114032097,
      "loss": 0.2441,
      "step": 681
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.30896615982055664,
      "learning_rate": 0.00030699897575964496,
      "loss": 0.2555,
      "step": 682
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.2746807336807251,
      "learning_rate": 0.00030686241037896896,
      "loss": 0.2416,
      "step": 683
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.34921547770500183,
      "learning_rate": 0.00030672584499829295,
      "loss": 0.3002,
      "step": 684
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.3305409252643585,
      "learning_rate": 0.00030658927961761694,
      "loss": 0.2758,
      "step": 685
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.3247512876987457,
      "learning_rate": 0.00030645271423694094,
      "loss": 0.2483,
      "step": 686
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.2827194631099701,
      "learning_rate": 0.000306316148856265,
      "loss": 0.251,
      "step": 687
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.2888502776622772,
      "learning_rate": 0.00030617958347558893,
      "loss": 0.2535,
      "step": 688
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.3101057708263397,
      "learning_rate": 0.0003060430180949129,
      "loss": 0.2353,
      "step": 689
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.34698182344436646,
      "learning_rate": 0.00030590645271423697,
      "loss": 0.2497,
      "step": 690
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.27240321040153503,
      "learning_rate": 0.00030576988733356096,
      "loss": 0.2407,
      "step": 691
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.2992326319217682,
      "learning_rate": 0.00030563332195288496,
      "loss": 0.2575,
      "step": 692
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.34528520703315735,
      "learning_rate": 0.00030549675657220895,
      "loss": 0.2733,
      "step": 693
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.27604684233665466,
      "learning_rate": 0.00030536019119153295,
      "loss": 0.2616,
      "step": 694
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.25040870904922485,
      "learning_rate": 0.00030522362581085694,
      "loss": 0.2289,
      "step": 695
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.2581034302711487,
      "learning_rate": 0.000305087060430181,
      "loss": 0.2281,
      "step": 696
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.27292492985725403,
      "learning_rate": 0.000304950495049505,
      "loss": 0.2348,
      "step": 697
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.2997443675994873,
      "learning_rate": 0.000304813929668829,
      "loss": 0.2575,
      "step": 698
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.3166705071926117,
      "learning_rate": 0.00030467736428815297,
      "loss": 0.2651,
      "step": 699
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.3317769467830658,
      "learning_rate": 0.00030454079890747697,
      "loss": 0.2571,
      "step": 700
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.3580833673477173,
      "learning_rate": 0.00030440423352680096,
      "loss": 0.2978,
      "step": 701
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.3152810335159302,
      "learning_rate": 0.00030426766814612495,
      "loss": 0.2732,
      "step": 702
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.290412575006485,
      "learning_rate": 0.000304131102765449,
      "loss": 0.2467,
      "step": 703
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.24854081869125366,
      "learning_rate": 0.000303994537384773,
      "loss": 0.243,
      "step": 704
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.251250684261322,
      "learning_rate": 0.00030385797200409694,
      "loss": 0.2484,
      "step": 705
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.24387232959270477,
      "learning_rate": 0.000303721406623421,
      "loss": 0.2406,
      "step": 706
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.25394347310066223,
      "learning_rate": 0.000303584841242745,
      "loss": 0.2228,
      "step": 707
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.2663169205188751,
      "learning_rate": 0.00030344827586206897,
      "loss": 0.2362,
      "step": 708
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.3247399926185608,
      "learning_rate": 0.000303311710481393,
      "loss": 0.2778,
      "step": 709
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.33574846386909485,
      "learning_rate": 0.00030317514510071696,
      "loss": 0.2594,
      "step": 710
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.409232497215271,
      "learning_rate": 0.00030303857972004096,
      "loss": 0.2642,
      "step": 711
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.30598199367523193,
      "learning_rate": 0.000302902014339365,
      "loss": 0.2354,
      "step": 712
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.3022158145904541,
      "learning_rate": 0.000302765448958689,
      "loss": 0.2427,
      "step": 713
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.29933327436447144,
      "learning_rate": 0.000302628883578013,
      "loss": 0.2441,
      "step": 714
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.25995954871177673,
      "learning_rate": 0.000302492318197337,
      "loss": 0.2218,
      "step": 715
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.2721095085144043,
      "learning_rate": 0.000302355752816661,
      "loss": 0.2136,
      "step": 716
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.3313751518726349,
      "learning_rate": 0.000302219187435985,
      "loss": 0.2405,
      "step": 717
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.31067144870758057,
      "learning_rate": 0.00030208262205530897,
      "loss": 0.2452,
      "step": 718
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.3437124192714691,
      "learning_rate": 0.000301946056674633,
      "loss": 0.2425,
      "step": 719
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.34595808386802673,
      "learning_rate": 0.000301809491293957,
      "loss": 0.2535,
      "step": 720
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.257402628660202,
      "learning_rate": 0.000301672925913281,
      "loss": 0.2009,
      "step": 721
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.2982734441757202,
      "learning_rate": 0.000301536360532605,
      "loss": 0.2296,
      "step": 722
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.3877638578414917,
      "learning_rate": 0.000301399795151929,
      "loss": 0.2951,
      "step": 723
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.2884873151779175,
      "learning_rate": 0.000301263229771253,
      "loss": 0.2408,
      "step": 724
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.28140708804130554,
      "learning_rate": 0.00030112666439057704,
      "loss": 0.2342,
      "step": 725
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.3028900623321533,
      "learning_rate": 0.00030099009900990103,
      "loss": 0.2549,
      "step": 726
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.3004824221134186,
      "learning_rate": 0.00030085353362922497,
      "loss": 0.2295,
      "step": 727
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.34865355491638184,
      "learning_rate": 0.000300716968248549,
      "loss": 0.2497,
      "step": 728
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.31758394837379456,
      "learning_rate": 0.000300580402867873,
      "loss": 0.2412,
      "step": 729
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.3228558301925659,
      "learning_rate": 0.000300443837487197,
      "loss": 0.2548,
      "step": 730
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.2849781811237335,
      "learning_rate": 0.00030030727210652105,
      "loss": 0.2171,
      "step": 731
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.31990668177604675,
      "learning_rate": 0.000300170706725845,
      "loss": 0.2482,
      "step": 732
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.3424624502658844,
      "learning_rate": 0.000300034141345169,
      "loss": 0.2606,
      "step": 733
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.3061659634113312,
      "learning_rate": 0.000299897575964493,
      "loss": 0.2258,
      "step": 734
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.31414079666137695,
      "learning_rate": 0.00029976101058381703,
      "loss": 0.2361,
      "step": 735
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.35448431968688965,
      "learning_rate": 0.000299624445203141,
      "loss": 0.2367,
      "step": 736
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.3284408748149872,
      "learning_rate": 0.000299487879822465,
      "loss": 0.2501,
      "step": 737
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.30347174406051636,
      "learning_rate": 0.000299351314441789,
      "loss": 0.2437,
      "step": 738
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.307405561208725,
      "learning_rate": 0.000299214749061113,
      "loss": 0.2213,
      "step": 739
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.2793098986148834,
      "learning_rate": 0.000299078183680437,
      "loss": 0.2254,
      "step": 740
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.29770147800445557,
      "learning_rate": 0.00029894161829976105,
      "loss": 0.2429,
      "step": 741
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.30253463983535767,
      "learning_rate": 0.00029880505291908504,
      "loss": 0.2317,
      "step": 742
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.3387569189071655,
      "learning_rate": 0.00029866848753840904,
      "loss": 0.267,
      "step": 743
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.3045158088207245,
      "learning_rate": 0.00029853192215773303,
      "loss": 0.2554,
      "step": 744
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.28460338711738586,
      "learning_rate": 0.000298395356777057,
      "loss": 0.2355,
      "step": 745
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.3839372396469116,
      "learning_rate": 0.000298258791396381,
      "loss": 0.2754,
      "step": 746
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.31111642718315125,
      "learning_rate": 0.00029812222601570507,
      "loss": 0.2418,
      "step": 747
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.3175371587276459,
      "learning_rate": 0.00029798566063502906,
      "loss": 0.2695,
      "step": 748
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.29508957266807556,
      "learning_rate": 0.000297849095254353,
      "loss": 0.2235,
      "step": 749
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.30835410952568054,
      "learning_rate": 0.000297712529873677,
      "loss": 0.2414,
      "step": 750
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.3015405833721161,
      "learning_rate": 0.00029757596449300105,
      "loss": 0.2428,
      "step": 751
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.2813645899295807,
      "learning_rate": 0.00029743939911232504,
      "loss": 0.2195,
      "step": 752
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.375727117061615,
      "learning_rate": 0.00029730283373164903,
      "loss": 0.272,
      "step": 753
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.29679930210113525,
      "learning_rate": 0.00029716626835097303,
      "loss": 0.2239,
      "step": 754
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.32407018542289734,
      "learning_rate": 0.000297029702970297,
      "loss": 0.2487,
      "step": 755
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.3077021837234497,
      "learning_rate": 0.000296893137589621,
      "loss": 0.2168,
      "step": 756
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.29967018961906433,
      "learning_rate": 0.00029675657220894506,
      "loss": 0.2255,
      "step": 757
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.2915712594985962,
      "learning_rate": 0.00029662000682826906,
      "loss": 0.237,
      "step": 758
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.30048152804374695,
      "learning_rate": 0.00029648344144759305,
      "loss": 0.2386,
      "step": 759
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.33901247382164,
      "learning_rate": 0.00029634687606691705,
      "loss": 0.2408,
      "step": 760
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.3419017195701599,
      "learning_rate": 0.00029621031068624104,
      "loss": 0.2563,
      "step": 761
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.2807473838329315,
      "learning_rate": 0.00029607374530556504,
      "loss": 0.2121,
      "step": 762
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.3045010268688202,
      "learning_rate": 0.0002959371799248891,
      "loss": 0.236,
      "step": 763
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.40098056197166443,
      "learning_rate": 0.0002958006145442131,
      "loss": 0.2852,
      "step": 764
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.32072681188583374,
      "learning_rate": 0.00029566404916353707,
      "loss": 0.2587,
      "step": 765
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.25665050745010376,
      "learning_rate": 0.00029552748378286107,
      "loss": 0.2168,
      "step": 766
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.331119179725647,
      "learning_rate": 0.00029539091840218506,
      "loss": 0.2753,
      "step": 767
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.3061767816543579,
      "learning_rate": 0.00029525435302150905,
      "loss": 0.2432,
      "step": 768
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.25391489267349243,
      "learning_rate": 0.00029511778764083305,
      "loss": 0.209,
      "step": 769
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.2607884407043457,
      "learning_rate": 0.0002949812222601571,
      "loss": 0.2001,
      "step": 770
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.3020077645778656,
      "learning_rate": 0.00029484465687948104,
      "loss": 0.2128,
      "step": 771
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.2972436547279358,
      "learning_rate": 0.00029470809149880503,
      "loss": 0.2163,
      "step": 772
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.3389706015586853,
      "learning_rate": 0.0002945715261181291,
      "loss": 0.239,
      "step": 773
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.3657676875591278,
      "learning_rate": 0.0002944349607374531,
      "loss": 0.2604,
      "step": 774
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.30844593048095703,
      "learning_rate": 0.00029429839535677707,
      "loss": 0.2204,
      "step": 775
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.40547457337379456,
      "learning_rate": 0.00029416182997610106,
      "loss": 0.267,
      "step": 776
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.3053847551345825,
      "learning_rate": 0.00029402526459542506,
      "loss": 0.2142,
      "step": 777
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.33917510509490967,
      "learning_rate": 0.00029388869921474905,
      "loss": 0.2655,
      "step": 778
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.2928614914417267,
      "learning_rate": 0.0002937521338340731,
      "loss": 0.2176,
      "step": 779
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.33835721015930176,
      "learning_rate": 0.0002936155684533971,
      "loss": 0.2429,
      "step": 780
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.28479239344596863,
      "learning_rate": 0.0002934790030727211,
      "loss": 0.25,
      "step": 781
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.30384114384651184,
      "learning_rate": 0.0002933424376920451,
      "loss": 0.2693,
      "step": 782
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.31234925985336304,
      "learning_rate": 0.0002932058723113691,
      "loss": 0.228,
      "step": 783
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.29555395245552063,
      "learning_rate": 0.00029306930693069307,
      "loss": 0.2324,
      "step": 784
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.3023376762866974,
      "learning_rate": 0.00029293274155001706,
      "loss": 0.2271,
      "step": 785
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.337980717420578,
      "learning_rate": 0.0002927961761693411,
      "loss": 0.2309,
      "step": 786
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.34002307057380676,
      "learning_rate": 0.0002926596107886651,
      "loss": 0.2522,
      "step": 787
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.29265618324279785,
      "learning_rate": 0.00029252304540798905,
      "loss": 0.2241,
      "step": 788
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.31291118264198303,
      "learning_rate": 0.0002923864800273131,
      "loss": 0.2481,
      "step": 789
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.2775956690311432,
      "learning_rate": 0.0002922499146466371,
      "loss": 0.2058,
      "step": 790
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.2999938726425171,
      "learning_rate": 0.0002921133492659611,
      "loss": 0.233,
      "step": 791
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.2878982126712799,
      "learning_rate": 0.00029197678388528513,
      "loss": 0.2262,
      "step": 792
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.32835647463798523,
      "learning_rate": 0.00029184021850460907,
      "loss": 0.2343,
      "step": 793
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.35022467374801636,
      "learning_rate": 0.00029170365312393307,
      "loss": 0.2597,
      "step": 794
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.3087023198604584,
      "learning_rate": 0.0002915670877432571,
      "loss": 0.2295,
      "step": 795
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.289816290140152,
      "learning_rate": 0.0002914305223625811,
      "loss": 0.2306,
      "step": 796
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.2709210515022278,
      "learning_rate": 0.0002912939569819051,
      "loss": 0.225,
      "step": 797
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.27896231412887573,
      "learning_rate": 0.00029115739160122915,
      "loss": 0.2105,
      "step": 798
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.2858116924762726,
      "learning_rate": 0.0002910208262205531,
      "loss": 0.2105,
      "step": 799
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.277883380651474,
      "learning_rate": 0.0002908842608398771,
      "loss": 0.2157,
      "step": 800
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.33724647760391235,
      "learning_rate": 0.0002907476954592011,
      "loss": 0.2287,
      "step": 801
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.3286634385585785,
      "learning_rate": 0.0002906111300785251,
      "loss": 0.2178,
      "step": 802
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.3831334710121155,
      "learning_rate": 0.0002904745646978491,
      "loss": 0.2333,
      "step": 803
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.29567062854766846,
      "learning_rate": 0.0002903379993171731,
      "loss": 0.1906,
      "step": 804
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.3941294550895691,
      "learning_rate": 0.0002902014339364971,
      "loss": 0.2605,
      "step": 805
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.32062381505966187,
      "learning_rate": 0.0002900648685558211,
      "loss": 0.2251,
      "step": 806
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.2895907759666443,
      "learning_rate": 0.0002899283031751451,
      "loss": 0.2225,
      "step": 807
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.3003113269805908,
      "learning_rate": 0.00028979173779446915,
      "loss": 0.229,
      "step": 808
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.3109486997127533,
      "learning_rate": 0.00028965517241379314,
      "loss": 0.271,
      "step": 809
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.27477288246154785,
      "learning_rate": 0.0002895186070331171,
      "loss": 0.2098,
      "step": 810
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.26171064376831055,
      "learning_rate": 0.00028938204165244113,
      "loss": 0.2158,
      "step": 811
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.31512537598609924,
      "learning_rate": 0.0002892454762717651,
      "loss": 0.2542,
      "step": 812
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.2640608549118042,
      "learning_rate": 0.0002891089108910891,
      "loss": 0.2014,
      "step": 813
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.3081047832965851,
      "learning_rate": 0.00028897234551041316,
      "loss": 0.2184,
      "step": 814
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.3164066672325134,
      "learning_rate": 0.00028883578012973716,
      "loss": 0.2097,
      "step": 815
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.37459537386894226,
      "learning_rate": 0.0002886992147490611,
      "loss": 0.225,
      "step": 816
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.385387659072876,
      "learning_rate": 0.0002885626493683851,
      "loss": 0.224,
      "step": 817
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.3204666078090668,
      "learning_rate": 0.00028842608398770914,
      "loss": 0.2188,
      "step": 818
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.2979351282119751,
      "learning_rate": 0.00028828951860703314,
      "loss": 0.1942,
      "step": 819
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.2948337197303772,
      "learning_rate": 0.00028815295322635713,
      "loss": 0.2156,
      "step": 820
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.29753392934799194,
      "learning_rate": 0.0002880163878456811,
      "loss": 0.2009,
      "step": 821
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.3556009531021118,
      "learning_rate": 0.0002878798224650051,
      "loss": 0.2272,
      "step": 822
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.3112938106060028,
      "learning_rate": 0.0002877432570843291,
      "loss": 0.2069,
      "step": 823
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.32406190037727356,
      "learning_rate": 0.00028760669170365316,
      "loss": 0.2376,
      "step": 824
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.28721246123313904,
      "learning_rate": 0.00028747012632297715,
      "loss": 0.2058,
      "step": 825
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.3482193946838379,
      "learning_rate": 0.00028733356094230115,
      "loss": 0.2429,
      "step": 826
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.31544020771980286,
      "learning_rate": 0.00028719699556162514,
      "loss": 0.2124,
      "step": 827
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.3302372395992279,
      "learning_rate": 0.00028706043018094914,
      "loss": 0.2158,
      "step": 828
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.4201676547527313,
      "learning_rate": 0.00028692386480027313,
      "loss": 0.235,
      "step": 829
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.36885708570480347,
      "learning_rate": 0.0002867872994195972,
      "loss": 0.2338,
      "step": 830
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.32017508149147034,
      "learning_rate": 0.0002866507340389212,
      "loss": 0.2322,
      "step": 831
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.29086485505104065,
      "learning_rate": 0.00028651416865824517,
      "loss": 0.2192,
      "step": 832
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.27868613600730896,
      "learning_rate": 0.0002863776032775691,
      "loss": 0.2202,
      "step": 833
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.3060135841369629,
      "learning_rate": 0.00028624103789689316,
      "loss": 0.2256,
      "step": 834
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.37719663977622986,
      "learning_rate": 0.00028610447251621715,
      "loss": 0.2933,
      "step": 835
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.2985701560974121,
      "learning_rate": 0.00028596790713554114,
      "loss": 0.2059,
      "step": 836
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.28321656584739685,
      "learning_rate": 0.0002858313417548652,
      "loss": 0.2138,
      "step": 837
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.35457703471183777,
      "learning_rate": 0.00028569477637418913,
      "loss": 0.2475,
      "step": 838
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.3412846624851227,
      "learning_rate": 0.0002855582109935131,
      "loss": 0.2512,
      "step": 839
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.3182961344718933,
      "learning_rate": 0.0002854216456128372,
      "loss": 0.2417,
      "step": 840
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.3019261360168457,
      "learning_rate": 0.00028528508023216117,
      "loss": 0.2087,
      "step": 841
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.33955439925193787,
      "learning_rate": 0.00028514851485148516,
      "loss": 0.2004,
      "step": 842
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.2843453288078308,
      "learning_rate": 0.00028501194947080916,
      "loss": 0.2051,
      "step": 843
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.33285313844680786,
      "learning_rate": 0.00028487538409013315,
      "loss": 0.2256,
      "step": 844
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.3417319357395172,
      "learning_rate": 0.00028473881870945715,
      "loss": 0.2525,
      "step": 845
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.307253897190094,
      "learning_rate": 0.0002846022533287812,
      "loss": 0.2183,
      "step": 846
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.31560319662094116,
      "learning_rate": 0.0002844656879481052,
      "loss": 0.2245,
      "step": 847
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.30729740858078003,
      "learning_rate": 0.0002843291225674292,
      "loss": 0.24,
      "step": 848
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.3633016049861908,
      "learning_rate": 0.0002841925571867532,
      "loss": 0.2405,
      "step": 849
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.3415476083755493,
      "learning_rate": 0.00028405599180607717,
      "loss": 0.2162,
      "step": 850
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.2885994613170624,
      "learning_rate": 0.00028391942642540116,
      "loss": 0.1985,
      "step": 851
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.3241797983646393,
      "learning_rate": 0.00028378286104472516,
      "loss": 0.2253,
      "step": 852
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.3000405728816986,
      "learning_rate": 0.0002836462956640492,
      "loss": 0.212,
      "step": 853
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.31546875834465027,
      "learning_rate": 0.0002835097302833732,
      "loss": 0.197,
      "step": 854
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.36185017228126526,
      "learning_rate": 0.00028337316490269714,
      "loss": 0.2417,
      "step": 855
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.3032544255256653,
      "learning_rate": 0.0002832365995220212,
      "loss": 0.188,
      "step": 856
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.34311795234680176,
      "learning_rate": 0.0002831000341413452,
      "loss": 0.2197,
      "step": 857
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.36230790615081787,
      "learning_rate": 0.0002829634687606692,
      "loss": 0.2491,
      "step": 858
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.3379611670970917,
      "learning_rate": 0.0002828269033799932,
      "loss": 0.2287,
      "step": 859
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.3311735987663269,
      "learning_rate": 0.00028269033799931717,
      "loss": 0.2269,
      "step": 860
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.44382908940315247,
      "learning_rate": 0.00028255377261864116,
      "loss": 0.2073,
      "step": 861
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.302861750125885,
      "learning_rate": 0.0002824172072379652,
      "loss": 0.2261,
      "step": 862
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.34865373373031616,
      "learning_rate": 0.0002822806418572892,
      "loss": 0.2323,
      "step": 863
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.3242364823818207,
      "learning_rate": 0.0002821440764766132,
      "loss": 0.2334,
      "step": 864
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.3911856412887573,
      "learning_rate": 0.0002820075110959372,
      "loss": 0.2311,
      "step": 865
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.3208194375038147,
      "learning_rate": 0.0002818709457152612,
      "loss": 0.222,
      "step": 866
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.35959184169769287,
      "learning_rate": 0.0002817343803345852,
      "loss": 0.227,
      "step": 867
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.36242541670799255,
      "learning_rate": 0.0002815978149539092,
      "loss": 0.2189,
      "step": 868
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.33084914088249207,
      "learning_rate": 0.0002814612495732332,
      "loss": 0.2055,
      "step": 869
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.3917248249053955,
      "learning_rate": 0.0002813246841925572,
      "loss": 0.2118,
      "step": 870
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.3457864820957184,
      "learning_rate": 0.0002811881188118812,
      "loss": 0.2173,
      "step": 871
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.3480873107910156,
      "learning_rate": 0.0002810515534312052,
      "loss": 0.2106,
      "step": 872
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.3174504041671753,
      "learning_rate": 0.0002809149880505292,
      "loss": 0.1929,
      "step": 873
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.3127475380897522,
      "learning_rate": 0.0002807784226698532,
      "loss": 0.204,
      "step": 874
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.34543007612228394,
      "learning_rate": 0.00028064185728917724,
      "loss": 0.2395,
      "step": 875
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.312093049287796,
      "learning_rate": 0.00028050529190850124,
      "loss": 0.2401,
      "step": 876
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.2829693555831909,
      "learning_rate": 0.0002803687265278252,
      "loss": 0.2174,
      "step": 877
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.3093150854110718,
      "learning_rate": 0.0002802321611471492,
      "loss": 0.2237,
      "step": 878
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.26797592639923096,
      "learning_rate": 0.0002800955957664732,
      "loss": 0.1952,
      "step": 879
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.32668888568878174,
      "learning_rate": 0.0002799590303857972,
      "loss": 0.2307,
      "step": 880
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.2911737561225891,
      "learning_rate": 0.00027982246500512126,
      "loss": 0.1613,
      "step": 881
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.3687017261981964,
      "learning_rate": 0.0002796858996244452,
      "loss": 0.1786,
      "step": 882
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.36060306429862976,
      "learning_rate": 0.0002795493342437692,
      "loss": 0.1829,
      "step": 883
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.5352655053138733,
      "learning_rate": 0.0002794127688630932,
      "loss": 0.1842,
      "step": 884
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.3576361835002899,
      "learning_rate": 0.00027927620348241724,
      "loss": 0.1616,
      "step": 885
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.36187607049942017,
      "learning_rate": 0.00027913963810174123,
      "loss": 0.1793,
      "step": 886
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.2912381887435913,
      "learning_rate": 0.0002790030727210652,
      "loss": 0.1438,
      "step": 887
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.3564930856227875,
      "learning_rate": 0.0002788665073403892,
      "loss": 0.163,
      "step": 888
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.37539878487586975,
      "learning_rate": 0.0002787299419597132,
      "loss": 0.1647,
      "step": 889
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.34697988629341125,
      "learning_rate": 0.0002785933765790372,
      "loss": 0.1623,
      "step": 890
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.3390069305896759,
      "learning_rate": 0.00027845681119836126,
      "loss": 0.1649,
      "step": 891
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.42260754108428955,
      "learning_rate": 0.00027832024581768525,
      "loss": 0.1948,
      "step": 892
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.37667495012283325,
      "learning_rate": 0.00027818368043700924,
      "loss": 0.1745,
      "step": 893
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.33015862107276917,
      "learning_rate": 0.00027804711505633324,
      "loss": 0.1706,
      "step": 894
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.41323158144950867,
      "learning_rate": 0.00027791054967565723,
      "loss": 0.1989,
      "step": 895
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.32872530817985535,
      "learning_rate": 0.0002777739842949812,
      "loss": 0.179,
      "step": 896
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.32055896520614624,
      "learning_rate": 0.0002776374189143053,
      "loss": 0.1684,
      "step": 897
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.3418472111225128,
      "learning_rate": 0.00027750085353362927,
      "loss": 0.1767,
      "step": 898
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.43275657296180725,
      "learning_rate": 0.0002773642881529532,
      "loss": 0.1859,
      "step": 899
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.3546399176120758,
      "learning_rate": 0.0002772277227722772,
      "loss": 0.1778,
      "step": 900
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.4182811677455902,
      "learning_rate": 0.00027709115739160125,
      "loss": 0.1915,
      "step": 901
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.4132921099662781,
      "learning_rate": 0.00027695459201092525,
      "loss": 0.1907,
      "step": 902
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.3578316271305084,
      "learning_rate": 0.00027681802663024924,
      "loss": 0.166,
      "step": 903
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.4101463556289673,
      "learning_rate": 0.00027668146124957323,
      "loss": 0.1865,
      "step": 904
    },
    {
      "epoch": 3.09,
      "grad_norm": 0.3503395915031433,
      "learning_rate": 0.00027654489586889723,
      "loss": 0.1871,
      "step": 905
    },
    {
      "epoch": 3.09,
      "grad_norm": 0.30999404191970825,
      "learning_rate": 0.0002764083304882212,
      "loss": 0.1705,
      "step": 906
    },
    {
      "epoch": 3.09,
      "grad_norm": 0.32750338315963745,
      "learning_rate": 0.00027627176510754527,
      "loss": 0.1556,
      "step": 907
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.3421001732349396,
      "learning_rate": 0.00027613519972686926,
      "loss": 0.1814,
      "step": 908
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.41279077529907227,
      "learning_rate": 0.00027599863434619326,
      "loss": 0.1917,
      "step": 909
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.3888916075229645,
      "learning_rate": 0.00027586206896551725,
      "loss": 0.195,
      "step": 910
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.3273974061012268,
      "learning_rate": 0.00027572550358484125,
      "loss": 0.1641,
      "step": 911
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.35132208466529846,
      "learning_rate": 0.00027558893820416524,
      "loss": 0.1896,
      "step": 912
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.3431086540222168,
      "learning_rate": 0.0002754523728234893,
      "loss": 0.186,
      "step": 913
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.3244113326072693,
      "learning_rate": 0.0002753158074428133,
      "loss": 0.1541,
      "step": 914
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.33612948656082153,
      "learning_rate": 0.0002751792420621373,
      "loss": 0.1827,
      "step": 915
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.3407977521419525,
      "learning_rate": 0.0002750426766814612,
      "loss": 0.1584,
      "step": 916
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.3577534258365631,
      "learning_rate": 0.00027490611130078527,
      "loss": 0.1655,
      "step": 917
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.4050396680831909,
      "learning_rate": 0.00027476954592010926,
      "loss": 0.1851,
      "step": 918
    },
    {
      "epoch": 3.13,
      "grad_norm": 0.4126919209957123,
      "learning_rate": 0.00027463298053943325,
      "loss": 0.2033,
      "step": 919
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.3916444182395935,
      "learning_rate": 0.0002744964151587573,
      "loss": 0.1651,
      "step": 920
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.3322475850582123,
      "learning_rate": 0.00027435984977808124,
      "loss": 0.1736,
      "step": 921
    },
    {
      "epoch": 3.14,
      "grad_norm": 0.3390955328941345,
      "learning_rate": 0.00027422328439740524,
      "loss": 0.1576,
      "step": 922
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.36328279972076416,
      "learning_rate": 0.0002740867190167293,
      "loss": 0.1699,
      "step": 923
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.4026196002960205,
      "learning_rate": 0.0002739501536360533,
      "loss": 0.1837,
      "step": 924
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.4087141752243042,
      "learning_rate": 0.0002738135882553773,
      "loss": 0.1813,
      "step": 925
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.376098096370697,
      "learning_rate": 0.00027367702287470127,
      "loss": 0.1868,
      "step": 926
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.3931495249271393,
      "learning_rate": 0.00027354045749402526,
      "loss": 0.1862,
      "step": 927
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.3501856327056885,
      "learning_rate": 0.00027340389211334926,
      "loss": 0.1652,
      "step": 928
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.3527006506919861,
      "learning_rate": 0.0002732673267326733,
      "loss": 0.1895,
      "step": 929
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.34535154700279236,
      "learning_rate": 0.0002731307613519973,
      "loss": 0.1835,
      "step": 930
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.38135215640068054,
      "learning_rate": 0.0002729941959713213,
      "loss": 0.1786,
      "step": 931
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.3445679843425751,
      "learning_rate": 0.0002728576305906453,
      "loss": 0.1778,
      "step": 932
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.323022723197937,
      "learning_rate": 0.0002727210652099693,
      "loss": 0.1586,
      "step": 933
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.3748306334018707,
      "learning_rate": 0.0002725844998292933,
      "loss": 0.178,
      "step": 934
    },
    {
      "epoch": 3.19,
      "grad_norm": 0.36419615149497986,
      "learning_rate": 0.00027244793444861727,
      "loss": 0.1732,
      "step": 935
    },
    {
      "epoch": 3.19,
      "grad_norm": 0.4152122437953949,
      "learning_rate": 0.0002723113690679413,
      "loss": 0.1877,
      "step": 936
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.39021027088165283,
      "learning_rate": 0.0002721748036872653,
      "loss": 0.1787,
      "step": 937
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.3665179908275604,
      "learning_rate": 0.00027203823830658925,
      "loss": 0.178,
      "step": 938
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.36268332600593567,
      "learning_rate": 0.0002719016729259133,
      "loss": 0.174,
      "step": 939
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.3188149034976959,
      "learning_rate": 0.0002717651075452373,
      "loss": 0.1662,
      "step": 940
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.31554487347602844,
      "learning_rate": 0.0002716285421645613,
      "loss": 0.166,
      "step": 941
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.329500287771225,
      "learning_rate": 0.00027149197678388534,
      "loss": 0.1708,
      "step": 942
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.33761778473854065,
      "learning_rate": 0.0002713554114032093,
      "loss": 0.1728,
      "step": 943
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.3661269247531891,
      "learning_rate": 0.00027121884602253327,
      "loss": 0.1841,
      "step": 944
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.3403746485710144,
      "learning_rate": 0.0002710822806418573,
      "loss": 0.147,
      "step": 945
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.3917948603630066,
      "learning_rate": 0.0002709457152611813,
      "loss": 0.1693,
      "step": 946
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.37389424443244934,
      "learning_rate": 0.0002708091498805053,
      "loss": 0.1584,
      "step": 947
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.3504187762737274,
      "learning_rate": 0.0002706725844998293,
      "loss": 0.1555,
      "step": 948
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.37423762679100037,
      "learning_rate": 0.0002705360191191533,
      "loss": 0.1828,
      "step": 949
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.37056103348731995,
      "learning_rate": 0.0002703994537384773,
      "loss": 0.1773,
      "step": 950
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.3522740304470062,
      "learning_rate": 0.0002702628883578013,
      "loss": 0.1615,
      "step": 951
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.32870739698410034,
      "learning_rate": 0.00027012632297712533,
      "loss": 0.1718,
      "step": 952
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.32489290833473206,
      "learning_rate": 0.0002699897575964493,
      "loss": 0.1632,
      "step": 953
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.34444108605384827,
      "learning_rate": 0.0002698531922157733,
      "loss": 0.1589,
      "step": 954
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.3620789051055908,
      "learning_rate": 0.0002697166268350973,
      "loss": 0.1776,
      "step": 955
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.4079180359840393,
      "learning_rate": 0.0002695800614544213,
      "loss": 0.1839,
      "step": 956
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.32887786626815796,
      "learning_rate": 0.0002694434960737453,
      "loss": 0.1541,
      "step": 957
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.365554541349411,
      "learning_rate": 0.00026930693069306935,
      "loss": 0.1674,
      "step": 958
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.33154651522636414,
      "learning_rate": 0.00026917036531239335,
      "loss": 0.1618,
      "step": 959
    },
    {
      "epoch": 3.27,
      "grad_norm": 0.37256842851638794,
      "learning_rate": 0.0002690337999317173,
      "loss": 0.1746,
      "step": 960
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.2974895238876343,
      "learning_rate": 0.00026889723455104133,
      "loss": 0.147,
      "step": 961
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.29883691668510437,
      "learning_rate": 0.00026876066917036533,
      "loss": 0.1332,
      "step": 962
    },
    {
      "epoch": 3.28,
      "grad_norm": 0.4404398798942566,
      "learning_rate": 0.0002686241037896893,
      "loss": 0.1951,
      "step": 963
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.4034886658191681,
      "learning_rate": 0.0002684875384090133,
      "loss": 0.1911,
      "step": 964
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.3069871664047241,
      "learning_rate": 0.00026835097302833736,
      "loss": 0.1435,
      "step": 965
    },
    {
      "epoch": 3.29,
      "grad_norm": 0.3404713273048401,
      "learning_rate": 0.0002682144076476613,
      "loss": 0.1774,
      "step": 966
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.37029045820236206,
      "learning_rate": 0.0002680778422669853,
      "loss": 0.1645,
      "step": 967
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.3861466646194458,
      "learning_rate": 0.00026794127688630935,
      "loss": 0.1765,
      "step": 968
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.386334627866745,
      "learning_rate": 0.00026780471150563334,
      "loss": 0.1942,
      "step": 969
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.35139939188957214,
      "learning_rate": 0.00026766814612495733,
      "loss": 0.1698,
      "step": 970
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.3330991566181183,
      "learning_rate": 0.00026753158074428133,
      "loss": 0.1587,
      "step": 971
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.32738208770751953,
      "learning_rate": 0.0002673950153636053,
      "loss": 0.1615,
      "step": 972
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.3391670286655426,
      "learning_rate": 0.0002672584499829293,
      "loss": 0.1706,
      "step": 973
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.3766893744468689,
      "learning_rate": 0.00026712188460225337,
      "loss": 0.183,
      "step": 974
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.365605890750885,
      "learning_rate": 0.00026698531922157736,
      "loss": 0.1759,
      "step": 975
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.3761231303215027,
      "learning_rate": 0.00026684875384090135,
      "loss": 0.1803,
      "step": 976
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.43626147508621216,
      "learning_rate": 0.00026671218846022535,
      "loss": 0.1778,
      "step": 977
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.3760504424571991,
      "learning_rate": 0.00026657562307954934,
      "loss": 0.1728,
      "step": 978
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.36308005452156067,
      "learning_rate": 0.00026643905769887334,
      "loss": 0.1642,
      "step": 979
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.38514822721481323,
      "learning_rate": 0.0002663024923181974,
      "loss": 0.1806,
      "step": 980
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.38597121834754944,
      "learning_rate": 0.0002661659269375214,
      "loss": 0.1852,
      "step": 981
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.3139248192310333,
      "learning_rate": 0.0002660293615568454,
      "loss": 0.152,
      "step": 982
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.34472227096557617,
      "learning_rate": 0.0002658927961761693,
      "loss": 0.1642,
      "step": 983
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.4206332862377167,
      "learning_rate": 0.00026575623079549336,
      "loss": 0.1941,
      "step": 984
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.34616580605506897,
      "learning_rate": 0.00026561966541481736,
      "loss": 0.1961,
      "step": 985
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.3608883023262024,
      "learning_rate": 0.00026548310003414135,
      "loss": 0.182,
      "step": 986
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.30316489934921265,
      "learning_rate": 0.0002653465346534654,
      "loss": 0.1602,
      "step": 987
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.35452938079833984,
      "learning_rate": 0.00026520996927278934,
      "loss": 0.1753,
      "step": 988
    },
    {
      "epoch": 3.37,
      "grad_norm": 0.3904125988483429,
      "learning_rate": 0.00026507340389211333,
      "loss": 0.2083,
      "step": 989
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.37211379408836365,
      "learning_rate": 0.0002649368385114374,
      "loss": 0.1691,
      "step": 990
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.3076159358024597,
      "learning_rate": 0.0002648002731307614,
      "loss": 0.1664,
      "step": 991
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.36583659052848816,
      "learning_rate": 0.00026466370775008537,
      "loss": 0.1741,
      "step": 992
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.38389262557029724,
      "learning_rate": 0.00026452714236940936,
      "loss": 0.1834,
      "step": 993
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.33549144864082336,
      "learning_rate": 0.00026439057698873336,
      "loss": 0.1653,
      "step": 994
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.3960261940956116,
      "learning_rate": 0.00026425401160805735,
      "loss": 0.1799,
      "step": 995
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.3106428384780884,
      "learning_rate": 0.0002641174462273814,
      "loss": 0.1378,
      "step": 996
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.4138626754283905,
      "learning_rate": 0.0002639808808467054,
      "loss": 0.1743,
      "step": 997
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.42327749729156494,
      "learning_rate": 0.0002638443154660294,
      "loss": 0.1725,
      "step": 998
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.4294850528240204,
      "learning_rate": 0.0002637077500853534,
      "loss": 0.1754,
      "step": 999
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.3817397356033325,
      "learning_rate": 0.0002635711847046774,
      "loss": 0.1596,
      "step": 1000
    }
  ],
  "logging_steps": 1,
  "max_steps": 2930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 1.42346440952021e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
