{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Segmentation Test Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Pre-Processing\n",
    "- We need the data to be a series of images at set time steps so if we are passing in a video file or something like that, we need to convert it to a set of discrete images for SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import json\n",
    "\n",
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns_reg(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    # sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((anns[0]['segmentation'].shape[0], anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of colors\n",
    "def random_colors(N):\n",
    "    np.random.seed(1)\n",
    "    intensity = 0.6\n",
    "    color = np.concatenate([np.random.random(3), np.array([intensity])], axis=0)\n",
    "    colors = np.array([color])\n",
    "    for i in range(N-1):\n",
    "        color = np.concatenate([np.random.random(3), np.array([intensity])], axis=0)\n",
    "        colors = np.concatenate([colors, [color]], axis=0)\n",
    "    return colors\n",
    "\n",
    "color_list = random_colors(100)\n",
    "\n",
    "def show_mask(mask, ax, random_color=False, color=None):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    elif color is not None:\n",
    "        color = color\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the hu moments of the mask for shape dissimilarity\n",
    "def hu_moments(mask):\n",
    "    mask = mask.astype(np.uint8)\n",
    "    moments = cv2.moments(mask)\n",
    "    hu_moments = cv2.HuMoments(moments)\n",
    "    return hu_moments\n",
    "\n",
    "# calculating the shape dissimilarity\n",
    "def shape_dissimilarity(hu_moments1, hu_moments2):\n",
    "    diff = np.abs(hu_moments1 - hu_moments2)\n",
    "    dissimilarity = np.mean(diff)\n",
    "    return dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hungarian_algorithm(cost_matrix):\n",
    "    num_rows = len(cost_matrix)\n",
    "    num_cols = len(cost_matrix[0])\n",
    "\n",
    "    # Step 1: Subtract the minimum value from each row\n",
    "    for i in range(num_rows):\n",
    "        min_value = min(cost_matrix[i])\n",
    "        for j in range(num_cols):\n",
    "            cost_matrix[i][j] -= min_value\n",
    "\n",
    "    # Step 2: Subtract the minimum value from each column\n",
    "    for j in range(num_cols):\n",
    "        min_value = min(cost_matrix[i][j] for i in range(num_rows))\n",
    "        for i in range(num_rows):\n",
    "            cost_matrix[i][j] -= min_value\n",
    "\n",
    "    # Step 3: Find a complete matching by selecting zero entries\n",
    "    matching = []\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            if cost_matrix[i][j] == 0 and not any(j in m for m in matching):\n",
    "                matching.append((i, j))\n",
    "                break\n",
    "\n",
    "    # Step 4: If the matching is not complete, update the matrix and repeat steps 3-4\n",
    "    while len(matching) < min(num_rows, num_cols):\n",
    "        # Find the minimum uncovered value\n",
    "        min_uncovered = float('inf')\n",
    "        for i in range(num_rows):\n",
    "            if not any(i == m[0] for m in matching):\n",
    "                for j in range(num_cols):\n",
    "                    if not any(j == m[1] for m in matching):\n",
    "                        min_uncovered = min(min_uncovered, cost_matrix[i][j])\n",
    "\n",
    "        # Subtract the minimum uncovered value from each uncovered row\n",
    "        for i in range(num_rows):\n",
    "            if not any(i == m[0] for m in matching):\n",
    "                for j in range(num_cols):\n",
    "                    cost_matrix[i][j] -= min_uncovered\n",
    "\n",
    "        # Add the minimum uncovered value to each covered column\n",
    "        for j in range(num_cols):\n",
    "            if any(j == m[1] for m in matching):\n",
    "                for i in range(num_rows):\n",
    "                    cost_matrix[i][j] += min_uncovered\n",
    "\n",
    "        # Find a complete matching by selecting zero entries\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_cols):\n",
    "                if cost_matrix[i][j] == 0 and not any(j in m for m in matching):\n",
    "                    matching.append((i, j))\n",
    "                    break\n",
    "\n",
    "    return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get matching masks to previous frame and keep matching segmentations based on IOU using Hungarian algorithm\n",
    "# good weights were 0.4, 0.05, 0.2, 0.2\n",
    "# def get_matching_masks(prev_masks, curr_masks, iou_weight=0.3, dist_weight=0.1, size_diff_weight=0.3, shape_dissimilarity_weight=0.3):\n",
    "def get_matching_masks(prev_masks, curr_masks, iou_weight=0.45, dist_weight=0.1, size_diff_weight=0.2, shape_dissimilarity_weight=0.4):\n",
    "    n_prev_masks = len(prev_masks)\n",
    "    n_curr_masks = len(curr_masks)\n",
    "    \n",
    "    # if there are no masks in the previous frame, then return all the masks in the current frame\n",
    "    if n_prev_masks == 0:\n",
    "        return list(range(n_curr_masks))\n",
    "    \n",
    "    # if there are no masks in the current frame, then return an empty list\n",
    "    if n_curr_masks == 0:\n",
    "        return []\n",
    "    \n",
    "    # compute the distance between each mask centroid in prev_masks and each mask centroid in curr_mask as a percentage of width and height\n",
    "    distance_matrix = np.zeros((n_prev_masks, n_curr_masks))\n",
    "    # compute the percent size difference between each mask in prev_masks and the corresponding mask in curr_masks\n",
    "    percent_size_diff = np.zeros((n_prev_masks, n_curr_masks))\n",
    "    # calculate IOU between all pairs of masks\n",
    "    shape_dissimilarity_matrix = np.zeros((n_prev_masks, n_curr_masks))\n",
    "    iou_matrix = np.zeros((n_prev_masks, n_curr_masks))\n",
    "    cost_matrix = np.zeros((n_prev_masks, n_curr_masks))\n",
    "    for i in range(n_prev_masks):\n",
    "        for j in range(n_curr_masks):\n",
    "            hu1 = hu_moments(prev_masks[i])\n",
    "            hu2 = hu_moments(curr_masks[j])\n",
    "            iou_matrix[i][j] = iou(prev_masks[i], curr_masks[j])\n",
    "            shape_dissimilarity_matrix[i][j] = shape_dissimilarity(hu1, hu2)\n",
    "            prev_centroid = np.mean(np.argwhere(prev_masks[i]), axis=0)\n",
    "            curr_centroid = np.mean(np.argwhere(curr_masks[j]), axis=0)\n",
    "            distance_matrix[i][j] = np.linalg.norm(prev_centroid - curr_centroid) / np.sqrt(prev_masks[i].shape[0] * prev_masks[i].shape[1])\n",
    "            prev_area = np.sum(prev_masks[i])\n",
    "            curr_area = np.sum(curr_masks[j])\n",
    "            percent_size_diff[i][j] = (abs(prev_area - curr_area) / prev_area)\n",
    "            # cost_matrix[i][j] = -iou_matrix[i][j] * iou_weight + distance_matrix[i][j] * dist_weight + percent_size_diff[i][j] * size_diff_weight + shape_dissimilarity_matrix[i][j] * shape_dissimilarity_weight\n",
    "            cost_matrix[i][j] = (1-iou_matrix[i][j]) * iou_weight + distance_matrix[i][j] * dist_weight + percent_size_diff[i][j] * size_diff_weight + shape_dissimilarity_matrix[i][j] * shape_dissimilarity_weight\n",
    "    \n",
    "    # use scipy to solve the assignment problem\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # get the matching pairs of masks\n",
    "    matching_pairs = []\n",
    "    for i in range(len(row_ind)):\n",
    "        # if iou_matrix[row_ind[i]][col_ind[i]] > iou_thresh:\n",
    "        matching_pairs.append((row_ind[i], col_ind[i]))\n",
    "    # matching_pairs = hungarian_algorithm(cost_matrix)\n",
    "\n",
    "    # print weighted shape dissimilarity, iou, distance and size difference for each matching pair\n",
    "    for i, j in matching_pairs:\n",
    "        print(f'Weighted Shape Dissimilarity: {shape_dissimilarity_matrix[i][j] * shape_dissimilarity_weight}, IOU: {iou_matrix[i][j] * iou_weight}, Distance: {distance_matrix[i][j] * dist_weight}, Size Difference: {percent_size_diff[i][j] * size_diff_weight}')\n",
    "    \n",
    "    return matching_pairs\n",
    "\n",
    "# calculate the intersection over union (IOU) of two masks\n",
    "def iou(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1, mask2)\n",
    "    union = np.logical_or(mask1, mask2)\n",
    "    return np.sum(intersection) / np.sum(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the bounding box given a mask, not using openCV\n",
    "def get_box(segmentation_mask):\n",
    "    rows = len(segmentation_mask)\n",
    "    if rows == 0:\n",
    "        return None\n",
    "    cols = len(segmentation_mask[0])\n",
    "    \n",
    "    # Initialize bounding box coordinates\n",
    "    min_row, min_col = rows, cols\n",
    "    max_row, max_col = 0, 0\n",
    "    \n",
    "    # Iterate through the segmentation mask to find True values\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            if segmentation_mask[row][col]:\n",
    "                min_row = min(min_row, row)\n",
    "                min_col = min(min_col, col)\n",
    "                max_row = max(max_row, row)\n",
    "                max_col = max(max_col, col)\n",
    "    \n",
    "    # If no True values found, return None\n",
    "    if min_row == rows or min_col == cols:\n",
    "        return None\n",
    "    \n",
    "    return [min_col, min_row, max_col, max_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(mask):\n",
    "    mask = mask.astype(np.uint8)\n",
    "    M = cv2.moments(mask)\n",
    "    if M[\"m00\"] == 0:\n",
    "        return np.array([0, 0])\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    return np.array([cX, cY])\n",
    "\n",
    "def find_centroid_2(mask):\n",
    "    # using np.argwhere and np.mean\n",
    "    return np.mean(np.argwhere(mask), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an array of mask numbers, combine all the masks and return the combined mask\n",
    "def combine_masks(mask_nums, masks):\n",
    "    combined_mask = np.zeros(masks[0]['segmentation'].shape, dtype=bool)\n",
    "    for i in mask_nums:\n",
    "        combined_mask = np.logical_or(combined_mask, masks[i]['segmentation'])\n",
    "    return combined_mask\n",
    "\n",
    "# Given an np.array of shape (mask_num, width, height), return the combined mask\n",
    "def combine_all_masks(masks):\n",
    "    combined_mask = np.zeros(masks[0].shape, dtype=bool)\n",
    "    for mask in masks:\n",
    "        combined_mask = np.logical_or(combined_mask, mask)\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get annotations from the json file\n",
    "def get_annotations(json_file):\n",
    "    # Read the JSON data from the file\n",
    "    data = None\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    annotations = []\n",
    "    # Iterate over each image in the JSON data\n",
    "    for image_data in data:\n",
    "        image_path = image_data['image']\n",
    "        index = image_path.index(\"test-images\")\n",
    "        image_path = image_path[index:]\n",
    "        image_path = image_path.replace(\"X\", \"/\")\n",
    "        original_width = image_data['label'][0]['original_width']\n",
    "        original_height = image_data['label'][0]['original_height']\n",
    "        \n",
    "        # Create a dictionary to store the bounding boxes for each label\n",
    "        bounding_boxes = {}\n",
    "        \n",
    "        # Iterate over each annotation for the current image\n",
    "        for annotation in image_data['label']:\n",
    "            label = annotation['rectanglelabels'][0]\n",
    "            \n",
    "            # Extract the bounding box coordinates\n",
    "            x = annotation['x']\n",
    "            y = annotation['y']\n",
    "            width = annotation['width']\n",
    "            height = annotation['height']\n",
    "            \n",
    "            # Scale the coordinates to the original image dimensions\n",
    "            x_scaled = int(x * original_width / 100)\n",
    "            y_scaled = int(y * original_height / 100)\n",
    "            width_scaled = int(width * original_width / 100)\n",
    "            height_scaled = int(height * original_height / 100)\n",
    "            \n",
    "            # Calculate the xyxy coordinates\n",
    "            x1 = x_scaled\n",
    "            y1 = y_scaled\n",
    "            x2 = x_scaled + width_scaled\n",
    "            y2 = y_scaled + height_scaled\n",
    "            \n",
    "            # Add the bounding box coordinates to the dictionary\n",
    "            if label not in bounding_boxes:\n",
    "                bounding_boxes[label] = []\n",
    "            bounding_boxes[label].append([x1, y1, x2, y2])\n",
    "        \n",
    "        annotations.append((image_path, bounding_boxes))\n",
    "\n",
    "    ann_np = np.array(annotations)\n",
    "    return ann_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in a mask and returns the mask with the largest contiguous section still kept in the mask and nothing else\n",
    "def get_largest_contiguous(mask):\n",
    "    # get the largest contiguous section of the mask\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask.astype(np.uint8), connectivity=8)\n",
    "    largest_label = 1\n",
    "    max_area = stats[1, cv2.CC_STAT_AREA]\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] > max_area:\n",
    "            max_area = stats[i, cv2.CC_STAT_AREA]\n",
    "            largest_label = i\n",
    "    mask = np.array(labels == largest_label, dtype=bool)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/home/yashas/Documents/thesis/segment-anything/test-images/group_0/traj0/images0/'\n",
    "image_prefix = 'im_'\n",
    "image_suffix = '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_plot_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "large_sam_checkpoint = \"/home/yashas/Documents/thesis/segment-anything/sam_vit_h_4b8939.pth\"\n",
    "large_model_type = \"vit_h\"\n",
    "\n",
    "# small_sam_checkpoint = \"/home/yashas/Documents/thesis/segment-anything/sam_vit_b_01ec64.pth\"\n",
    "# small_model_type = \"vit_b\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[large_model_type](checkpoint=large_sam_checkpoint)\n",
    "# sam = sam_model_registry[small_model_type](checkpoint=small_sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First image visualization and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_dir + image_prefix + '0' + image_suffix)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "predictor.set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read testset_annotations.json file and get the annotations\n",
    "json_file = \"/home/yashas/Documents/thesis/thesis_working/testset_annotations.json\"\n",
    "annotations = get_annotations(json_file)\n",
    "\n",
    "image_path = image_dir + image_prefix + '0' + image_suffix\n",
    "image_path = image_path[image_path.index(\"test-images\"):]\n",
    "\n",
    "# get the annotations for the current image\n",
    "curr_ann = None\n",
    "for ann in annotations:\n",
    "    if ann[0] == image_path:\n",
    "        curr_ann = ann\n",
    "        break\n",
    "print(curr_ann)\n",
    "\n",
    "# getting the bounding boxes and centroid points for each label\n",
    "boxes = []\n",
    "boxes.append(curr_ann[1]['gripper'][0])\n",
    "boxes.append(curr_ann[1]['table'][0])\n",
    "boxes.append(curr_ann[1]['yellow_block'][0])\n",
    "boxes.append(curr_ann[1]['green_block'][0])\n",
    "boxes.append(curr_ann[1]['blue_block'][0])\n",
    "boxes.append(curr_ann[1]['red_block'][0])\n",
    "input_boxes = torch.tensor(boxes, device=predictor.device)\n",
    "transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])\n",
    "\n",
    "points = []\n",
    "points.append(curr_ann[1]['gripper_center'][0][:2])\n",
    "points.append(curr_ann[1]['table_center'][0][:2])\n",
    "points.append(curr_ann[1]['yellow_block_center'][0][:2])\n",
    "points.append(curr_ann[1]['green_block_center'][0][:2])\n",
    "points.append(curr_ann[1]['blue_block_center'][0][:2])\n",
    "points.append(curr_ann[1]['red_block_center'][0][:2])\n",
    "points_input = np.array([points])\n",
    "for i in range(1, len(points)):\n",
    "    points_input = np.append(points_input, [points], axis=0)\n",
    "points_input = torch.tensor(points_input, device=predictor.device)\n",
    "input_points = predictor.transform.apply_coords_torch(points_input, image.shape[:2])\n",
    "labels = torch.diag(torch.ones(len(points), device=predictor.device))\n",
    "first_frame_segs, scores, logits = predictor.predict_torch(\n",
    "    point_coords=input_points,\n",
    "    point_labels=labels,\n",
    "    boxes = transformed_boxes,\n",
    "    multimask_output = False,\n",
    ")\n",
    "print(first_frame_segs.shape)\n",
    "\n",
    "# get the masks from the first frame\n",
    "first_frame_masks = first_frame_segs.cpu().numpy()\n",
    "first_frame_masks = first_frame_masks > 0.5\n",
    "first_frame_masks = first_frame_masks.squeeze(1)\n",
    "print(first_frame_masks.shape)\n",
    "\n",
    "# combine the masks\n",
    "combined_mask = combine_all_masks(first_frame_masks)\n",
    "\n",
    "plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "# plt.imshow(image)\n",
    "show_mask(combined_mask, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# get the largest contiguous section of each mask\n",
    "for i in range(len(first_frame_masks)):\n",
    "    first_frame_masks[i] = get_largest_contiguous(first_frame_masks[i])\n",
    "\n",
    "combined_mask = combine_all_masks(first_frame_masks)\n",
    "\n",
    "plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "# plt.imshow(image)\n",
    "show_mask(combined_mask, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "total_masks_over_time = np.array([first_frame_masks])\n",
    "print(total_masks_over_time.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentations over time of the rest of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out how many images there are in the directory\n",
    "import os\n",
    "\n",
    "image_files = os.listdir(image_dir)\n",
    "image_files = [f for f in image_files if f.endswith('.jpg')]\n",
    "image_files = sorted(image_files)\n",
    "n_images = len(image_files)\n",
    "print(f\"Found {n_images} images in the directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_margin = 0.2\n",
    "\n",
    "# total_masks_over_time = np.array([[relevant_first_mask_anns[i]['segmentation'] for i in range(len(relevant_first_mask_anns))]])\n",
    "# # the shape of this is [frame_num, mask_num, height, width]\n",
    "# print(total_masks_over_time.shape)\n",
    "total_masks_over_time = np.array([first_frame_masks])\n",
    "print(total_masks_over_time.shape)\n",
    "for i in range(1, n_images):\n",
    "    frame_num = i\n",
    "    image = cv2.imread(image_dir + image_prefix + str(frame_num) + image_suffix)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    predictor.set_image(image)\n",
    "\n",
    "    # get bounding boxes from previous masks\n",
    "    boxes = [get_box(mask) for mask in total_masks_over_time[frame_num-1]]\n",
    "    print(\"Frame Number: \", frame_num)\n",
    "    # print(boxes)\n",
    "    # inflate boxes\n",
    "    for box in boxes:\n",
    "        if box is not None:\n",
    "            box[0] = max(0, box[0] - box_margin * (box[2] - box[0]))\n",
    "            box[1] = max(0, box[1] - box_margin * (box[3] - box[1]))\n",
    "            box[2] = min(image.shape[1], box[2] + box_margin * (box[2] - box[0]))\n",
    "            box[3] = min(image.shape[0], box[3] + box_margin * (box[3] - box[1]))\n",
    "\n",
    "    input_boxes = torch.tensor(boxes, device=predictor.device)\n",
    "\n",
    "    transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])\n",
    "\n",
    "    # commented out since just the boxes give us terrible performance and we use the boxes later anyways\n",
    "    masks, scores, logits = predictor.predict_torch(\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        boxes=transformed_boxes,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "\n",
    "    masks = masks.cpu().numpy()\n",
    "    curr_frame_first_masks = np.array([masks[i][j] for i in range(masks.shape[0]) for j in range(masks.shape[1])])\n",
    "\n",
    "    centroids = np.array([find_centroid(mask) for mask in total_masks_over_time[frame_num-1]])\n",
    "    masks_points = torch.tensor(centroids, device=predictor.device)\n",
    "    points_for_display = masks_points.cpu().numpy()\n",
    "    # reshape masks_points to be of shape (n_masks, 1, 2)\n",
    "    masks_points = masks_points.unsqueeze(1)\n",
    "    masks_labels = torch.ones(len(masks_points), device=predictor.device)\n",
    "    labels_for_display = masks_labels.cpu().numpy()\n",
    "    # reshape masks_labels to be of shape (n_masks, 1)\n",
    "    masks_labels = masks_labels.unsqueeze(1)\n",
    "    input_points = predictor.transform.apply_coords_torch(masks_points, image.shape[:2])\n",
    "    # print(\"Masks Points: \")\n",
    "    # print(masks_points.shape)\n",
    "    mask_point_segs, scores, logits = predictor.predict_torch(\n",
    "        point_coords=input_points,\n",
    "        point_labels=masks_labels,\n",
    "        boxes=transformed_boxes,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "    mask_point_segs = mask_point_segs.cpu().numpy()\n",
    "    curr_frame_point_seg_masks = np.array([mask_point_segs[i][j] for i in range(mask_point_segs.shape[0]) for j in range(mask_point_segs.shape[1])])\n",
    "    # print(\"Mask Point Segs:\")\n",
    "    # print(mask_point_segs.shape)\n",
    "    # print(\"Curr Frame Point Seg Masks:\")\n",
    "    # print(curr_frame_point_seg_masks.shape)\n",
    "\n",
    "    points_input = np.array([centroids])\n",
    "    for i in range(1, len(centroids)):\n",
    "        points_input = np.append(points_input, [centroids], axis=0)\n",
    "    labels = torch.diag(torch.ones(len(centroids), device=predictor.device))\n",
    "    points_input = torch.tensor(points_input, device=predictor.device)\n",
    "    input_points = predictor.transform.apply_coords_torch(points_input, image.shape[:2])\n",
    "    third_seg_masks, scores, logits = predictor.predict_torch(\n",
    "        point_coords=input_points,\n",
    "        point_labels=labels,\n",
    "        boxes=None,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "    third_seg_masks = third_seg_masks.cpu().numpy()\n",
    "    curr_frame_third_seg_masks = np.array([third_seg_masks[i][j] for i in range(third_seg_masks.shape[0]) for j in range(third_seg_masks.shape[1])])\n",
    "\n",
    "    # plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "    # # plt.imshow(image)\n",
    "    # k = 0\n",
    "    # for mask in third_seg_masks:\n",
    "    #     # print(mask.shape)\n",
    "    #     # get first element of mask but keep shape of mask\n",
    "    #     mask = mask[1]\n",
    "    #     # print(mask.shape)\n",
    "    #     show_mask(mask, plt.gca(), color=np.array([color_list[k]]))\n",
    "    #     k = k + 1\n",
    "    # for box in input_boxes:\n",
    "    #     show_box(box.cpu().numpy(), plt.gca())\n",
    "    # for point in input_points:\n",
    "    #     show_points(points_for_display, labels_for_display, plt.gca())\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    use_contiguous = True\n",
    "    use_first_segmentation = False\n",
    "    # flatten all multimasks into one masks array\n",
    "    # create curr_frame_all_masks as numpy array with dimensions n_masks, height, width\n",
    "    if use_first_segmentation:\n",
    "        curr_frame_all_masks = np.array([curr_frame_first_masks[i] for i in range(len(curr_frame_first_masks))])\n",
    "        curr_frame_all_masks = np.append(curr_frame_all_masks, curr_frame_point_seg_masks, axis=0)\n",
    "    else:\n",
    "        curr_frame_all_masks = np.array([curr_frame_point_seg_masks[i] for i in range(len(curr_frame_point_seg_masks))])\n",
    "    # merge curr_frame_all_masks with curr_frame_point_seg_masks\n",
    "    curr_frame_all_masks = np.append(curr_frame_all_masks, curr_frame_third_seg_masks, axis=0)\n",
    "    # get contiguous sections of each mask\n",
    "    contiguous_all_masks = np.array([get_largest_contiguous(mask) for mask in curr_frame_all_masks])\n",
    "    # print(\"Curr Frame All Masks:\")\n",
    "    # print(curr_frame_all_masks.shape)\n",
    "    # compute matching pairs between masks and total_masks_over_time[frame_num]\n",
    "    if not use_contiguous:\n",
    "        matching_pairs = get_matching_masks(total_masks_over_time[frame_num-1], curr_frame_all_masks)\n",
    "        matching_masks = [curr_frame_all_masks[pair[1]] for pair in matching_pairs]\n",
    "    else:\n",
    "        matching_pairs = get_matching_masks(total_masks_over_time[frame_num-1], contiguous_all_masks)\n",
    "        matching_masks = [contiguous_all_masks[pair[1]] for pair in matching_pairs]\n",
    "    print(\"Matching Pairs:\")\n",
    "    print(matching_pairs)\n",
    "    total_masks_over_time = np.append(total_masks_over_time, np.array([matching_masks]), axis=0)\n",
    "    print(total_masks_over_time.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the total_masks_over_time as an animation, with each mask in each frame being a different color, side by side with the real image, for comparison\n",
    "for i in range(0, n_images):\n",
    "    image = cv2.imread(image_dir + image_prefix + str(i) + image_suffix)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(big_plot_dim*2, big_plot_dim*2))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"Frame {i} Real Image\")\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"Frame {i} Segmentation\")\n",
    "    show_all_masks = True\n",
    "    masks_to_show = [2]\n",
    "    for j in range(len(total_masks_over_time[i])):\n",
    "        if show_all_masks:\n",
    "            show_mask(total_masks_over_time[i][j], plt.gca(), color=np.array(color_list[j]))\n",
    "        elif j in masks_to_show:\n",
    "            show_mask(total_masks_over_time[i][j], plt.gca(), color=np.array(color_list[j]))\n",
    "    # output each frame in animation to file\n",
    "    plt.savefig(f\"frame_{i}.png\")\n",
    "    plt.show()\n",
    "    time.sleep(0.1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the total_masks_over_time, with each mask in each frame being a different color\n",
    "# n = total_masks_over_time.shape[0]\n",
    "# cols = 4\n",
    "# rows = n // cols + 1\n",
    "# plt.figure(figsize=(16, 16))\n",
    "# for i in range(n):\n",
    "#     plt.subplot(rows, cols, i + 1)\n",
    "#     plt.title(f\"Frame {i}\")\n",
    "#     for j in range(len(total_masks_over_time[i])):\n",
    "#         show_mask(total_masks_over_time[i][j], plt.gca(), color=np.array(color_list[j]))\n",
    "#     plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all images in directory as animation\n",
    "# for i in range(0, n_images):\n",
    "#     image = cv2.imread(image_dir + image_prefix + str(i) + image_suffix)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "#     plt.title(f\"Frame {i}\")\n",
    "#     plt.imshow(image)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "#     time.sleep(0.1)\n",
    "#     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the total_masks_over time as an animation and in the same plot as the real image, for comparison\n",
    "# for i in range(0, n_images):\n",
    "#     image = cv2.imread(image_dir + image_prefix + str(i) + image_suffix)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     plt.figure(figsize=(big_plot_dim, big_plot_dim))\n",
    "#     plt.title(f\"Frame {i}\")\n",
    "#     plt.imshow(image)   # Comment this line to see only the masks\n",
    "#     for j in range(len(total_masks_over_time[i])):\n",
    "#         show_mask(total_masks_over_time[i][j], plt.gca(), color=np.array(color_list[j]))\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "#     time.sleep(0.1)\n",
    "#     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling necessary results for use with algorithmic tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "out_path = image_dir + 'total_masks_over_time.pkl'\n",
    "with open(out_path, 'wb') as f:\n",
    "    pickle.dump(total_masks_over_time, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
